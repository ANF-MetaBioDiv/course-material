[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ANF MetaBioDiv",
    "section": "",
    "text": "Welcome to the third edition of the ANF Exploration de la Diversité Taxonomique des Ecosystèmes par Metabarcoding. The aim of this course is to teach you how to run microbial ecology analyses (mostly alpha and beta diversity) from metabarcoding raw sequencing data using R.\n\n\nYou can also find a pdf version of the program here\n\nMonday 29th:\n\n09h00: Participants arrival and installation\n12h30: \n14h00: Training introduction I\n14h15: Introduction and R practical by Marc Garel + check technical issues\n16h00: \n16h15: R practical by Marc Garel + check technical issues\n18h00: Seminar “Introduction bonne pratique” - – i.e dépôt github, FAIR principles by M. Garel\n19h30:  Ice breack, apéritif and diner\n\nTuesday 30th:\n\n08h30: Introduction Metabarcoding to metabarcoding by Loïs Maignien\n09h30: Analysing metabarcoding data with dada2 by Charlotte Berthelier\n10h15: \n10h30: Preprocessing: dada2 by Charlotte Berthelier\n12h30: \n14h00: Introduction to phyloseq\n15h00: Preprocessing: dada2 and Preprocessing: phyloseq by Charlotte Berthelier\n16h00: \n16h15: Preprocessing: dada2 and Preprocessing: phyloseq by Charlotte Berthelier\n18h00: Mise en place des repos de données perso pour ceux qu’il le souhaite outemps libre\n19h30: \n\nWednesday 1st:\n\n08h30: Course on alpha diversity 1/2 by Fabrice Armougom and Elsa Mendes\n10h15: \n10h30: Alpha diversity practical by Fabrice Armougom and Elsa Mendes\n12h30: \n14h00: Séminaire metabarcoding worklows by Charlotte Berthelier\n15h00: Ampliseq configuration workflow by Charlotte Berthelier and Marc Garel\n16h00: \n16h15: Ampliseq configuration workflow by Charlotte Berthelier and Marc Garel\n17h15: Séminaire introduction Long Read by F. Armougom\n18h15: Mise en place des repos de données perso pour ceux qu’il le souhaite outemps libre\n19h30: \n\nThursday 2nd:\n\n08h30: Course on beta diversity 1/2 by Jean-Christophe Auguet\n10h15: \n10h30: Beta diversity practical by Jean-Christophe Auguet\n12h30: \n14h00: Course on beta diversity 2/2 by Jean-Christophe Auguet\n15h00: Beta diversity practical by Jean-Christophe Auguet\n16h00: \n16h15: Beta diversity practical by Jean-Christophe Auguet\n18h00: free time\n19h30:  \n\nFriday 3rd:\n\n09h00: À la carte with \n12h30: \n14h00: End of the course"
  },
  {
    "objectID": "index.html#program",
    "href": "index.html#program",
    "title": "ANF MetaBioDiv",
    "section": "",
    "text": "You can also find a pdf version of the program here\n\nMonday 29th:\n\n09h00: Participants arrival and installation\n12h30: \n14h00: Training introduction I\n14h15: Introduction and R practical by Marc Garel + check technical issues\n16h00: \n16h15: R practical by Marc Garel + check technical issues\n18h00: Seminar “Introduction bonne pratique” - – i.e dépôt github, FAIR principles by M. Garel\n19h30:  Ice breack, apéritif and diner\n\nTuesday 30th:\n\n08h30: Introduction Metabarcoding to metabarcoding by Loïs Maignien\n09h30: Analysing metabarcoding data with dada2 by Charlotte Berthelier\n10h15: \n10h30: Preprocessing: dada2 by Charlotte Berthelier\n12h30: \n14h00: Introduction to phyloseq\n15h00: Preprocessing: dada2 and Preprocessing: phyloseq by Charlotte Berthelier\n16h00: \n16h15: Preprocessing: dada2 and Preprocessing: phyloseq by Charlotte Berthelier\n18h00: Mise en place des repos de données perso pour ceux qu’il le souhaite outemps libre\n19h30: \n\nWednesday 1st:\n\n08h30: Course on alpha diversity 1/2 by Fabrice Armougom and Elsa Mendes\n10h15: \n10h30: Alpha diversity practical by Fabrice Armougom and Elsa Mendes\n12h30: \n14h00: Séminaire metabarcoding worklows by Charlotte Berthelier\n15h00: Ampliseq configuration workflow by Charlotte Berthelier and Marc Garel\n16h00: \n16h15: Ampliseq configuration workflow by Charlotte Berthelier and Marc Garel\n17h15: Séminaire introduction Long Read by F. Armougom\n18h15: Mise en place des repos de données perso pour ceux qu’il le souhaite outemps libre\n19h30: \n\nThursday 2nd:\n\n08h30: Course on beta diversity 1/2 by Jean-Christophe Auguet\n10h15: \n10h30: Beta diversity practical by Jean-Christophe Auguet\n12h30: \n14h00: Course on beta diversity 2/2 by Jean-Christophe Auguet\n15h00: Beta diversity practical by Jean-Christophe Auguet\n16h00: \n16h15: Beta diversity practical by Jean-Christophe Auguet\n18h00: free time\n19h30:  \n\nFriday 3rd:\n\n09h00: À la carte with \n12h30: \n14h00: End of the course"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "The Action Nationale de Formation CNRS-INSU MetaBioDiv, led by the Mediterranean Institut of Oceanography (Armougom F., MIO) and the Délégation Régionale Côte d’Azur CNRS (DR20, Pierrette Finsac), offers to the scientific community a formation to learn how to characterize microbial ecosystems biodiversity with R analysing data from high-throughput Illumina (Miseq) sequencing.\n\n\n\nL’Action Nationale de Formation CNRS-INSU MetaBioDiv, portée par l’Institut Méditerranéen d’Océanologie (Armougom F., MIO) et la Délégation Régionale Côte d’Azur CNRS (DR20, Pierrette Finsac), propose à la communauté scientifique une formation sur la caractérisation de la biodiversité taxonomique d’écosystèmes (procaryotes et micro-eucaryotes) par le prisme du séquençage haut-débit Illumina (Miseq) et du traitement bio-informatique associé (outils R sous Rstudio)."
  },
  {
    "objectID": "about.html#english",
    "href": "about.html#english",
    "title": "About",
    "section": "",
    "text": "The Action Nationale de Formation CNRS-INSU MetaBioDiv, led by the Mediterranean Institut of Oceanography (Armougom F., MIO) and the Délégation Régionale Côte d’Azur CNRS (DR20, Pierrette Finsac), offers to the scientific community a formation to learn how to characterize microbial ecosystems biodiversity with R analysing data from high-throughput Illumina (Miseq) sequencing."
  },
  {
    "objectID": "about.html#french",
    "href": "about.html#french",
    "title": "About",
    "section": "",
    "text": "L’Action Nationale de Formation CNRS-INSU MetaBioDiv, portée par l’Institut Méditerranéen d’Océanologie (Armougom F., MIO) et la Délégation Régionale Côte d’Azur CNRS (DR20, Pierrette Finsac), propose à la communauté scientifique une formation sur la caractérisation de la biodiversité taxonomique d’écosystèmes (procaryotes et micro-eucaryotes) par le prisme du séquençage haut-débit Illumina (Miseq) et du traitement bio-informatique associé (outils R sous Rstudio)."
  },
  {
    "objectID": "practicals/rforbeginer.html",
    "href": "practicals/rforbeginer.html",
    "title": "Part 0: R for beginner",
    "section": "",
    "text": "To install R, you can go to https://cran.r-project.org/, and download the install file for your favorite operating system, click on the .exe, .dmg, .pkg, .deb, respectively for Windows, MacOS and Linux-debian.\nAnd click on follow… until to reach successful installation Then download and install the IDE Rstudio https://posit.co/download/rstudio-desktop/.\nEverything is free to download\n\n\n\nWhere am I?\nTo get the current working directory\n\ngetwd()\n\n[1] \"/home/rstudio/mydatalocal/course-material/practicals\"\n\n\nTo change my working directory from the console\n\nsetwd(\"/path/to/my/fancy/project/\")\n\nIn Rstudio, we can change the working directory by navigating in folder in File panel and clicking on menu More\nIf you are using a Rproject, you don’t need to change your working directory.\nHow can I find documentation about function?\nThe command help() is the 911\n\n# exemple with function read.table\nhelp(\"read.table\")\n#other exemple of 911\nexample(\"plot\")\n??plot()"
  },
  {
    "objectID": "practicals/rforbeginer.html#useful-link",
    "href": "practicals/rforbeginer.html#useful-link",
    "title": "Part 0: R for beginner",
    "section": "",
    "text": "To install R, you can go to https://cran.r-project.org/, and download the install file for your favorite operating system, click on the .exe, .dmg, .pkg, .deb, respectively for Windows, MacOS and Linux-debian.\nAnd click on follow… until to reach successful installation Then download and install the IDE Rstudio https://posit.co/download/rstudio-desktop/.\nEverything is free to download"
  },
  {
    "objectID": "practicals/rforbeginer.html#first-commands",
    "href": "practicals/rforbeginer.html#first-commands",
    "title": "Part 0: R for beginner",
    "section": "",
    "text": "Where am I?\nTo get the current working directory\n\ngetwd()\n\n[1] \"/home/rstudio/mydatalocal/course-material/practicals\"\n\n\nTo change my working directory from the console\n\nsetwd(\"/path/to/my/fancy/project/\")\n\nIn Rstudio, we can change the working directory by navigating in folder in File panel and clicking on menu More\nIf you are using a Rproject, you don’t need to change your working directory.\nHow can I find documentation about function?\nThe command help() is the 911\n\n# exemple with function read.table\nhelp(\"read.table\")\n#other exemple of 911\nexample(\"plot\")\n??plot()"
  },
  {
    "objectID": "practicals/rforbeginer.html#installation",
    "href": "practicals/rforbeginer.html#installation",
    "title": "Part 0: R for beginner",
    "section": "2.1 Installation",
    "text": "2.1 Installation\nYou can install new packages by clicking directly in Rstudio or by command line (the best way for me)\n\ninstall.packages(\"your_package\") # for packages on CRAN mirror\n\nFor packages from Bioconductor (specifically for bioinformatic):\n\nBiocManager::install(\"your_package\")\n\nor from github (using the package devtools)\n\ndevtools::install_github(\"your_package\")"
  },
  {
    "objectID": "practicals/rforbeginer.html#using-functions-from-a-package",
    "href": "practicals/rforbeginer.html#using-functions-from-a-package",
    "title": "Part 0: R for beginner",
    "section": "2.2 Using functions from a package",
    "text": "2.2 Using functions from a package\nTo use functions from a specific package you can either load the entire package:\n\nlibrary(\"your package1\")\nlibrary(\"your package2\")\nlibrary(\"your package3\")\n\nor call the function this way:\n\nyour_package::yourfunction()\n\nOn your R session using cloud IFB all the necessary packages are installed"
  },
  {
    "objectID": "practicals/rforbeginer.html#expression",
    "href": "practicals/rforbeginer.html#expression",
    "title": "Part 0: R for beginner",
    "section": "3.1 Expression",
    "text": "3.1 Expression\nAn expression is directly evaluated and the result is displayed on terminal Example :\n\n2 + 3\n\n[1] 5\n\nsqrt(25)\n\n[1] 5"
  },
  {
    "objectID": "practicals/rforbeginer.html#affectation-in-an-object",
    "href": "practicals/rforbeginer.html#affectation-in-an-object",
    "title": "Part 0: R for beginner",
    "section": "3.2 Affectation in an object",
    "text": "3.2 Affectation in an object\nAn assignment is an expression stored in object or variable. In this example expression, constant, array, matrix, data frame, list Example :\n\na &lt;- 2 + 3\nb &lt;- \"madame\"\n\n What happens when you execute this cell?\n\na\n\n[1] 5\n\nb\n\n[1] \"madame\"\n\n\n\na &lt;- 10\nb &lt;- \"5\"\n\n\nsomme &lt;- a + b\n\n Why do we have an error ? I need to know the type of the object\n\nstr(a)\n\n num 10\n\nstr(b)\n\n chr \"5\"\n\n\n What kind of information do we get?\nWe can also perform mathematical operations on numerical objects.\n\nlog(a) # to obtain the logarithm of a\n\n[1] 2.302585\n\nsqrt(a)# to obtain the square root of a\n\n[1] 3.162278\n\n\n\n# we can compare it\nlog(a) &gt; sqrt(a)\n\n[1] FALSE"
  },
  {
    "objectID": "practicals/rforbeginer.html#type-of-objects",
    "href": "practicals/rforbeginer.html#type-of-objects",
    "title": "Part 0: R for beginner",
    "section": "3.3 Type of objects",
    "text": "3.3 Type of objects\n\n3.3.1 Vectors\nVectors are objects composed by values with the same type or (i.e, numeric, characters…)\n\nV1 &lt;- c(2, 6, 9) # numeric vector\nV2 &lt;- c(\"monday\", \"Tuesday\", \"Wednesday\") # character vector\nV3 &lt;- rep(6, 3) # repetition of the same value\nV4 &lt;- seq(1, 3, 0.1)# sequence of number\nV5 &lt;- 1:100\nV5\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\n\nTo know the number of value inside a vector\n\nlength(V1)\n\n[1] 3\n\n\nWhat do you think about V4?\nFilter a vector according to criteria\n\n# Example : with list of value (a vector)\n\nx &lt;- c(1, 3, 5, 3, 2, 1, 4, 6, 4, 7, 5, 4, 3)\n\n# get element from 2 to 6\n\nx[2:6]\n\n[1] 3 5 3 2 1\n\n# get elements 3 et 5 from x.\n\nx[c(3, 5)]\n\n[1] 5 2\n\n# get value more than 20.\n\nx[x &gt; 5]\n\n[1] 6 7\n\n# get value of  x where x is equal to 21.\n\nx[x == 5]\n\n[1] 5 5\n\n# return elements form x the the value different from 5\n\nx[x != 5]\n\n [1] 1 3 3 2 1 4 6 4 7 4 3\n\n\nFilter a vector according to several criteria\n\n# 3 lists : ages, sexes et poids\n\nage &lt;- c(20, 30, 40,\n         15, 22, 24,\n         36, 38)\n\nsexe &lt;- c(\"F\", \"M\", \"F\",\n          \"M\", \"F\", \"M\",\n          \"F\", \"M\")\n\npoids &lt;- c(75, 76, 73,\n           72, 64, 76,\n           73, 72)\n\n# get value from age greater than 20 and less than 30.\n\nage[age &gt; 20 & age &lt; 30]\n\n[1] 22 24\n\n# Recovering \"poids\" for those who are older than 25 and female\n\npoids[age &gt; 25 & sexe == \"F\"]\n\n[1] 73 73\n\n#Retrieve age values below 20 or above 30.\n\nage[age &lt; 20 | age &gt; 30]\n\n[1] 40 15 36 38\n\n\nExo1\nConsidering the vector a such as a &lt;- c(\"lannister\", \"targaryen\", \"baratheon\", \"starck\", \"greyjoy\")\n\nWhat is the length of the vector?\nTry doing a[1:3]. What do you get?\nCreate a new vector b containing only lannister and starck.\nTry doing a[-1]. What do you get?\nSort by alphabetical order using sort()\n\nExo2\n\nCreate a vector a containing all integers from 1 to 100.\nAdd the values 200, 201, 202 to the vector a.\nCreate a vector b containing all even integers from 2 to 100 using seq()\n\n\n\n3.3.2 Data frames\nData frames are objects composed by vector where the value are of different modes (i.e, numeric, characters…)\n\n3.3.2.1 Data frame examples\nLoad a data frame\n\ndata(iris)\n\nVisualise the data frame in a table\n\nView(iris)\n\nDisplay its internal structure\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nWhat can we notice?\n\n\n3.3.2.2 How to build your own data frame\n\ndate &lt;- c(\"1_monday\", \"2_Tuesday\", \"3_Wednesday\",\n          \"4_Thursday\", \"5_Friday\", \"6_Sturday\",\n          \"7_Sunday\")\n\nis.character(date)\n\n[1] TRUE\n\n# temperature in deg Celsius\ntemperature &lt;- c(24, 27, 25,\n               22, 30, 21,\n               28)\n\nis.numeric(temperature)\n\n[1] TRUE\n\n# rain in mm\nrain &lt;- c(1, 0, 0,\n          5, 2, 0,\n          0)\n\nis.numeric(rain)\n\n[1] TRUE\n\n# make data.frame\ndf &lt;- data.frame(date, temperature, rain)\nstr(df)\n\n'data.frame':   7 obs. of  3 variables:\n $ date       : chr  \"1_monday\" \"2_Tuesday\" \"3_Wednesday\" \"4_Thursday\" ...\n $ temperature: num  24 27 25 22 30 21 28\n $ rain       : num  1 0 0 5 2 0 0\n\n#To select a column or vector\ndf$temperature\n\n[1] 24 27 25 22 30 21 28\n\ndf[, 2]\n\n[1] 24 27 25 22 30 21 28\n\n# here we use list() instead of c()\n# because there is multiple class in inside row\n\nday &lt;- list(\"8_monday\", 29, 1)\nnew_def &lt;- rbind(df, day)# add row to a data frame\nnew_def\n\n         date temperature rain\n1    1_monday          24    1\n2   2_Tuesday          27    0\n3 3_Wednesday          25    0\n4  4_Thursday          22    5\n5    5_Friday          30    2\n6   6_Sturday          21    0\n7    7_Sunday          28    0\n8    8_monday          29    1"
  },
  {
    "objectID": "practicals/rforbeginer.html#definition",
    "href": "practicals/rforbeginer.html#definition",
    "title": "Part 0: R for beginner",
    "section": "4.1 Definition",
    "text": "4.1 Definition\nFunction are a compilation of command line with different instructions inside one object to simplify code. A function is composed by arguments and options.\nfunction(argument1, argument2, option1, … ,option10)"
  },
  {
    "objectID": "practicals/rforbeginer.html#usual-functions-for-data-frame",
    "href": "practicals/rforbeginer.html#usual-functions-for-data-frame",
    "title": "Part 0: R for beginner",
    "section": "4.2 Usual functions for data frame",
    "text": "4.2 Usual functions for data frame\n\nhead() # to know first line of your data frame\nclass()# return the class of the object. Ex : data.frame, matrix, list ....\nstr()# return the structure of the object. Ex : numeric, factor, character....\nnames()# to get or set the names of an object\nsum() # for addition\nmin() # return the minimum of the vector\nmax() # return the minimum of the vector\nrow.names() # attribute names for lines of the data frame\ncolnames() # attribute names for column of the data frame\napply() # Returns a vector or array or list of values obtained by applying a function to margins of an array or matrix.\n\nExample function row.names, class and str\n\ndf2 &lt;- data.frame(x = c(TRUE, FALSE, NA, NA), y = c(12, 34, 56, 78))\ndf2\n\n      x  y\n1  TRUE 12\n2 FALSE 34\n3    NA 56\n4    NA 78\n\nrow.names(df2) &lt;- paste(\"row\", 1 : 4, sep = \"_\")\ndf2 # what do you see\n\n          x  y\nrow_1  TRUE 12\nrow_2 FALSE 34\nrow_3    NA 56\nrow_4    NA 78\n\nclass(df2)\n\n[1] \"data.frame\"\n\nstr(df2)\n\n'data.frame':   4 obs. of  2 variables:\n $ x: logi  TRUE FALSE NA NA\n $ y: num  12 34 56 78\n\n\nExample function apply\n\nhead(df)\n\n         date temperature rain\n1    1_monday          24    1\n2   2_Tuesday          27    0\n3 3_Wednesday          25    0\n4  4_Thursday          22    5\n5    5_Friday          30    2\n6   6_Sturday          21    0\n\nclass(df)\n\n[1] \"data.frame\"\n\nstr(df)\n\n'data.frame':   7 obs. of  3 variables:\n $ date       : chr  \"1_monday\" \"2_Tuesday\" \"3_Wednesday\" \"4_Thursday\" ...\n $ temperature: num  24 27 25 22 30 21 28\n $ rain       : num  1 0 0 5 2 0 0\n\n# return mean for the numerical column of the data.frame. apply(data,margin,fun). \n# For margin parameter the value 1 return mean for each row, \n# for margin=2 return mean for each selected column.\napply(df[, 2:3], 2, mean)\n\ntemperature        rain \n  25.285714    1.142857 \n\n\nExo 3\nFrom data set iris in package datasets** Load package datasets and load data set iris using data()\n\nGive the class Sepal.Width and Species vectors\nWhat is the minimum / maximum / average sepal length of these irises?\nWhat are the values of the first 10 irises?\nCalculate standard deviation for every numeric vector (function : sd())\nCalculate mean for every numeric vector\nCreate a data frame with mean and sd as line and give a name for each line\nAn error of 0.5cm was made in the measurement of the length of the sepal of the 41st iris: add 0.5cm to this measurement"
  },
  {
    "objectID": "practicals/rforbeginer.html#use-dplyr-to-select-filter-a-data-frame",
    "href": "practicals/rforbeginer.html#use-dplyr-to-select-filter-a-data-frame",
    "title": "Part 0: R for beginner",
    "section": "4.3 Use dplyr to select, filter a data frame",
    "text": "4.3 Use dplyr to select, filter a data frame\ndplyr is part of the library set named tidyverse (contraction of “tidy” and “universe”, it’s a tidy universe). tidyverse packages are designed to work together and thus follow the same code logic and a common grammar.\nThe pipe, %&gt;%, is one of the useful elements of the tidyverse. It allows to structure sequences of operations by minimizing the creation of intermediate objects and by facilitating the addition of a step anywhere in this sequence. Note that from R 4.1 you can use a new pipe, |&gt; without the need of loading any library.\nThe most commonly used tidyverse packages are loaded in your session:\n\nggplot2\ndplyr\ntidyr\nreadr\ntibble\nstringr\n\n\ntidyverse::tidyverse_packages()\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\n\n4.3.0.1 Filter and select variable in data frame\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndata(\"iris\")\n#To select a variable with tidyverse\ndplyr::select(iris, Species)\n\n       Species\n1       setosa\n2       setosa\n3       setosa\n4       setosa\n5       setosa\n6       setosa\n7       setosa\n8       setosa\n9       setosa\n10      setosa\n11      setosa\n12      setosa\n13      setosa\n14      setosa\n15      setosa\n16      setosa\n17      setosa\n18      setosa\n19      setosa\n20      setosa\n21      setosa\n22      setosa\n23      setosa\n24      setosa\n25      setosa\n26      setosa\n27      setosa\n28      setosa\n29      setosa\n30      setosa\n31      setosa\n32      setosa\n33      setosa\n34      setosa\n35      setosa\n36      setosa\n37      setosa\n38      setosa\n39      setosa\n40      setosa\n41      setosa\n42      setosa\n43      setosa\n44      setosa\n45      setosa\n46      setosa\n47      setosa\n48      setosa\n49      setosa\n50      setosa\n51  versicolor\n52  versicolor\n53  versicolor\n54  versicolor\n55  versicolor\n56  versicolor\n57  versicolor\n58  versicolor\n59  versicolor\n60  versicolor\n61  versicolor\n62  versicolor\n63  versicolor\n64  versicolor\n65  versicolor\n66  versicolor\n67  versicolor\n68  versicolor\n69  versicolor\n70  versicolor\n71  versicolor\n72  versicolor\n73  versicolor\n74  versicolor\n75  versicolor\n76  versicolor\n77  versicolor\n78  versicolor\n79  versicolor\n80  versicolor\n81  versicolor\n82  versicolor\n83  versicolor\n84  versicolor\n85  versicolor\n86  versicolor\n87  versicolor\n88  versicolor\n89  versicolor\n90  versicolor\n91  versicolor\n92  versicolor\n93  versicolor\n94  versicolor\n95  versicolor\n96  versicolor\n97  versicolor\n98  versicolor\n99  versicolor\n100 versicolor\n101  virginica\n102  virginica\n103  virginica\n104  virginica\n105  virginica\n106  virginica\n107  virginica\n108  virginica\n109  virginica\n110  virginica\n111  virginica\n112  virginica\n113  virginica\n114  virginica\n115  virginica\n116  virginica\n117  virginica\n118  virginica\n119  virginica\n120  virginica\n121  virginica\n122  virginica\n123  virginica\n124  virginica\n125  virginica\n126  virginica\n127  virginica\n128  virginica\n129  virginica\n130  virginica\n131  virginica\n132  virginica\n133  virginica\n134  virginica\n135  virginica\n136  virginica\n137  virginica\n138  virginica\n139  virginica\n140  virginica\n141  virginica\n142  virginica\n143  virginica\n144  virginica\n145  virginica\n146  virginica\n147  virginica\n148  virginica\n149  virginica\n150  virginica\n\n\n\n#To select several variables with tidyverse\ndplyr::select(iris,Species, Sepal.Length, Sepal.Width)\n\n       Species Sepal.Length Sepal.Width\n1       setosa          5.1         3.5\n2       setosa          4.9         3.0\n3       setosa          4.7         3.2\n4       setosa          4.6         3.1\n5       setosa          5.0         3.6\n6       setosa          5.4         3.9\n7       setosa          4.6         3.4\n8       setosa          5.0         3.4\n9       setosa          4.4         2.9\n10      setosa          4.9         3.1\n11      setosa          5.4         3.7\n12      setosa          4.8         3.4\n13      setosa          4.8         3.0\n14      setosa          4.3         3.0\n15      setosa          5.8         4.0\n16      setosa          5.7         4.4\n17      setosa          5.4         3.9\n18      setosa          5.1         3.5\n19      setosa          5.7         3.8\n20      setosa          5.1         3.8\n21      setosa          5.4         3.4\n22      setosa          5.1         3.7\n23      setosa          4.6         3.6\n24      setosa          5.1         3.3\n25      setosa          4.8         3.4\n26      setosa          5.0         3.0\n27      setosa          5.0         3.4\n28      setosa          5.2         3.5\n29      setosa          5.2         3.4\n30      setosa          4.7         3.2\n31      setosa          4.8         3.1\n32      setosa          5.4         3.4\n33      setosa          5.2         4.1\n34      setosa          5.5         4.2\n35      setosa          4.9         3.1\n36      setosa          5.0         3.2\n37      setosa          5.5         3.5\n38      setosa          4.9         3.6\n39      setosa          4.4         3.0\n40      setosa          5.1         3.4\n41      setosa          5.0         3.5\n42      setosa          4.5         2.3\n43      setosa          4.4         3.2\n44      setosa          5.0         3.5\n45      setosa          5.1         3.8\n46      setosa          4.8         3.0\n47      setosa          5.1         3.8\n48      setosa          4.6         3.2\n49      setosa          5.3         3.7\n50      setosa          5.0         3.3\n51  versicolor          7.0         3.2\n52  versicolor          6.4         3.2\n53  versicolor          6.9         3.1\n54  versicolor          5.5         2.3\n55  versicolor          6.5         2.8\n56  versicolor          5.7         2.8\n57  versicolor          6.3         3.3\n58  versicolor          4.9         2.4\n59  versicolor          6.6         2.9\n60  versicolor          5.2         2.7\n61  versicolor          5.0         2.0\n62  versicolor          5.9         3.0\n63  versicolor          6.0         2.2\n64  versicolor          6.1         2.9\n65  versicolor          5.6         2.9\n66  versicolor          6.7         3.1\n67  versicolor          5.6         3.0\n68  versicolor          5.8         2.7\n69  versicolor          6.2         2.2\n70  versicolor          5.6         2.5\n71  versicolor          5.9         3.2\n72  versicolor          6.1         2.8\n73  versicolor          6.3         2.5\n74  versicolor          6.1         2.8\n75  versicolor          6.4         2.9\n76  versicolor          6.6         3.0\n77  versicolor          6.8         2.8\n78  versicolor          6.7         3.0\n79  versicolor          6.0         2.9\n80  versicolor          5.7         2.6\n81  versicolor          5.5         2.4\n82  versicolor          5.5         2.4\n83  versicolor          5.8         2.7\n84  versicolor          6.0         2.7\n85  versicolor          5.4         3.0\n86  versicolor          6.0         3.4\n87  versicolor          6.7         3.1\n88  versicolor          6.3         2.3\n89  versicolor          5.6         3.0\n90  versicolor          5.5         2.5\n91  versicolor          5.5         2.6\n92  versicolor          6.1         3.0\n93  versicolor          5.8         2.6\n94  versicolor          5.0         2.3\n95  versicolor          5.6         2.7\n96  versicolor          5.7         3.0\n97  versicolor          5.7         2.9\n98  versicolor          6.2         2.9\n99  versicolor          5.1         2.5\n100 versicolor          5.7         2.8\n101  virginica          6.3         3.3\n102  virginica          5.8         2.7\n103  virginica          7.1         3.0\n104  virginica          6.3         2.9\n105  virginica          6.5         3.0\n106  virginica          7.6         3.0\n107  virginica          4.9         2.5\n108  virginica          7.3         2.9\n109  virginica          6.7         2.5\n110  virginica          7.2         3.6\n111  virginica          6.5         3.2\n112  virginica          6.4         2.7\n113  virginica          6.8         3.0\n114  virginica          5.7         2.5\n115  virginica          5.8         2.8\n116  virginica          6.4         3.2\n117  virginica          6.5         3.0\n118  virginica          7.7         3.8\n119  virginica          7.7         2.6\n120  virginica          6.0         2.2\n121  virginica          6.9         3.2\n122  virginica          5.6         2.8\n123  virginica          7.7         2.8\n124  virginica          6.3         2.7\n125  virginica          6.7         3.3\n126  virginica          7.2         3.2\n127  virginica          6.2         2.8\n128  virginica          6.1         3.0\n129  virginica          6.4         2.8\n130  virginica          7.2         3.0\n131  virginica          7.4         2.8\n132  virginica          7.9         3.8\n133  virginica          6.4         2.8\n134  virginica          6.3         2.8\n135  virginica          6.1         2.6\n136  virginica          7.7         3.0\n137  virginica          6.3         3.4\n138  virginica          6.4         3.1\n139  virginica          6.0         3.0\n140  virginica          6.9         3.1\n141  virginica          6.7         3.1\n142  virginica          6.9         3.1\n143  virginica          5.8         2.7\n144  virginica          6.8         3.2\n145  virginica          6.7         3.3\n146  virginica          6.7         3.0\n147  virginica          6.3         2.5\n148  virginica          6.5         3.0\n149  virginica          6.2         3.4\n150  virginica          5.9         3.0\n\n# To select several lines inside data frame\ndplyr::slice(iris, 22:30)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.7          1.5         0.4  setosa\n2          4.6         3.6          1.0         0.2  setosa\n3          5.1         3.3          1.7         0.5  setosa\n4          4.8         3.4          1.9         0.2  setosa\n5          5.0         3.0          1.6         0.2  setosa\n6          5.0         3.4          1.6         0.4  setosa\n7          5.2         3.5          1.5         0.2  setosa\n8          5.2         3.4          1.4         0.2  setosa\n9          4.7         3.2          1.6         0.2  setosa\n\n# I can affect it to an object\n\nsubdata &lt;- dplyr::slice(iris, 22:30)\n\n#or choosing different lines\nmyline &lt;- c(22, 38, 120) # I build a vector containing the line that I want\ndplyr::slice(iris,myline)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1          5.1         3.7          1.5         0.4    setosa\n2          4.9         3.6          1.4         0.1    setosa\n3          6.0         2.2          5.0         1.5 virginica\n\n\n\n\n4.3.0.2 Bonus : to pipe many function serval function together\nThe pipe  |&gt; , or %&gt;%, is one of the useful elements of the tidyverse. It allows to structure sequences of operations by minimizing the creation of intermediate objects and by facilitating the addition of a step anywhere in this sequence.\nThe useful command to manage data frame : 1) select() to select vector or variable from a data frame ; 2) filter() is used to subset a data frame, retaining all rows that satisfy your conditions ; mutate() adds new variables and preserves existing ones.\n\nlibrary(dplyr)\n\niris %&gt;%\n  filter(Sepal.Length &gt; 6) %&gt;% # filtered using size of Sepal Length\n  filter(Species == \"versicolor\") # and the species\n\n   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1           7.0         3.2          4.7         1.4 versicolor\n2           6.4         3.2          4.5         1.5 versicolor\n3           6.9         3.1          4.9         1.5 versicolor\n4           6.5         2.8          4.6         1.5 versicolor\n5           6.3         3.3          4.7         1.6 versicolor\n6           6.6         2.9          4.6         1.3 versicolor\n7           6.1         2.9          4.7         1.4 versicolor\n8           6.7         3.1          4.4         1.4 versicolor\n9           6.2         2.2          4.5         1.5 versicolor\n10          6.1         2.8          4.0         1.3 versicolor\n11          6.3         2.5          4.9         1.5 versicolor\n12          6.1         2.8          4.7         1.2 versicolor\n13          6.4         2.9          4.3         1.3 versicolor\n14          6.6         3.0          4.4         1.4 versicolor\n15          6.8         2.8          4.8         1.4 versicolor\n16          6.7         3.0          5.0         1.7 versicolor\n17          6.7         3.1          4.7         1.5 versicolor\n18          6.3         2.3          4.4         1.3 versicolor\n19          6.1         3.0          4.6         1.4 versicolor\n20          6.2         2.9          4.3         1.3 versicolor\n\n\n\niris %&gt;%\n  select(Sepal.Length, Species) %&gt;%\n  mutate(Sepal.Length2 = Sepal.Length * 2) %&gt;%\n  mutate(Sepal.Length2_squared = Sepal.Length2 * Sepal.Length2)\n\n    Sepal.Length    Species Sepal.Length2 Sepal.Length2_squared\n1            5.1     setosa          10.2                104.04\n2            4.9     setosa           9.8                 96.04\n3            4.7     setosa           9.4                 88.36\n4            4.6     setosa           9.2                 84.64\n5            5.0     setosa          10.0                100.00\n6            5.4     setosa          10.8                116.64\n7            4.6     setosa           9.2                 84.64\n8            5.0     setosa          10.0                100.00\n9            4.4     setosa           8.8                 77.44\n10           4.9     setosa           9.8                 96.04\n11           5.4     setosa          10.8                116.64\n12           4.8     setosa           9.6                 92.16\n13           4.8     setosa           9.6                 92.16\n14           4.3     setosa           8.6                 73.96\n15           5.8     setosa          11.6                134.56\n16           5.7     setosa          11.4                129.96\n17           5.4     setosa          10.8                116.64\n18           5.1     setosa          10.2                104.04\n19           5.7     setosa          11.4                129.96\n20           5.1     setosa          10.2                104.04\n21           5.4     setosa          10.8                116.64\n22           5.1     setosa          10.2                104.04\n23           4.6     setosa           9.2                 84.64\n24           5.1     setosa          10.2                104.04\n25           4.8     setosa           9.6                 92.16\n26           5.0     setosa          10.0                100.00\n27           5.0     setosa          10.0                100.00\n28           5.2     setosa          10.4                108.16\n29           5.2     setosa          10.4                108.16\n30           4.7     setosa           9.4                 88.36\n31           4.8     setosa           9.6                 92.16\n32           5.4     setosa          10.8                116.64\n33           5.2     setosa          10.4                108.16\n34           5.5     setosa          11.0                121.00\n35           4.9     setosa           9.8                 96.04\n36           5.0     setosa          10.0                100.00\n37           5.5     setosa          11.0                121.00\n38           4.9     setosa           9.8                 96.04\n39           4.4     setosa           8.8                 77.44\n40           5.1     setosa          10.2                104.04\n41           5.0     setosa          10.0                100.00\n42           4.5     setosa           9.0                 81.00\n43           4.4     setosa           8.8                 77.44\n44           5.0     setosa          10.0                100.00\n45           5.1     setosa          10.2                104.04\n46           4.8     setosa           9.6                 92.16\n47           5.1     setosa          10.2                104.04\n48           4.6     setosa           9.2                 84.64\n49           5.3     setosa          10.6                112.36\n50           5.0     setosa          10.0                100.00\n51           7.0 versicolor          14.0                196.00\n52           6.4 versicolor          12.8                163.84\n53           6.9 versicolor          13.8                190.44\n54           5.5 versicolor          11.0                121.00\n55           6.5 versicolor          13.0                169.00\n56           5.7 versicolor          11.4                129.96\n57           6.3 versicolor          12.6                158.76\n58           4.9 versicolor           9.8                 96.04\n59           6.6 versicolor          13.2                174.24\n60           5.2 versicolor          10.4                108.16\n61           5.0 versicolor          10.0                100.00\n62           5.9 versicolor          11.8                139.24\n63           6.0 versicolor          12.0                144.00\n64           6.1 versicolor          12.2                148.84\n65           5.6 versicolor          11.2                125.44\n66           6.7 versicolor          13.4                179.56\n67           5.6 versicolor          11.2                125.44\n68           5.8 versicolor          11.6                134.56\n69           6.2 versicolor          12.4                153.76\n70           5.6 versicolor          11.2                125.44\n71           5.9 versicolor          11.8                139.24\n72           6.1 versicolor          12.2                148.84\n73           6.3 versicolor          12.6                158.76\n74           6.1 versicolor          12.2                148.84\n75           6.4 versicolor          12.8                163.84\n76           6.6 versicolor          13.2                174.24\n77           6.8 versicolor          13.6                184.96\n78           6.7 versicolor          13.4                179.56\n79           6.0 versicolor          12.0                144.00\n80           5.7 versicolor          11.4                129.96\n81           5.5 versicolor          11.0                121.00\n82           5.5 versicolor          11.0                121.00\n83           5.8 versicolor          11.6                134.56\n84           6.0 versicolor          12.0                144.00\n85           5.4 versicolor          10.8                116.64\n86           6.0 versicolor          12.0                144.00\n87           6.7 versicolor          13.4                179.56\n88           6.3 versicolor          12.6                158.76\n89           5.6 versicolor          11.2                125.44\n90           5.5 versicolor          11.0                121.00\n91           5.5 versicolor          11.0                121.00\n92           6.1 versicolor          12.2                148.84\n93           5.8 versicolor          11.6                134.56\n94           5.0 versicolor          10.0                100.00\n95           5.6 versicolor          11.2                125.44\n96           5.7 versicolor          11.4                129.96\n97           5.7 versicolor          11.4                129.96\n98           6.2 versicolor          12.4                153.76\n99           5.1 versicolor          10.2                104.04\n100          5.7 versicolor          11.4                129.96\n101          6.3  virginica          12.6                158.76\n102          5.8  virginica          11.6                134.56\n103          7.1  virginica          14.2                201.64\n104          6.3  virginica          12.6                158.76\n105          6.5  virginica          13.0                169.00\n106          7.6  virginica          15.2                231.04\n107          4.9  virginica           9.8                 96.04\n108          7.3  virginica          14.6                213.16\n109          6.7  virginica          13.4                179.56\n110          7.2  virginica          14.4                207.36\n111          6.5  virginica          13.0                169.00\n112          6.4  virginica          12.8                163.84\n113          6.8  virginica          13.6                184.96\n114          5.7  virginica          11.4                129.96\n115          5.8  virginica          11.6                134.56\n116          6.4  virginica          12.8                163.84\n117          6.5  virginica          13.0                169.00\n118          7.7  virginica          15.4                237.16\n119          7.7  virginica          15.4                237.16\n120          6.0  virginica          12.0                144.00\n121          6.9  virginica          13.8                190.44\n122          5.6  virginica          11.2                125.44\n123          7.7  virginica          15.4                237.16\n124          6.3  virginica          12.6                158.76\n125          6.7  virginica          13.4                179.56\n126          7.2  virginica          14.4                207.36\n127          6.2  virginica          12.4                153.76\n128          6.1  virginica          12.2                148.84\n129          6.4  virginica          12.8                163.84\n130          7.2  virginica          14.4                207.36\n131          7.4  virginica          14.8                219.04\n132          7.9  virginica          15.8                249.64\n133          6.4  virginica          12.8                163.84\n134          6.3  virginica          12.6                158.76\n135          6.1  virginica          12.2                148.84\n136          7.7  virginica          15.4                237.16\n137          6.3  virginica          12.6                158.76\n138          6.4  virginica          12.8                163.84\n139          6.0  virginica          12.0                144.00\n140          6.9  virginica          13.8                190.44\n141          6.7  virginica          13.4                179.56\n142          6.9  virginica          13.8                190.44\n143          5.8  virginica          11.6                134.56\n144          6.8  virginica          13.6                184.96\n145          6.7  virginica          13.4                179.56\n146          6.7  virginica          13.4                179.56\n147          6.3  virginica          12.6                158.76\n148          6.5  virginica          13.0                169.00\n149          6.2  virginica          12.4                153.76\n150          5.9  virginica          11.8                139.24\n\niris %&gt;%\n  select(Sepal.Length, Species) %&gt;%\n  mutate(Sepal.Length = Sepal.Length / mean(Sepal.Length, na.rm = TRUE))\n\n    Sepal.Length    Species\n1      0.8727895     setosa\n2      0.8385625     setosa\n3      0.8043354     setosa\n4      0.7872219     setosa\n5      0.8556760     setosa\n6      0.9241301     setosa\n7      0.7872219     setosa\n8      0.8556760     setosa\n9      0.7529949     setosa\n10     0.8385625     setosa\n11     0.9241301     setosa\n12     0.8214489     setosa\n13     0.8214489     setosa\n14     0.7358813     setosa\n15     0.9925841     setosa\n16     0.9754706     setosa\n17     0.9241301     setosa\n18     0.8727895     setosa\n19     0.9754706     setosa\n20     0.8727895     setosa\n21     0.9241301     setosa\n22     0.8727895     setosa\n23     0.7872219     setosa\n24     0.8727895     setosa\n25     0.8214489     setosa\n26     0.8556760     setosa\n27     0.8556760     setosa\n28     0.8899030     setosa\n29     0.8899030     setosa\n30     0.8043354     setosa\n31     0.8214489     setosa\n32     0.9241301     setosa\n33     0.8899030     setosa\n34     0.9412436     setosa\n35     0.8385625     setosa\n36     0.8556760     setosa\n37     0.9412436     setosa\n38     0.8385625     setosa\n39     0.7529949     setosa\n40     0.8727895     setosa\n41     0.8556760     setosa\n42     0.7701084     setosa\n43     0.7529949     setosa\n44     0.8556760     setosa\n45     0.8727895     setosa\n46     0.8214489     setosa\n47     0.8727895     setosa\n48     0.7872219     setosa\n49     0.9070165     setosa\n50     0.8556760     setosa\n51     1.1979464 versicolor\n52     1.0952653 versicolor\n53     1.1808329 versicolor\n54     0.9412436 versicolor\n55     1.1123788 versicolor\n56     0.9754706 versicolor\n57     1.0781517 versicolor\n58     0.8385625 versicolor\n59     1.1294923 versicolor\n60     0.8899030 versicolor\n61     0.8556760 versicolor\n62     1.0096977 versicolor\n63     1.0268112 versicolor\n64     1.0439247 versicolor\n65     0.9583571 versicolor\n66     1.1466058 versicolor\n67     0.9583571 versicolor\n68     0.9925841 versicolor\n69     1.0610382 versicolor\n70     0.9583571 versicolor\n71     1.0096977 versicolor\n72     1.0439247 versicolor\n73     1.0781517 versicolor\n74     1.0439247 versicolor\n75     1.0952653 versicolor\n76     1.1294923 versicolor\n77     1.1637193 versicolor\n78     1.1466058 versicolor\n79     1.0268112 versicolor\n80     0.9754706 versicolor\n81     0.9412436 versicolor\n82     0.9412436 versicolor\n83     0.9925841 versicolor\n84     1.0268112 versicolor\n85     0.9241301 versicolor\n86     1.0268112 versicolor\n87     1.1466058 versicolor\n88     1.0781517 versicolor\n89     0.9583571 versicolor\n90     0.9412436 versicolor\n91     0.9412436 versicolor\n92     1.0439247 versicolor\n93     0.9925841 versicolor\n94     0.8556760 versicolor\n95     0.9583571 versicolor\n96     0.9754706 versicolor\n97     0.9754706 versicolor\n98     1.0610382 versicolor\n99     0.8727895 versicolor\n100    0.9754706 versicolor\n101    1.0781517  virginica\n102    0.9925841  virginica\n103    1.2150599  virginica\n104    1.0781517  virginica\n105    1.1123788  virginica\n106    1.3006275  virginica\n107    0.8385625  virginica\n108    1.2492869  virginica\n109    1.1466058  virginica\n110    1.2321734  virginica\n111    1.1123788  virginica\n112    1.0952653  virginica\n113    1.1637193  virginica\n114    0.9754706  virginica\n115    0.9925841  virginica\n116    1.0952653  virginica\n117    1.1123788  virginica\n118    1.3177410  virginica\n119    1.3177410  virginica\n120    1.0268112  virginica\n121    1.1808329  virginica\n122    0.9583571  virginica\n123    1.3177410  virginica\n124    1.0781517  virginica\n125    1.1466058  virginica\n126    1.2321734  virginica\n127    1.0610382  virginica\n128    1.0439247  virginica\n129    1.0952653  virginica\n130    1.2321734  virginica\n131    1.2664005  virginica\n132    1.3519681  virginica\n133    1.0952653  virginica\n134    1.0781517  virginica\n135    1.0439247  virginica\n136    1.3177410  virginica\n137    1.0781517  virginica\n138    1.0952653  virginica\n139    1.0268112  virginica\n140    1.1808329  virginica\n141    1.1466058  virginica\n142    1.1808329  virginica\n143    0.9925841  virginica\n144    1.1637193  virginica\n145    1.1466058  virginica\n146    1.1466058  virginica\n147    1.0781517  virginica\n148    1.1123788  virginica\n149    1.0610382  virginica\n150    1.0096977  virginica\n\n#Sepal.Length_norm is calculated using the mean of the Sepal.Length for all data set.\n\niris %&gt;%\n  select(Sepal.Length, Species) %&gt;%\n  group_by(Species) %&gt;%\n  mutate(Sepal.Length_norm = Sepal.Length / mean(Sepal.Length, na.rm = TRUE))\n\n# A tibble: 150 × 3\n# Groups:   Species [3]\n   Sepal.Length Species Sepal.Length_norm\n          &lt;dbl&gt; &lt;fct&gt;               &lt;dbl&gt;\n 1          5.1 setosa              1.02 \n 2          4.9 setosa              0.979\n 3          4.7 setosa              0.939\n 4          4.6 setosa              0.919\n 5          5   setosa              0.999\n 6          5.4 setosa              1.08 \n 7          4.6 setosa              0.919\n 8          5   setosa              0.999\n 9          4.4 setosa              0.879\n10          4.9 setosa              0.979\n# ℹ 140 more rows\n\n# In this last example Sepal.Length_norm is calculated using the mean of the Sepal.Length for each species using group_by()\n\n These commands are non-persistent, no changes are made on the original iris data frame. If you want to store it, you must assign your changes to a object\n\niris_modif &lt;- iris %&gt;%\n  select(Sepal.Length, Species) %&gt;%\n  group_by(Species) %&gt;%\n  mutate(Sepal.Length_norm = Sepal.Length / mean(Sepal.Length, na.rm = TRUE))\n\n\n\n4.3.1 How to import external data frame issue from .txt or .csv\nTo import data set, the function read.table() or read.csv() are commonly used.\nread.table(file, header = FALSE, sep = \"\", dec = \".\", ...)\nThe main parameter are :\n\nfile : add the pathway and the name of the file\nheader : a logical value (TRUE or FALSE) indicating whether the file contains the names of the variables as its first line.\nsep : the field separator character. Values on each line of the file are separated by this character. If sep = “” (the default for read.table) the separator is ‘white space’, that is one or more spaces, tabs, newlines or carriage returns.\ndec : the character used in the file for decimal points.\n\n\nds &lt;- read.table(here::here(\"data\",\n                            \"rforbeginers\",\n                            \"exemple_read.txt\"),\n                 header = TRUE,\n                 sep = \";\",\n                 dec = \",\")\n\nWhy I use the parameter header=TRUE ?\n\n\n4.3.2 To export data set as .txt to read in excel\nThe function is similar to read.table()\nwrite.table(x, file = \"\", sep = \" \",na = \"NA\", dec = \".\", ... )\n\nx : this is your data.frame\nfile : give a name for your file\nsep : cf read.table\ndec : cf read.table\nna : give a symbole for missing data, by convention is NA\n\n\nwrite.table(ds, \"ds.txt\", sep = \"\\t\", dec = \".\")\n\nTo keep our working directory tidy, we now delete ds.txt\n\nfile.remove(\"ds.txt\")\n\n[1] TRUE\n\n\nExo 4\n\nIn the dataset Iris select Sepal Width, Sepal length and Species,to create a new data frame name “subset_iris”\nSave this new data frame as text file"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html",
    "href": "practicals/preprocessing_dada2.html",
    "title": "Preprocessing : dada2",
    "section": "",
    "text": "To begin with, download the course repository on your computer or virtual machine.\nTo do so, visit the (ANF-metabarcoding) repository on github and download it as a zip file.\nYou can also download the repository directly from the terminal using this commmand:\nwget https://github.com/ANF-MetaBioDiv/course-material/archive/refs/heads/main.zip\nOnce on your machine, unzip the file and go to the resulting folder or place the resulting folder in the most convenient location (setwd(\"~/course-material-main\") for example).\n\n💡 Tip: Work within an RStudio project. Open your course-material-main folder as an RStudio project (create or use a .Rproj file inside it). Then here::here(“data”, “refdb”) will correctly point to /home/rstudio/Documents/course-material-main/data/refdb.\n\n\n\n\nSave as a variable the path to the folder where you will place the references databases.\n\nrefdb_folder &lt;- here::here(\"data\", \"refdb\")\nrefdb_folder\n\n[1] \"/home/rstudio/mydatalocal/course-material/data/refdb\"\n\n\nIn this course we use as much as possible the :: operator. It allows calling a function from a given package without having to load the entire package using library(package). This way it is clear where the functions come from. In that case, the function here() comes from the package here.\nThe reason why we use here::here() is that when you render a Rmarkdown file, the working directory is where the Rmarkdown file is:\n\ngetwd()\n\nWhereas here::here() point to the root of the R project\n\nhere::here()\n\nNow, let’s create the folder directly from R:\n\nif (!dir.exists(refdb_folder)) dir.create(refdb_folder, recursive = TRUE)\n\nYou can also create the folder from RStudio in the Files window\n\n💡 Tip: You can access the documentation of any R function using ? in the console. If you to know everything about the function dir.create(), simply run ?dir.create()\n\nThe Silva reference database, commonly used to assign 16S metabarcoding data, will be used in practical.\nIn case you are working with 18S sequences, you will have better assignments using PR2 or EukRibo especially if you are interested in protists.\nThe following code downloads dada2 formatted silva reference databases. If you are not comfortable with it, you can simply download the reference database files from your web browser here.\n\n# R stop downloading after timeout which is\n# 60 seconds by default\ngetOption(\"timeout\")\n\n[1] 60\n\n# so we change timeout to be 20 minutes\noptions(timeout = 1200)\n\n# we save in variable the path to the refdb\n# in the working space\nsilva_train_set &lt;- \n  file.path(\n    refdb_folder,\n    \"silva_nr99_v138.2_toGenus_trainset.fa.gz\"\n  )\n\nsilva_species_assignment &lt;- \n  file.path(\n    refdb_folder,\n    \"silva_v138.2_assignSpecies.fa.gz\"\n  )\n\n# then we download the files if they don't already exist\n\nif (!file.exists(silva_train_set)) {\n  download.file(\n    \"https://zenodo.org/records/14169026/files/silva_nr99_v138.2_toGenus_trainset.fa.gz\",\n    silva_train_set,\n    quiet = TRUE\n  )\n}\n\nif (!file.exists(silva_species_assignment)) {\n  download.file(\n    \"https://zenodo.org/records/14169026/files/silva_v138.2_assignSpecies.fa.gz\",\n    silva_species_assignment,\n    quiet = TRUE\n  )\n}\n\n\n\n\nWe will use in this practical R functions especially written for this course. The “classic” way to import functions is to use source() with the name of the R script to source.\nInstead, we use devtools::load_all(). This function will source all the scripts from the folder R/ along with the documentation in man/ :\n\ndevtools::load_all()\n\nWarning: Objects listed as exports, but not present in namespace:\n• primer_trim"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#get-the-repository-files",
    "href": "practicals/preprocessing_dada2.html#get-the-repository-files",
    "title": "Preprocessing : dada2",
    "section": "",
    "text": "To begin with, download the course repository on your computer or virtual machine.\nTo do so, visit the (ANF-metabarcoding) repository on github and download it as a zip file.\nYou can also download the repository directly from the terminal using this commmand:\nwget https://github.com/ANF-MetaBioDiv/course-material/archive/refs/heads/main.zip\nOnce on your machine, unzip the file and go to the resulting folder or place the resulting folder in the most convenient location (setwd(\"~/course-material-main\") for example).\n\n💡 Tip: Work within an RStudio project. Open your course-material-main folder as an RStudio project (create or use a .Rproj file inside it). Then here::here(“data”, “refdb”) will correctly point to /home/rstudio/Documents/course-material-main/data/refdb."
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#download-the-reference-database",
    "href": "practicals/preprocessing_dada2.html#download-the-reference-database",
    "title": "Preprocessing : dada2",
    "section": "",
    "text": "Save as a variable the path to the folder where you will place the references databases.\n\nrefdb_folder &lt;- here::here(\"data\", \"refdb\")\nrefdb_folder\n\n[1] \"/home/rstudio/mydatalocal/course-material/data/refdb\"\n\n\nIn this course we use as much as possible the :: operator. It allows calling a function from a given package without having to load the entire package using library(package). This way it is clear where the functions come from. In that case, the function here() comes from the package here.\nThe reason why we use here::here() is that when you render a Rmarkdown file, the working directory is where the Rmarkdown file is:\n\ngetwd()\n\nWhereas here::here() point to the root of the R project\n\nhere::here()\n\nNow, let’s create the folder directly from R:\n\nif (!dir.exists(refdb_folder)) dir.create(refdb_folder, recursive = TRUE)\n\nYou can also create the folder from RStudio in the Files window\n\n💡 Tip: You can access the documentation of any R function using ? in the console. If you to know everything about the function dir.create(), simply run ?dir.create()\n\nThe Silva reference database, commonly used to assign 16S metabarcoding data, will be used in practical.\nIn case you are working with 18S sequences, you will have better assignments using PR2 or EukRibo especially if you are interested in protists.\nThe following code downloads dada2 formatted silva reference databases. If you are not comfortable with it, you can simply download the reference database files from your web browser here.\n\n# R stop downloading after timeout which is\n# 60 seconds by default\ngetOption(\"timeout\")\n\n[1] 60\n\n# so we change timeout to be 20 minutes\noptions(timeout = 1200)\n\n# we save in variable the path to the refdb\n# in the working space\nsilva_train_set &lt;- \n  file.path(\n    refdb_folder,\n    \"silva_nr99_v138.2_toGenus_trainset.fa.gz\"\n  )\n\nsilva_species_assignment &lt;- \n  file.path(\n    refdb_folder,\n    \"silva_v138.2_assignSpecies.fa.gz\"\n  )\n\n# then we download the files if they don't already exist\n\nif (!file.exists(silva_train_set)) {\n  download.file(\n    \"https://zenodo.org/records/14169026/files/silva_nr99_v138.2_toGenus_trainset.fa.gz\",\n    silva_train_set,\n    quiet = TRUE\n  )\n}\n\nif (!file.exists(silva_species_assignment)) {\n  download.file(\n    \"https://zenodo.org/records/14169026/files/silva_v138.2_assignSpecies.fa.gz\",\n    silva_species_assignment,\n    quiet = TRUE\n  )\n}"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#attach-custom-functions",
    "href": "practicals/preprocessing_dada2.html#attach-custom-functions",
    "title": "Preprocessing : dada2",
    "section": "",
    "text": "We will use in this practical R functions especially written for this course. The “classic” way to import functions is to use source() with the name of the R script to source.\nInstead, we use devtools::load_all(). This function will source all the scripts from the folder R/ along with the documentation in man/ :\n\ndevtools::load_all()\n\nWarning: Objects listed as exports, but not present in namespace:\n• primer_trim"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#locate-the-sequencing-files",
    "href": "practicals/preprocessing_dada2.html#locate-the-sequencing-files",
    "title": "Preprocessing : dada2",
    "section": "2.1 Locate the sequencing files",
    "text": "2.1 Locate the sequencing files\nSave the path to the directory containing your raw data (paired-end sequencing fastq files) in a variable named path_to_fastqs.\n\npath_to_fastqs &lt;- here::here(\"data\", \"raw\")\n\nThe gzipped (compressed) FASTQ formatted “forward” (R1) and “reverse” (R2) files are named as follow:\n\n${SAMPLENAME}_R1.fastq.gz for the forward files\n${SAMPLENAME}_R2.fastq.gz for the reverse files.\n\nWe list the forward files using the function list.files(). The argument pattern gives you the possibility to only select file names matching a regular expression. In our case, we select all file names finishing by _R1.fastq.gz.\n\nfnFs &lt;- sort(list.files(path_to_fastqs,\n                        pattern = \"_R1.fastq.gz\",\n                        full.names = TRUE))\n\nWe do the same for reverse samples.\n\nfnRs &lt;- sort(list.files(path_to_fastqs,\n                        pattern = \"_R2.fastq.gz\",\n                        full.names = TRUE))\n\nTo understand: What fnFs & fnRs variables contain?"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#extract-sample-names",
    "href": "practicals/preprocessing_dada2.html#extract-sample-names",
    "title": "Preprocessing : dada2",
    "section": "2.2 Extract sample names",
    "text": "2.2 Extract sample names\n\nsample_names &lt;- basename(fnFs) |&gt;\n  strsplit(split = \"_\") |&gt;\n  sapply(head, 1)\n\nTo understand:\nbasename(): remove path to only keep file name.\n|&gt;: R “pipe”. It allows you to chain functions, avoiding intermediate variables and nested parenthesis. It basically transfers the output of the left expression to the input of the right expression. You need R &gt; 4.1 to use this pipe, otherwise use %&gt;% from magrittr.\nstrsplit(): split character chain according to a defined pattern. ?strsplit for documentation.\nsapply(): apply a function to each element of a list or vector. The output is simplified to be vector.\nLet’s go step by step. First list the R1 file names.\n\nbasename(fnFs) |&gt;\n  head()\n\n[1] \"S11B_R1.fastq.gz\" \"S1B_R1.fastq.gz\"  \"S2B_R1.fastq.gz\"  \"S2S_R1.fastq.gz\" \n[5] \"S3B_R1.fastq.gz\"  \"S3S_R1.fastq.gz\" \n\n\nWe can see that the sample name is before the first _. With strsplit(), we can split each file name into a 2 elements vector. The result is a list of 2 elements vectors.\n\nbasename(fnFs) |&gt;\n  strsplit(split = \"_\") |&gt;\n  head()\n\n[[1]]\n[1] \"S11B\"        \"R1.fastq.gz\"\n\n[[2]]\n[1] \"S1B\"         \"R1.fastq.gz\"\n\n[[3]]\n[1] \"S2B\"         \"R1.fastq.gz\"\n\n[[4]]\n[1] \"S2S\"         \"R1.fastq.gz\"\n\n[[5]]\n[1] \"S3B\"         \"R1.fastq.gz\"\n\n[[6]]\n[1] \"S3S\"         \"R1.fastq.gz\"\n\n\nNow, We just have to extract the first element for each file.\n\nbasename(fnFs) |&gt;\n  strsplit(split = \"_\") |&gt;\n  sapply(head, 1) |&gt;\n  head()\n\n[1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\" \n\n\nTip: you can achieve the same thing using regular expressions:\n\ngsub(\"^.+/|_.+$\", \"\", fnFs) |&gt; head()\n\n[1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\" \n\n\nRegular expressions are extremely useful. If you are keen to learn how to use them, have a look here"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#prepare-outputs",
    "href": "practicals/preprocessing_dada2.html#prepare-outputs",
    "title": "Preprocessing : dada2",
    "section": "4.1 Prepare outputs",
    "text": "4.1 Prepare outputs\nWe first create a folder where to save the reads once they are trimmed:\n\npath_to_trimmed_reads &lt;- here::here(\n  \"outputs\",\n  \"dada2\",\n  \"trimmed\"\n)\n\nif (!dir.exists(path_to_trimmed_reads)) dir.create(path_to_trimmed_reads, recursive = TRUE)\n\nThen we prepare a list of paths where to save the results (e.g. sequences without primers)\n\nnopFw &lt;- file.path(path_to_trimmed_reads, basename(fnFs))\nnopRv &lt;- file.path(path_to_trimmed_reads, basename(fnRs))\n\nhead(nopFw)\n\n[1] \"/home/rstudio/mydatalocal/course-material/outputs/dada2/trimmed/S11B_R1.fastq.gz\"\n[2] \"/home/rstudio/mydatalocal/course-material/outputs/dada2/trimmed/S1B_R1.fastq.gz\" \n[3] \"/home/rstudio/mydatalocal/course-material/outputs/dada2/trimmed/S2B_R1.fastq.gz\" \n[4] \"/home/rstudio/mydatalocal/course-material/outputs/dada2/trimmed/S2S_R1.fastq.gz\" \n[5] \"/home/rstudio/mydatalocal/course-material/outputs/dada2/trimmed/S3B_R1.fastq.gz\" \n[6] \"/home/rstudio/mydatalocal/course-material/outputs/dada2/trimmed/S3S_R1.fastq.gz\""
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#remove-primers",
    "href": "practicals/preprocessing_dada2.html#remove-primers",
    "title": "Preprocessing : dada2",
    "section": "4.2 Remove primers",
    "text": "4.2 Remove primers\nThe data you are working with correspond to the V3-V4 region using the primers Pro341F (CCTACGGGNBGCASCAG) and Pro805R (GACTACNVGGGTATCTAAT). Save into variables the forward and reverse primers:\n\nprimer_fwd  &lt;- \"CCTACGGGNBGCASCAG\"\nprimer_rev  &lt;- \"GACTACNVGGGTATCTAAT\"\n\nLet’s have a closer look at sequences and find the primers.\nForward reads would contain CCTACGGGNBGCASCAG\n\nBiostrings::readDNAStringSet(\n  fnFs[1],\n  format = \"fastq\",\n  nrec = 10\n)\n\nDNAStringSet object of length 10:\n     width seq                                              names               \n [1]   293 CCTACGGGGGGCAGCAGTAGGGA...ACATCGGCTTAACCGATGAAGT M01522:260:000000...\n [2]   293 CCTACGGGTGGCACCAGTAGGGA...CGGGGCTTAACCTCGGAACTGC M01522:260:000000...\n [3]   292 CCTACGGGGCGCAGCAGGCGCGA...GGGACCGGGAGAGGTGTGAGGT M01522:260:000000...\n [4]   293 CCTACGGGGTGCAGCAGTAGGGA...TCAAAACTCCCAGTCTAGAGTT M01522:260:000000...\n [5]   291 CCTACGGGTGGCAGCAGTGGGGA...GCAGTGGAAACTGTTGGGCTTG M01522:260:000000...\n [6]   293 CCTACGGGATGCAGCAGGCGCGA...GGGACCGGGAGAGGTGTGGGGG M01522:260:000000...\n [7]   292 CCTACGGGATGCAGCAGTGGGGA...TTTAATCCTGATGAGCTAGAAA M01522:260:000000...\n [8]   293 CCTACGGGGCGCAGCAGTAGGGA...TTAAAACTTTTGTTCTGGAATT M01522:260:000000...\n [9]   292 CCTACGGGTTGCAGCAGTGGGGA...ATTAAAACTTTTCAGCTAGAGT M01522:260:000000...\n[10]   293 CCTACGGGAGGCAGCAGTGGGGA...CCCGGGCTCAACCTGGGAACGG M01522:260:000000...\n\n\nAnd reverse reads should contain GACTACNVGGGTATCTAAT\n\nBiostrings::readDNAStringSet(\n  fnRs[1],\n  format = \"fastq\",\n  nrec = 10\n)\n\nDNAStringSet object of length 10:\n     width seq                                              names               \n [1]   301 GACTACCAGGGTATCTAATCCTG...GGCTGCTGGCACGAAGTTCGCC M01522:260:000000...\n [2]   301 GACTACCGGGGTATCTAATCCTG...GGCTGCTGGCACGGAGTTAGCC M01522:260:000000...\n [3]   300 AATCCGGTTCGTGCCCCTAGGCT...TCTTTCCCAGCCCTTATTCCAA M01522:260:000000...\n [4]   301 GACTACCGGGGTATCTAATCCTG...GGCTGCTGGCACGGAGTTAGCC M01522:260:000000...\n [5]   301 GACTACCGGGGTATCTAATCCCT...GGCTGCTGGCCCGGAATTAGCC M01522:260:000000...\n [6]   301 GGTATCTAATCCGGTTCGTGCCC...CACCGTCCTTACCCCCCCCTTT M01522:260:000000...\n [7]   301 GGTATCTAATCTTGTTTGCTCCC...CCCGACGTTAGCCGGGGCTTCT M01522:260:000000...\n [8]   301 GACTACGAGGGTATCTAATCCCG...GGCTGCTGGCACGGAATTAGCC M01522:260:000000...\n [9]   301 GGTATCTAATCCTCTTCGCTACC...CACGAAGTTAGCCGGACCTTCT M01522:260:000000...\n[10]   301 GACTACGGGGGTATCTAATCCTG...GGCTGCCGGCACGGGGTTAGCC M01522:260:000000...\n\n\nUse the function dada2::removePrimers() twice to remove the primers from forward fnFs and reverse fnRs reads and save the results in nopFs and nopRs respectively.\n\ndada2::removePrimers(fn = fnFs,\n                     fout = nopFw,\n                     primer.fwd = primer_fwd,\n                     max.mismatch = 1,\n                     verbose = TRUE)\n\ndada2::removePrimers(fn = fnRs,\n                     fout = nopRv,\n                     primer.fwd = primer_rev,\n                     max.mismatch = 1,\n                     verbose = TRUE)"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#for-more-complex-situations",
    "href": "practicals/preprocessing_dada2.html#for-more-complex-situations",
    "title": "Preprocessing : dada2",
    "section": "4.3 For more complex situations",
    "text": "4.3 For more complex situations\nIf you have to deal with a lot of samples and/or mixed orientated reads, we would recommend using dedicated tools such as cutadapt. We will see later during the course how to use cutadapt from the nextflow workflow nf-core/ampliseq."
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#learn-the-error-model",
    "href": "practicals/preprocessing_dada2.html#learn-the-error-model",
    "title": "Preprocessing : dada2",
    "section": "6.1 Learn the error model",
    "text": "6.1 Learn the error model\nTo be able to denoise your data, you need an error model. The error model will tell you at which rate a nucleotide is replace by another for a given quality score. For example, for a quality score Q of 30, what is the probability of an A being wrongly read as a T.\nThis error model can be learnt directly from the data with the function dada2::learnErrors(). You can come back to the course for more details about the maths behind.\n\nerrF &lt;- dada2::learnErrors(filtFs,\n                           randomize = TRUE,\n                           multithread = TRUE)\n\n6110500 total bases in 24442 reads from 18 samples will be used for learning the error rates.\n\nerrR &lt;- dada2::learnErrors(filtRs,\n                           randomize = TRUE,\n                           multithread = TRUE)\n\n5377240 total bases in 24442 reads from 18 samples will be used for learning the error rates.\n\n\nYou can visualise the resulting error model using the function dada2::plotErrors()\n\ndada2::plotErrors(errF, nominalQ = TRUE)\n\nWarning: Transformation introduced infinite values in continuous y-axis\nTransformation introduced infinite values in continuous y-axis"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#dereplication",
    "href": "practicals/preprocessing_dada2.html#dereplication",
    "title": "Preprocessing : dada2",
    "section": "6.2 Dereplication",
    "text": "6.2 Dereplication\nBefore denoising, we need to dereplicate the sequences. It means, for each unique sequence, count the number of reads.\nThe dereplication is achieved using the function dada2::derepFastq()\n\nderepFs &lt;- dada2::derepFastq(filtFs, verbose = TRUE)\n\nderepRs &lt;- dada2::derepFastq(filtRs, verbose = TRUE)"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#run-dada",
    "href": "practicals/preprocessing_dada2.html#run-dada",
    "title": "Preprocessing : dada2",
    "section": "6.3 Run dada",
    "text": "6.3 Run dada\nNow we are ready to run the denoising algorithm with dada2::dada(). As input, we need the error model and the dereplicated sequences.\n\ndadaFs &lt;- dada2::dada(derepFs, err = errF, multithread = TRUE)\n\nSample 1 - 1318 reads in 793 unique sequences.\nSample 2 - 1367 reads in 843 unique sequences.\nSample 3 - 1385 reads in 814 unique sequences.\nSample 4 - 1321 reads in 799 unique sequences.\nSample 5 - 1352 reads in 803 unique sequences.\nSample 6 - 1452 reads in 801 unique sequences.\nSample 7 - 1393 reads in 756 unique sequences.\nSample 8 - 1444 reads in 668 unique sequences.\nSample 9 - 1358 reads in 807 unique sequences.\nSample 10 - 1394 reads in 701 unique sequences.\nSample 11 - 1327 reads in 698 unique sequences.\nSample 12 - 1347 reads in 697 unique sequences.\nSample 13 - 1328 reads in 730 unique sequences.\nSample 14 - 1371 reads in 757 unique sequences.\nSample 15 - 1306 reads in 735 unique sequences.\nSample 16 - 1352 reads in 734 unique sequences.\nSample 17 - 1283 reads in 707 unique sequences.\nSample 18 - 1344 reads in 710 unique sequences.\n\ndadaRs &lt;- dada2::dada(derepRs, err = errR, multithread = TRUE)\n\nSample 1 - 1318 reads in 815 unique sequences.\nSample 2 - 1367 reads in 834 unique sequences.\nSample 3 - 1385 reads in 872 unique sequences.\nSample 4 - 1321 reads in 799 unique sequences.\nSample 5 - 1352 reads in 832 unique sequences.\nSample 6 - 1452 reads in 851 unique sequences.\nSample 7 - 1393 reads in 838 unique sequences.\nSample 8 - 1444 reads in 746 unique sequences.\nSample 9 - 1358 reads in 852 unique sequences.\nSample 10 - 1394 reads in 777 unique sequences.\nSample 11 - 1327 reads in 734 unique sequences.\nSample 12 - 1347 reads in 710 unique sequences.\nSample 13 - 1328 reads in 754 unique sequences.\nSample 14 - 1371 reads in 816 unique sequences.\nSample 15 - 1306 reads in 788 unique sequences.\nSample 16 - 1352 reads in 814 unique sequences.\nSample 17 - 1283 reads in 751 unique sequences.\nSample 18 - 1344 reads in 782 unique sequences."
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#r-objects",
    "href": "practicals/preprocessing_dada2.html#r-objects",
    "title": "Preprocessing : dada2",
    "section": "11.1 R objects",
    "text": "11.1 R objects\nThe results can be exported as a R objects, one object for the ASV table and another one for the taxonomy.\n\nexport_folder &lt;- here::here(\"outputs\", \"dada2\", \"asv_table\")\n\nif (!dir.exists(export_folder)) dir.create(export_folder, recursive = TRUE)\n\nsaveRDS(object = seqtab_nochim,\n        file = file.path(export_folder, \"seqtab_nochim.rds\"))\n\nsaveRDS(object = taxonomy,\n        file = file.path(export_folder, \"taxonomy.rds\"))"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#text-files",
    "href": "practicals/preprocessing_dada2.html#text-files",
    "title": "Preprocessing : dada2",
    "section": "11.2 Text files",
    "text": "11.2 Text files\nWe recommand to export your results as text files. They are then reusable by other programs/languages.\nBut before, we need to format the data a little bit.\nFirst we create a new variable to collect the ASV sequences:\n\nasv_seq &lt;- colnames(seqtab_nochim)\n\nWe create unique ids for each ASV. The sequence itself is an unique id, but we would like to have something shorter.\n\nndigits &lt;- nchar(length(asv_seq))\nasv_id &lt;- sprintf(paste0(\"ASV_%0\", ndigits, \"d\"), seq_along(asv_seq))\n\nand rename the different variables with the new ids\n\nrow.names(taxonomy) &lt;- colnames(seqtab_nochim) &lt;- names(asv_seq) &lt;- asv_id\n\nBefore exporting the data frames (taxonomy and seqtab_nochim) as a text file, we convert their row names (ASV ids) into a new column named asv. This is achieved using the custom function df_export()\n\ntaxonomy_export &lt;- df_export(taxonomy, new_rn = \"asv\")\n\nseqtab_nochim_export &lt;- t(seqtab_nochim)\nseqtab_nochim_export &lt;- df_export(seqtab_nochim_export, new_rn = \"asv\")\n\nFinally, we can export the taxonomy\n\nwrite.table(taxonomy_export,\n            file = file.path(export_folder, \"taxonomy.tsv\"),\n            quote = FALSE,\n            sep = \"\\t\",\n            row.names = FALSE)\n\nthe ASV table\n\nwrite.table(seqtab_nochim_export,\n            file = file.path(export_folder, \"asv_table.tsv\"),\n            quote = FALSE,\n            sep = \"\\t\",\n            row.names = FALSE)\n\nand the sequences as a fasta file\n\ncat(paste0(\"&gt;\", names(asv_seq), \"\\n\", asv_seq),\n    sep = \"\\n\",\n    file = file.path(export_folder, \"asv.fasta\"))"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#log",
    "href": "practicals/preprocessing_dada2.html#log",
    "title": "Preprocessing : dada2",
    "section": "11.3 Log",
    "text": "11.3 Log\nStatistics about each preprocessing step can also be exported.\nFirst this table need to be assembled:\n\ngetN &lt;- function(x) sum(dada2::getUniques(x))\n\nlog_table &lt;- data.frame(\n  input = out[, 1],\n  filtered = out[, 2],\n  denoisedF = sapply(dadaFs, getN),\n  denoisedR = sapply(dadaRs, getN),\n  merged = sapply(mergers, getN),\n  nonchim = rowSums(seqtab_nochim),\n  perc_retained = rowSums(seqtab_nochim) / out[, 1] * 100\n)\n\nrownames(log_table) &lt;- sample_names\n\nThen it can be exported:\n\ndf_export(log_table, new_rn = \"sample\") |&gt;\n  write.table(file = file.path(export_folder, \"log_table.tsv\"),\n              quote = FALSE,\n              sep = \"\\t\",\n              row.names = FALSE)\n\nThe sessionInfo() function in R provides a quick summary of your R environment, including the version of R, loaded packages, and their versions—useful for debugging, reproducibility, and sharing your setup with others.\n\nsessionInfo()\n\nR version 4.3.1 (2023-06-16)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 22.04.3 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ANF_metaB_1.0.0\n\nloaded via a namespace (and not attached):\n  [1] bitops_1.0-7                deldir_1.0-9               \n  [3] remotes_2.4.2.1             rlang_1.1.1                \n  [5] magrittr_2.0.3              matrixStats_1.0.0          \n  [7] compiler_4.3.1              png_0.1-8                  \n  [9] callr_3.7.3                 vctrs_0.6.3                \n [11] reshape2_1.4.4              stringr_1.5.0              \n [13] profvis_0.3.8               pkgconfig_2.0.3            \n [15] crayon_1.5.2                fastmap_1.1.1              \n [17] XVector_0.40.0              ellipsis_0.3.2             \n [19] labeling_0.4.2              utf8_1.2.3                 \n [21] Rsamtools_2.16.0            promises_1.2.1             \n [23] rmarkdown_2.24              sessioninfo_1.2.2          \n [25] ps_1.7.5                    purrr_1.0.2                \n [27] xfun_0.40                   zlibbioc_1.46.0            \n [29] cachem_1.0.8                GenomeInfoDb_1.36.2        \n [31] jsonlite_1.8.7              later_1.3.1                \n [33] DelayedArray_0.26.7         BiocParallel_1.34.2        \n [35] jpeg_0.1-10                 parallel_4.3.1             \n [37] prettyunits_1.1.1           R6_2.5.1                   \n [39] stringi_1.7.12              RColorBrewer_1.1-3         \n [41] pkgload_1.3.2.1             GenomicRanges_1.52.0       \n [43] Rcpp_1.0.11                 SummarizedExperiment_1.30.2\n [45] knitr_1.43                  usethis_2.2.2              \n [47] IRanges_2.34.1              httpuv_1.6.11              \n [49] Matrix_1.6-1                tidyselect_1.2.0           \n [51] rstudioapi_0.15.0           abind_1.4-5                \n [53] yaml_2.3.7                  codetools_0.2-19           \n [55] miniUI_0.1.1.1              hwriter_1.3.2.1            \n [57] processx_3.8.2              pkgbuild_1.4.2             \n [59] plyr_1.8.8                  lattice_0.21-8             \n [61] tibble_3.2.1                Biobase_2.60.0             \n [63] shiny_1.7.5                 withr_2.5.0                \n [65] ShortRead_1.58.0            evaluate_0.21              \n [67] desc_1.4.2                  RcppParallel_5.1.7         \n [69] urlchecker_1.0.1            Biostrings_2.68.1          \n [71] pillar_1.9.0                MatrixGenerics_1.12.3      \n [73] stats4_4.3.1                generics_0.1.3             \n [75] rprojroot_2.0.3             RCurl_1.98-1.12            \n [77] S4Vectors_0.38.1            ggplot2_3.4.3              \n [79] munsell_0.5.0               scales_1.2.1               \n [81] xtable_1.8-4                glue_1.6.2                 \n [83] tools_4.3.1                 interp_1.1-4               \n [85] GenomicAlignments_1.36.0    fs_1.6.3                   \n [87] grid_4.3.1                  latticeExtra_0.6-30        \n [89] devtools_2.4.5              colorspace_2.1-0           \n [91] GenomeInfoDbData_1.2.10     cli_3.6.1                  \n [93] fansi_1.0.4                 S4Arrays_1.0.5             \n [95] dada2_1.28.0                dplyr_1.1.2                \n [97] gtable_0.3.4                digest_0.6.33              \n [99] BiocGenerics_0.46.0         farver_2.1.1               \n[101] htmlwidgets_1.6.2           memoise_2.0.1              \n[103] htmltools_0.5.6             lifecycle_1.0.3            \n[105] here_1.0.1                  mime_0.12"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html",
    "href": "practicals/preprocessing_phyloseq.html",
    "title": "Preprocessing : phyloseq",
    "section": "",
    "text": "Load phyloseq\n\nlibrary(phyloseq)\n\nWe import the ASV table, the taxonomic assignment results and the sequences from the text files we exported in the dada2 practical.\nDefine where the previous practical outputs are located:\n\ninput_dir &lt;- here::here(\"outputs\", \"dada2\", \"asv_table\")\n\nImport the ASV table:\n\nasv_table &lt;- read.table(file = file.path(input_dir, \"asv_table.tsv\"),\n                        header = TRUE,\n                        sep = \"\\t\",\n                        row.names = 1)\n\nthe results of the taxonomic assignment:\n\ntaxonomy &lt;- read.table(file = file.path(input_dir, \"taxonomy.tsv\"),\n                        header = TRUE,\n                        sep = \"\\t\",\n                        row.names = 1)\n\nand the ASV sequences:\n\nasv_seq &lt;- Biostrings::readDNAStringSet(\n  filepath = file.path(input_dir, \"asv.fasta\"),\n  format = \"fasta\"\n)\n\nWe will also need some information about the samples, the file is located is another folder.\n\ncontext &lt;- read.table(here::here(\"data\",\n                                 \"context\",\n                                 \"mapfileFA.txt\"),\n                      header = TRUE,\n                      row.names = 1)"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#check-sample-file",
    "href": "practicals/preprocessing_phyloseq.html#check-sample-file",
    "title": "Preprocessing : phyloseq",
    "section": "2.1 Check sample file",
    "text": "2.1 Check sample file\nMake sure sample names in the ASV table…\n\ncolnames(asv_table) |&gt; sort()\n\n [1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\"  \"S4B\"  \"S4S\"  \"S5B\"  \"S5S\" \n[11] \"S6B\"  \"S6S\"  \"S7B\"  \"S7S\"  \"S8B\"  \"S8S\"  \"S9B\"  \"S9S\" \n\n\nmatch sample table ids.\n\nrow.names(context) |&gt; sort()\n\n [1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\"  \"S4B\"  \"S4S\"  \"S5B\"  \"S5S\" \n[11] \"S6B\"  \"S6S\"  \"S7B\"  \"S7S\"  \"S8B\"  \"S8S\"  \"S9B\"  \"S9S\" \n\n\nYou can do it in a more formal way using the function setdiff(). This function returns the elements of x not present in y.\n\nsetdiff(x = colnames(asv_table),\n        y = row.names(context))\n\ncharacter(0)\n\n\nPerfect! The ASV table sample names match with the contextual data table."
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#assemble-asv-table-taxonomy-and-contextual-data",
    "href": "practicals/preprocessing_phyloseq.html#assemble-asv-table-taxonomy-and-contextual-data",
    "title": "Preprocessing : phyloseq",
    "section": "2.2 Assemble ASV table, taxonomy and contextual data",
    "text": "2.2 Assemble ASV table, taxonomy and contextual data\nUse the phyloseq::phyloseq() function to create a phyloseq object. A phyloseq object is usualy composed by an ASV table, a taxonomy table and a table describing the samples. You can also add ASV sequences and a phylogenetic tree\n\nphyseq &lt;- phyloseq::phyloseq(\n  phyloseq::otu_table(asv_table, taxa_are_rows = TRUE),\n  phyloseq::tax_table(as.matrix(taxonomy)),\n  phyloseq::sample_data(context),\n  phyloseq::refseq(asv_seq)\n)"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#why",
    "href": "practicals/preprocessing_phyloseq.html#why",
    "title": "Preprocessing : phyloseq",
    "section": "3.1 Why?",
    "text": "3.1 Why?\nKnowing the ASVs phylogenetic relatedness will help you to have a better understanding of the communities your studying.\nTo quote the evolutionary biologist Theodosius Dobzhansky:\n\nNothing in Biology Makes Sense Except in the Light of Evolution.\n\nA phylogenetic tree reconstructed from the ASV sequences will be used to measure their relatedness."
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#alignment-using-decipher",
    "href": "practicals/preprocessing_phyloseq.html#alignment-using-decipher",
    "title": "Preprocessing : phyloseq",
    "section": "3.2 Alignment using DECIPHER",
    "text": "3.2 Alignment using DECIPHER\nBefore reconstructing a phylogenetic tree we need to align the ASVs sequences.\n\naln &lt;- refseq(physeq) |&gt;\n  DECIPHER::AlignSeqs(anchor = NA)\n\nOnce it is done, you can visualise the alignment using the function DECIPHER::BrowseSeqs()\n\nDECIPHER::BrowseSeqs(aln, highlight = 0)"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#infering-the-phylogenetic-tree",
    "href": "practicals/preprocessing_phyloseq.html#infering-the-phylogenetic-tree",
    "title": "Preprocessing : phyloseq",
    "section": "3.3 Infering the phylogenetic tree",
    "text": "3.3 Infering the phylogenetic tree\nWe will infer a phylogenetic from our alignement using the library phangorn.\nFirst, let’s convert our DNAStringSet alignment to the phangorn phyDat format.\n\nphang_align &lt;- as.matrix(aln) |&gt; phangorn::phyDat(type = \"DNA\")\n\nThen, we compute pairwise distances of our aligned sequences using equal base frequencies (JC69 model used by default).\n\ndm &lt;- phangorn::dist.ml(phang_align, model = \"JC69\")\n\nFinally, we reconstruct a neighbour joining tree.\n\ntreeNJ &lt;- phangorn::NJ(dm)\n\nOther approaches to reconstruct a phylogenetic tree exist. If you want to try them with phangorn, have a look here\nWe need the tree to be rooted for future analysis. We can do that using the function phangorn::midpoint()\n\ntreeNJ &lt;- phangorn::midpoint(tree = treeNJ)\n\nOnce we have a rooted tree, we can add it to the phyloseq object.\n\nphyseq &lt;- phyloseq::merge_phyloseq(physeq,treeNJ)"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#if-i-do-not-have-a-tree",
    "href": "practicals/preprocessing_phyloseq.html#if-i-do-not-have-a-tree",
    "title": "Preprocessing : phyloseq",
    "section": "3.4 If I do not have a tree",
    "text": "3.4 If I do not have a tree\nFor some reasons, it is sometimes not relevant or not possible to infer a tree from our data.\nFor example, the metabarcode you are using is not carrying enough phylogenetic information to reconstruct a tree.\nOr you have so many ASVs that infering a tree would require more computational ressource that what you can afford.\nIn that case, it is fine. You will still be able to perform most of the analyses introduced in the alpha and beta diversity practicals."
  },
  {
    "objectID": "practicals/alpha_diversity.html",
    "href": "practicals/alpha_diversity.html",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "",
    "text": "library(phyloseq)\nlibrary(ggplot2)\nlibrary(patchwork)\n\n\n\n\n\ndevtools::load_all()\n\nWarning: Objects listed as exports, but not present in namespace:\n• primer_trim\n\n\n\n\n\n\noutput_alpha &lt;- here::here(\"outputs\", \"alpha_diversity\")\nif (!dir.exists(output_alpha)) dir.create(output_alpha, recursive = TRUE)\n\n\n\n\n\nphyseq &lt;- readRDS(here::here(\"data\",\n                             \"asv_table\",\n                             \"phyloseq_object_alpha_beta_div.rds\"))"
  },
  {
    "objectID": "practicals/alpha_diversity.html#load-libraries",
    "href": "practicals/alpha_diversity.html#load-libraries",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "",
    "text": "library(phyloseq)\nlibrary(ggplot2)\nlibrary(patchwork)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#load-custom-functions",
    "href": "practicals/alpha_diversity.html#load-custom-functions",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "",
    "text": "devtools::load_all()\n\nWarning: Objects listed as exports, but not present in namespace:\n• primer_trim"
  },
  {
    "objectID": "practicals/alpha_diversity.html#define-output-folder",
    "href": "practicals/alpha_diversity.html#define-output-folder",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "",
    "text": "output_alpha &lt;- here::here(\"outputs\", \"alpha_diversity\")\nif (!dir.exists(output_alpha)) dir.create(output_alpha, recursive = TRUE)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#load-the-data-and-inspect-the-phyloseq-object",
    "href": "practicals/alpha_diversity.html#load-the-data-and-inspect-the-phyloseq-object",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "",
    "text": "physeq &lt;- readRDS(here::here(\"data\",\n                             \"asv_table\",\n                             \"phyloseq_object_alpha_beta_div.rds\"))"
  },
  {
    "objectID": "practicals/alpha_diversity.html#composition-of-our-phyloseq-object-physeq",
    "href": "practicals/alpha_diversity.html#composition-of-our-phyloseq-object-physeq",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "2.1 Composition of our phyloseq object physeq",
    "text": "2.1 Composition of our phyloseq object physeq\n\n2.1.1 An ASV table with the absolute counts\nBe careful: Rows are samples, columns are ASVs\n\nphyseq@otu_table[1:10,1:10]\n\nOTU Table:          [10 taxa and 10 samples]\n                     taxa are columns\n     ASV1 ASV2 ASV3 ASV4 ASV5 ASV6 ASV7 ASV8 ASV9 ASV10\nS11B  117   25   85   70   87   40   57   34   41     0\nS1B    67    0   23    0   51   48    0    0   27    58\nS2B    43    0   35   15   42   52    0    0    0    43\nS2S   103   87   76   12   99   43   36   72   46     0\nS3B    59    0   32    0   49   73    0    0    0    57\nS3S    81   10    0   20   36    0    0    0    0    50\nS4B    11    6   38   33   43   46    0    8    0    37\nS4S    68    6   38    0   62    0    0   11   30    46\nS5B   176   18   62  109    0   35   56   13   33    82\nS5S   182    0   36  101   51    0   33    0   29    42\n\n\n\n\n2.1.2 A metadata table with information (e.g. physicochemical, categorical variables) about samples\n\nphyseq@sam_data\n\n     SampName   Geo Description groupe Pres PicoEuk Synec Prochloro NanoEuk\nS11B     S11B South     South5B    SGF   35    5370 46830       580    6010\nS1B       S1B North     North1B    NBF   52     660 32195     10675     955\nS2B       S2B North     North2B    NBF   59     890 25480     16595     670\nS2S       S2S North     North2S    NBS    0     890 25480     16595     670\nS3B       S3B North     North3B    NBF   74     835 13340     25115    1115\nS3S       S3S North     North3S    NBS    0     715 26725     16860     890\nS4B       S4B North     North4B    NBF   78    2220  3130     29835    2120\nS4S       S4S North     North4S    NBS   78    2220  3130     29835    2120\nS5B       S5B North     North5B    NBF   42    1620 55780     23795    2555\nS5S       S5S North     North5S    NBS    0    1620 56555     22835    2560\nS6B       S6B South     South1B    SGF   13    2520 39050       705    3630\nS6S       S6S South     South1S    SGS    0    2435 35890       915    3735\nS7B       S7B South     South2B    SGF   26       0     0         0    4005\nS7S       S7S South     South2S    SGS    0    4535 26545      1340    6585\nS8B       S8B South     South3B    SGF   33       0     0         0    5910\nS8S       S8S South     South3S    SGS    0    4260 36745       985    5470\nS9B       S9B South     South4B    SGF   25    4000 31730       485    4395\nS9S       S9S South     South4S    SGS    0    5465 32860       820    5045\n     Crypto SiOH4   NO2   NO3   NH4   PO4    NT    PT   Chla       T       S\nS11B   1690 3.324 0.083 0.756 0.467 0.115 9.539 4.138 0.0182 23.0308 38.9967\nS1B     115 1.813 0.256 0.889 0.324 0.132 9.946 3.565 0.0000 22.7338 37.6204\nS2B     395 2.592 0.105 1.125 0.328 0.067 9.378 3.391 0.0000 22.6824 37.6627\nS2S     395 3.381 0.231 0.706 0.450 0.109 8.817 3.345 0.0000 22.6854 37.6176\nS3B     165 1.438 0.057 1.159 0.369 0.174 8.989 2.568 0.0000 21.5296 37.5549\nS3S     200 1.656 0.098 0.794 0.367 0.095 7.847 2.520 0.0000 22.5610 37.5960\nS4B     235 2.457 0.099 1.087 0.349 0.137 8.689 3.129 0.0000 18.8515 37.4542\nS4S     235 2.457 0.099 1.087 0.349 0.137 8.689 3.129 0.0000 18.8515 37.4542\nS5B    1355 2.028 0.103 1.135 0.216 0.128 8.623 3.137 0.0102 24.1905 38.3192\nS5S     945 2.669 0.136 0.785 0.267 0.114 9.146 3.062 0.0000 24.1789 38.3213\nS6B    1295 2.206 0.249 0.768 0.629 0.236 9.013 3.455 0.0000 22.0197 39.0877\nS6S    1300 3.004 0.251 0.927 0.653 0.266 8.776 3.230 0.0134 22.0515 39.0884\nS7B    1600 3.016 0.157 0.895 0.491 0.176 8.968 4.116 0.0000 23.6669 38.9699\nS7S    1355 1.198 0.165 1.099 0.432 0.180 8.256 3.182 0.0000 23.6814 38.9708\nS8B    1590 3.868 0.253 0.567 0.533 0.169 8.395 3.126 0.0000 23.1236 39.0054\nS8S    2265 3.639 0.255 0.658 0.665 0.247 8.991 3.843 0.0132 23.3147 38.9885\nS9B    1180 3.910 0.107 0.672 0.490 0.134 8.954 4.042 0.0172 22.6306 38.9094\nS9S    1545 3.607 0.139 0.644 0.373 0.167 9.817 3.689 0.0062 22.9545 38.7777\n     Sigma_t\nS11B 26.9631\nS1B  26.0046\nS2B  26.0521\nS2S  26.0137\nS3B  26.2987\nS3S  26.0332\nS4B  26.9415\nS4S  26.9415\nS5B  26.1037\nS5S  26.1065\nS6B  27.3241\nS6S  27.3151\nS7B  26.7536\nS7S  26.7488\nS8B  26.9423\nS8S  26.8713\nS9B  27.0131\nS9S  26.8172\n\n\n\n\n2.1.3 A table of taxonomic classification level of each ASV\n\nphyseq@tax_table[1:10,]\n\nTaxonomy Table:     [10 taxa by 7 taxonomic ranks]:\n      Kingdom    Phylum             Class                 Order             \nASV1  \"Bacteria\" \"Cyanobacteria\"    \"Cyanobacteriia\"      \"Synechococcales\" \nASV2  \"Bacteria\" \"Proteobacteria\"   \"Gammaproteobacteria\" \"Enterobacterales\"\nASV3  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \nASV4  \"Archaea\"  \"Thermoplasmatota\" \"Thermoplasmata\"      \"Marine Group II\" \nASV5  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \nASV6  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \nASV7  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"Rhodospirillales\"\nASV8  \"Bacteria\" \"Proteobacteria\"   \"Gammaproteobacteria\" \"Enterobacterales\"\nASV9  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \nASV10 \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \n      Family                    Genus                  Species\nASV1  \"Cyanobiaceae\"            \"Synechococcus CC9902\" NA     \nASV2  \"Pseudoalteromonadaceae\"  \"Pseudoalteromonas\"    NA     \nASV3  \"Clade I\"                 \"Clade Ia\"             NA     \nASV4  NA                        NA                     NA     \nASV5  \"Clade I\"                 \"Clade Ia\"             NA     \nASV6  \"Clade II\"                NA                     NA     \nASV7  \"AEGEAN-169 marine group\" NA                     NA     \nASV8  \"Pseudoalteromonadaceae\"  \"Pseudoalteromonas\"    NA     \nASV9  \"Clade I\"                 \"Clade Ia\"             NA     \nASV10 \"Clade I\"                 \"Clade Ia\"             NA     \n\n\n\n\n2.1.4 A Phylogenetic tree\n\nphyseq@phy_tree\n\n\nPhylogenetic tree with 213 tips and 212 internal nodes.\n\nTip labels:\n  ASV1, ASV2, ASV3, ASV4, ASV5, ASV6, ...\n\nRooted; includes branch lengths.\n\n\n\n\n2.1.5 A table with the ASV sequences\n\nphyseq@refseq\n\nDNAStringSet object of length 213:\n      width seq                                             names               \n  [1]   402 GGAATTTTCCGCAATGGGCGAA...CGAAAGCCAGGGGAGCGAAAGG ASV1\n  [2]   425 GGAATATTGCACAATGGGCGCA...CGAAAGCGTGGGGAGCAAACAG ASV2\n  [3]   400 GGAATCTTGCACAATGGAGGAA...CGAAAGCATGGGTAGCGAAGAG ASV3\n  [4]   383 CGAAAACTTGACAATGCGAGCA...CGAAGCCTAGGGGCACGAACCG ASV4\n  [5]   400 GGAATCTTGCACAATGGAGGAA...CGAAAGCATGGGTAGCGAAGAG ASV5\n  ...   ... ...\n[209]   426 GGAATTTTGCGCAATGGACGAA...CGAAAGCGTGGGGAGCGAACAG ASV209\n[210]   403 GGAATATTGCACAATGGGCGCA...GGTCAACACTGACGCTCATGTA ASV210\n[211]   360 CGAAAACTTCACACTGCAGGAA...GAACGGATCCGACGGTCAGGGA ASV211\n[212]   400 GGAATATTGGACAATGGGCGAA...CGAAAGCGTGGGTAGCAAACAG ASV212\n[213]   404 GGAATATTGCACAATGGGCGCA...GTCAACACTGACGCTCATGTAC ASV213"
  },
  {
    "objectID": "practicals/alpha_diversity.html#rarefaction-curves",
    "href": "practicals/alpha_diversity.html#rarefaction-curves",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "3.1 Rarefaction Curves",
    "text": "3.1 Rarefaction Curves\nBefore normalization by sub-sampling, let’s have a look at rarefaction curves, evaluate your sequencing effort and make decisions\n\n3.1.1 Identify your minimum sample size\n\nphyloseq::sample_sums(physeq)\n\nS11B  S1B  S2B  S2S  S3B  S3S  S4B  S4S  S5B  S5S  S6B  S6S  S7B  S7S  S8B  S8S \n 975  837  893  983  878  889  917 1077 1018 1006 1076  937  878  936  846  958 \n S9B  S9S \n 888  991 \n\n\nWhat is the minimum sample size?\n\n\n3.1.2 Run rarefaction curves using our custom function ggrare() (defined in R/alpha_diversity.R)\n\n#Make rarefaction curves & Add min sample size line\nggrare(physeq, step = 10, color = \"Description\", se = FALSE) +\n  geom_vline(xintercept = min(sample_sums(physeq)), color = \"gray60\")\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 4\n\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 3\n\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 4\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 4\n\n\n\n\n\n\n\n\nDo you think is a good idea to normalize your data using this minimal sample size?"
  },
  {
    "objectID": "practicals/alpha_diversity.html#normalization-process-for-alpha-diversity-sub-sampling",
    "href": "practicals/alpha_diversity.html#normalization-process-for-alpha-diversity-sub-sampling",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "3.2 Normalization process for alpha diversity: sub-sampling",
    "text": "3.2 Normalization process for alpha diversity: sub-sampling\n\nphyseq_rar &lt;- phyloseq::rarefy_even_depth(physeq, rngseed = TRUE)\n\nCheck the number of sequences for each sample using sample_sums function\nDid you lost a lot of ASVs?"
  },
  {
    "objectID": "practicals/alpha_diversity.html#run-rarefaction-curves-on-normalized-data",
    "href": "practicals/alpha_diversity.html#run-rarefaction-curves-on-normalized-data",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "3.3 Run rarefaction curves on normalized data",
    "text": "3.3 Run rarefaction curves on normalized data\n\np0 &lt;- ggrare(physeq_rar, step = 10, color = \"Description\", se = TRUE)\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 2\n\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 3\n\n\nWarning in vegan::rarefy(x[i, , drop = FALSE], n, se = se): most observed count\ndata have counts 1, but smallest count is 4"
  },
  {
    "objectID": "practicals/alpha_diversity.html#group-separation",
    "href": "practicals/alpha_diversity.html#group-separation",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "3.4 Group separation",
    "text": "3.4 Group separation\n\np0 + facet_wrap(~Geo, ncol = 2)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#indices",
    "href": "practicals/alpha_diversity.html#indices",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "4.1 Indices",
    "text": "4.1 Indices\n\n4.1.1 Get taxonomy-based diversity indices\n\n#Get indices with alpha function (NB: index=\"all\" if you want all the indices)\nalpha_indices &lt;- microbiome::alpha(\n  physeq_rar,\n  index = c(\"observed\", \"diversity_gini_simpson\",\n          \"diversity_shannon\", \"evenness_pielou\",\n          \"dominance_relative\")\n)\n\n#save\nwrite.table(alpha_indices,\n            file = file.path(output_alpha, \"indices_alpha_resultat.txt\"),\n            sep = \"\\t\")\n\n#which type?\nclass(alpha_indices)\n\n[1] \"data.frame\"\n\n\n\n#see\nalpha_indices\n\n     observed diversity_gini_simpson diversity_shannon evenness_pielou\nS11B       36              0.9447863          3.146480       0.8780420\nS1B        35              0.9477924          3.177766       0.8937989\nS2B        43              0.9577758          3.408022       0.9060997\nS2S        36              0.9414576          3.112066       0.8684385\nS3B        41              0.9503989          3.275906       0.8821441\nS3S        38              0.9491313          3.246802       0.8925706\nS4B        40              0.9570249          3.350694       0.9083230\nS4S        40              0.9363446          3.097474       0.8396788\nS5B        32              0.9271578          2.978541       0.8594252\nS5S        33              0.9253250          2.993341       0.8560944\nS6B        41              0.9439556          3.213508       0.8653415\nS6S        28              0.8247810          2.440971       0.7325395\nS7B        36              0.9435901          3.157702       0.8811735\nS7S        44              0.9488744          3.278296       0.8663140\nS8B        33              0.9452117          3.108474       0.8890226\nS8S        39              0.9517578          3.307644       0.9028494\nS9B        36              0.9443038          3.105908       0.8667202\nS9S        33              0.9487545          3.180393       0.9095912\n     dominance_relative\nS11B         0.10274791\nS1B          0.10274791\nS2B          0.09677419\nS2S          0.10991637\nS3B          0.10991637\nS3S          0.10991637\nS4B          0.08721625\nS4S          0.14336918\nS5B          0.16606930\nS5S          0.18876941\nS6B          0.13620072\nS6S          0.38351254\nS7B          0.13022700\nS7S          0.10633214\nS8B          0.09438471\nS8S          0.09677419\nS9B          0.09438471\nS9S          0.10394265\n\n\nWhat can you notice for one sample?\nHow to show this graphically?\n\n\n4.1.2 Add the alpha indices result to your metadata (sample_data) phyloseq object\nImportant because many times you will probably want to add new variables in the phyloseq class object!!!\n\n#Turn into sample_data object : sample_data function\nalpha_indices &lt;- phyloseq::sample_data(alpha_indices)\n#See\nclass(alpha_indices)\n\n[1] \"sample_data\"\nattr(,\"package\")\n[1] \"phyloseq\"\n\n\n\n#Add alpha_indices to phyloseq sample_data object: merge_phyloseq function!\nphyseq_rar &lt;- phyloseq::merge_phyloseq(physeq_rar, alpha_indices)\n#See the result\nsample_data(physeq_rar)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#alpha-diversity-representations",
    "href": "practicals/alpha_diversity.html#alpha-diversity-representations",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "4.2 Alpha diversity representations",
    "text": "4.2 Alpha diversity representations\nThis section will show you how to plot by different ways the alpha diversity and its customization. Understand how it works!\n\n4.2.1 Alpha representations using phyloseq::plot_richness()\nYou are limited to the indices calculated by the phyloseq::estimate_richness function (i.e.”Observed”, “Chao1”, “ACE”, “Shannon”, “Simpson”, “InvSimpson”, “Fisher”).\n\n4.2.1.1 Selected indices + SampName\nx allow you to choose the column from sample_data(physeq_rar) for applying the label\n\nphyloseq::plot_richness(physeq_rar, x = \"SampName\",\n                        measures = c(\"Observed\", \"Shannon\", \"Simpson\"))\n\n\n\n\n\n\n\n4.2.2 Color by group: color = Geo & change sample name\nFor color option pass the column of sample_data(physeq_rar) that you want. Here different colors is applied depending on Geo (which is North and South, so 2 different colors)\n\nphyloseq::plot_richness(physeq_rar,\n                        x = \"Description\",\n                        color=\"Geo\",\n                        measures=c(\"Observed\", \"Shannon\", \"Simpson\"))\n\n\n\n\n\n\n4.2.3 Make box_plot by adding geom_boxplot function\n\nphyloseq::plot_richness(physeq_rar,\n                        x=\"Geo\",\n                        color=\"Geo\",\n                        measures=c(\"Observed\", \"Shannon\", \"Simpson\")) +\n  ggplot2::geom_boxplot()\n\n\n\n\n\n\n4.2.4 Make box_plot : geom_boxplot + fill color of boxplot (fill) + transparency (with alpha)\n\nphyloseq::plot_richness(physeq_rar,\n                        x = \"Geo\",\n                        measures = c(\"Observed\", \"Shannon\", \"Simpson\")) +\n  ggplot2::geom_boxplot(aes(fill = Geo), alpha = 0.4)\n\n\n\n\n\n\n4.2.5 Alpha representations using Microbiome::boxplot_alpha (not shown)\nAgain, you are limited to the indices calculated by the Microbiome::alpha function\n\n\n4.2.6 Alpha representations using ggplot2\nInterest: Freedom!! you can use ANY indices that you have calculated from different packages & included in sample_data\n\n#Before : Change your phyloseq class oject sample_data as a dataframe\nmetadata &lt;- data.frame(sample_data(physeq_rar))\n\n\n4.2.6.1 Boxplot, color control, points and Mean SD: stat_summary()\n\nggplot(metadata, aes(x = Geo, y = observed)) +\n  geom_boxplot(alpha = 0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color=c(\"#00AFBB\", \"#E7B800\")) +\n  geom_jitter(aes(colour = groupe), position = position_jitter(0.07), cex = 2.2) +\n  stat_summary(fun = mean, geom = \"point\", shape = 17, size = 3, color = \"white\") +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1, color = \"white\")\n\n\n\n\n\n\n4.2.6.2 Combine graphs on same figure: patchwork\n\n#Put your  graphs in different variables P1,P2,P3\np1 &lt;- ggplot(metadata, aes(x = Geo, y = observed)) +\n  geom_boxplot(alpha = 0.6,\n               fill = c(\"#00AFBB\",\"#E7B800\"),\n               color=c(\"#00AFBB\",\"#E7B800\")) +\n  geom_jitter(aes(colour = groupe), position = position_jitter(0.07), cex = 2.2) +\n  theme(axis.title.x = element_blank())\n\np2 &lt;- ggplot(metadata, aes(x = Geo, y = evenness_pielou)) +\n  geom_boxplot(alpha = 0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color = c(\"#00AFBB\", \"#E7B800\")) +\n  geom_jitter(aes(colour = groupe), position = position_jitter(0.07), cex = 2.2) +\n  theme(axis.title.x = element_blank())\n\np3 &lt;- ggplot(metadata, aes(x = Geo, y = diversity_gini_simpson)) +\n  geom_boxplot(alpha = 0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color = c(\"#00AFBB\", \"#E7B800\")) +\n  geom_jitter(aes(colour = groupe), position = position_jitter(0.07), cex = 2.2) +\n  theme(axis.title.x = element_blank())\n\n\n#Put the graph of p1, p2 and p3 on same Figure\np1 + p2 + p3 +\n  patchwork::plot_annotation(tag_levels = \"A\") +\n  patchwork::plot_layout(guides = \"collect\")"
  },
  {
    "objectID": "practicals/alpha_diversity.html#anova-parametric-follows-normal-distribution-and-at-least-3-groups",
    "href": "practicals/alpha_diversity.html#anova-parametric-follows-normal-distribution-and-at-least-3-groups",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "5.1 ANOVA: parametric (follows normal distribution) AND at least 3 groups",
    "text": "5.1 ANOVA: parametric (follows normal distribution) AND at least 3 groups\n\n5.1.0.1 Anova for Observed ASV and 4 groups\n\n# How many groups used? See the column \"groupe\" of metadata:\nfactor(metadata$groupe)\n\n [1] SGF NBF NBF NBS NBF NBS NBF NBS NBF NBS SGF SGS SGF SGS SGF SGS SGF SGS\nLevels: NBF NBS SGF SGS\n\n\n\n\n5.1.0.2 Variance\n\n# Check homogeneity of variance between groups\n# (avoid bias in ANOVA result & keep the power of the test)\n# H0= equality of variances in the different populations\nstats::bartlett.test(observed ~ groupe, metadata)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  observed by groupe\nBartlett's K-squared = 3.1798, df = 3, p-value = 0.3647\n\n\nConclusion?\n\n\n5.1.1 Alternative to Bartlett : Levene test (package car), less sensitive to normality deviation\nGlobal Test: Anova tell you if that some of the group means are different, but you don’t know which pairs of groups are different!\n\naov_observed &lt;- stats::aov(observed ~ groupe, metadata)\nsummary(aov_observed)\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\ngroupe       3  13.03   4.343   0.211  0.887\nResiduals   14 288.75  20.625               \n\n\n\n5.1.1.1 Which pairs of groups are different? -&gt; Post-hoc test: Tukey multiple pairwise-comparisons\n\nsignif_pairgroups &lt;- stats::TukeyHSD(aov_observed, method = \"bh\")\nsignif_pairgroups\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: stats::aov(formula = observed ~ groupe, data = metadata)\n\n$groupe\n         diff        lwr      upr     p adj\nNBS-NBF -1.45 -10.304898 7.404898 0.9631679\nSGF-NBF -1.80 -10.148478 6.548478 0.9217657\nSGS-NBF -2.20 -11.054898 6.654898 0.8866424\nSGF-NBS -0.35  -9.204898 8.504898 0.9994302\nSGS-NBS -0.75 -10.083882 8.583882 0.9953019\nSGS-SGF -0.40  -9.254898 8.454898 0.9991510"
  },
  {
    "objectID": "practicals/alpha_diversity.html#kruskal-wallis-non-parametric-at-least-three-groups",
    "href": "practicals/alpha_diversity.html#kruskal-wallis-non-parametric-at-least-three-groups",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "5.2 Kruskal-Wallis: non-parametric & at least three groups",
    "text": "5.2 Kruskal-Wallis: non-parametric & at least three groups\n\n5.2.0.1 Kruskal for diversity_shannon and 4 groups\nGlobal test\n\nstats::kruskal.test(diversity_shannon ~ groupe, data = metadata)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  diversity_shannon by groupe\nKruskal-Wallis chi-squared = 2.9544, df = 3, p-value = 0.3987\n\n\n\n\n5.2.0.2 Post hoc test: Dunn test (pairwise group test)\n\nsignifgroup &lt;- FSA::dunnTest(diversity_shannon ~ groupe,\n                           data = metadata,\n                           method = \"bh\")\n\nWarning: groupe was coerced to a factor.\n\n#See\nsignifgroup\n\n  Comparison          Z   P.unadj     P.adj\n1  NBF - NBS  1.5218359 0.1280502 0.7683013\n2  NBF - SGF  1.2439326 0.2135244 0.6405731\n3  NBS - SGF -0.3490449 0.7270556 0.7270556\n4  NBF - SGS  0.4048921 0.6855568 0.8226682\n5  NBS - SGS -1.0596259 0.2893148 0.5786297\n6  SGF - SGS -0.7678988 0.4425473 0.6638209"
  },
  {
    "objectID": "practicals/alpha_diversity.html#t-test-parametric-2-groups-i.e-north-vs.-sud",
    "href": "practicals/alpha_diversity.html#t-test-parametric-2-groups-i.e-north-vs.-sud",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "5.3 T-test: parametric, 2 groups (i.e North Vs. Sud)",
    "text": "5.3 T-test: parametric, 2 groups (i.e North Vs. Sud)\n\nstats::bartlett.test(observed ~ Geo, metadata)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  observed by Geo\nBartlett's K-squared = 0.38191, df = 1, p-value = 0.5366\n\n\n\nobserved_ttest &lt;- stats::t.test(observed ~ Geo, data = metadata)\n#see\nobserved_ttest\n\n\n    Welch Two Sample t-test\n\ndata:  observed by Geo\nt = 0.66008, df = 15.246, p-value = 0.5191\nalternative hypothesis: true difference in means between group North and group South is not equal to 0\n95 percent confidence interval:\n -2.966072  5.632739\nsample estimates:\nmean in group North mean in group South \n           37.55556            36.22222"
  },
  {
    "objectID": "practicals/alpha_diversity.html#wilcoxon-rank-sum-non-parametric-2-groups",
    "href": "practicals/alpha_diversity.html#wilcoxon-rank-sum-non-parametric-2-groups",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "5.4 Wilcoxon rank sum: non-parametric & 2 Groups",
    "text": "5.4 Wilcoxon rank sum: non-parametric & 2 Groups\n\npairwise_test &lt;- ggpubr::compare_means(diversity_shannon ~ Geo,\n                                       metadata,\n                                       method = \"wilcox.test\")\n#See\npairwise_test\n\n# A tibble: 1 × 8\n  .y.               group1 group2     p p.adj p.format p.signif method  \n  &lt;chr&gt;             &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 diversity_shannon South  North  0.863  0.86 0.86     ns       Wilcoxon\n\n\n\n5.4.1 Boxplot representation with p-value information\n\n#Boxplot as previously seen\ngraph_shan &lt;- ggplot(metadata, aes(x = Geo, y = diversity_shannon)) + \n  geom_boxplot(alpha=0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color = c(\"#00AFBB\", \"#E7B800\")) +\n  geom_jitter(aes(colour = groupe),\n              position = position_jitter(0.02) ,\n              cex=2.2)+\n  stat_summary(fun = mean, geom = \"point\",\n               shape = 17, size = 3,\n               color = \"white\")\n\n#Add p-value on graph\ngraph_shan + ggpubr::stat_pvalue_manual(\n  pairwise_test,\n  y.position = 3.5,\n  label = \"p.adj = {p.adj}\",\n  color = \"blue\",\n  linetype = 1,\n  tip.length = 0.01\n)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#abundance-transformation",
    "href": "practicals/alpha_diversity.html#abundance-transformation",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "6.1 Abundance Transformation",
    "text": "6.1 Abundance Transformation\n\n6.1.1 Counts in percentage using phyloseq::transform_sample_counts()\n\npourcentS &lt;- phyloseq::transform_sample_counts(physeq_rar, function(x) x/sum(x) * 100)\n\nSee plot:\n\nphyloseq::plot_bar(pourcentS)\n\n\n\n\nWhat are the separation lines?\n\n\n6.1.2 Summarise at a given taxonomic level with phyloseq::tax_glom()\nRemember ranks can be obtained with phyloseq::rank_names()\n\nphyloseq::rank_names(pourcentS)\n\n[1] \"Kingdom\" \"Phylum\"  \"Class\"   \"Order\"   \"Family\"  \"Genus\"   \"Species\"\n\n\n\nPhylum_glom &lt;- phyloseq::tax_glom(pourcentS,\n                                  taxrank = \"Phylum\",\n                                  NArm = FALSE)\n\n#Plot at Phylum taxonomic rank, with color\nphyloseq::plot_bar(Phylum_glom, fill = \"Phylum\") \n\n\n\n\nNArm?\n\n\n6.1.3 Filter phylum (mean of the line): phyloseq::filter_taxa()\nLet’s filter out the phylums with a mean relative abundance inferior to 1%\n\nPhylum_1 &lt;- phyloseq::filter_taxa(Phylum_glom,\n                                  flist = function(x) mean(x) &gt;= 1,\n                                  prune = TRUE)\n\n#Plot at Phylum taxonomic rank, with color\nphyloseq::plot_bar(Phylum_1, fill = \"Phylum\") \n\n\n\n\n\n\n6.1.4 How to save a table into a file: exemple of phylum taxonomic table\n\nwrite.table(df_export(otu_table(Phylum_glom)),\n            row.names = FALSE,\n            file = file.path(output_alpha, \"Phylum_pourcent.tsv\"),\n            sep = \"\\t\")\n\n\n\n6.1.5 Remove black lines\n\nphyloseq::plot_bar(Phylum_glom, \"Description\", fill = \"Phylum\") +\n  geom_bar(aes(colour = Phylum), stat = \"identity\")"
  },
  {
    "objectID": "practicals/alpha_diversity.html#microbiome-package",
    "href": "practicals/alpha_diversity.html#microbiome-package",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "6.2 Microbiome package",
    "text": "6.2 Microbiome package\n\n6.2.1 microbiome::aggregate_taxa()\n\n# Order Rank\nOrder_microb &lt;- microbiome::aggregate_taxa(pourcentS, \"Order\")\n\n#Filter at 1%\nOrder1 &lt;- phyloseq::filter_taxa(Order_microb, function(x) mean(x) &gt;= 1, prune = TRUE) \n\n\n\n6.2.2 microbiome::plot_composition()\n\np_order &lt;- microbiome::plot_composition(Order1,\n                                        otu.sort = \"abundance\",\n                                        sample.sort = \"Description\",\n                                        x.label = \"Description\",\n                                        plot.type = \"barplot\",\n                                        verbose = FALSE) +\n  ggplot2::labs(x = \"\", y = \"Relative abundance (%)\")\n#see\np_order\n\n\n\n\n\n#Average by group :average_by option\np_order_groupe &lt;- microbiome::plot_composition(Order1,\n                                               otu.sort = \"abundance\",\n                                               sample.sort = \"Description\",\n                                               x.label = \"Description\",\n                                               plot.type = \"barplot\",\n                                               verbose = FALSE,\n                                               average_by = \"Geo\") +\n  ggplot2::labs(x = \"\", y = \"Relative abundance (%)\")\n\n#see\np_order_groupe\n\n\n\n\n\n\n6.2.3 Interactive barplot with plotly::ggplotly()\n\nplotly::ggplotly(p_order)\n\n\n\n6.2.4 How to manage colors in barplots\nWith the number of Phyla, Order etc a barplot can become very confusing… Need to have distinct color for each taxonomic groups.\nUse the library RColorBrewer et scale_fill_manual() See here to understand the possibilities\nYou can visualise RColorBrewer’s palettes with the following command:\n\nRColorBrewer::display.brewer.all()\n\n\n\n\n\n\n6.2.5 Build your own palette\nLet’s assemble from two RColorBrewer’s palettes a single 13 colors palette\n\n#See Set2 colors\n(col1 &lt;- RColorBrewer::brewer.pal(name = \"Set2\", n = 8))\n\n[1] \"#66C2A5\" \"#FC8D62\" \"#8DA0CB\" \"#E78AC3\" \"#A6D854\" \"#FFD92F\" \"#E5C494\"\n[8] \"#B3B3B3\"\n\n#See  Paired colors \n(col2 &lt;- RColorBrewer::brewer.pal(name = \"Paired\", n = 5))\n\n[1] \"#A6CEE3\" \"#1F78B4\" \"#B2DF8A\" \"#33A02C\" \"#FB9A99\"\n\n#Build your set of colors using brewer.pal or your own colors\nmycolors &lt;- c(col1, col2)\n\n\n\n6.2.6 Use your palette in the p_order barplot\n\n#Use scale_fill_manual\np_order +\n  ggplot2::scale_fill_manual(\"Order\", values = mycolors) +\n  theme(legend.position = \"right\",\n        legend.text = element_text(size=8))\n\n\n\n\n\n\n6.2.7 To go even further in chosing colors\n\norder_color &lt;- c(\n  \"SAR11 clade\" = \"cyan3\",\n  \"Enterobacterales\" = \"#33A02C\",      # lime green\n  \"Synechococcales\" = \"#8DA0CB\",       # light steel blue\n  \"Rhodospirillales\"=\"pink\",\n  \"Marine Group II\"=\"red\",\n  \"Actinomarinales\"=\"purple\",\n  \"Pseudomonadales\" = \"#8B0000\",       # dark red\n  \"Unknown\"=\"#B3B3B3\",\n  \"Flavobacteriales\" = \"gold2\",\n  \"Chloroplast\" = \"#FDBF6F\",       # light orange\n  \"Rhodobacterales\" = \"darkorange1\"    # dark orange\n)\n\np_order +\n  ggplot2::scale_fill_manual(\"Order\", values = order_color) +\n  theme(legend.position = \"right\",\n        legend.text = element_text(size=8))"
  },
  {
    "objectID": "practicals/alpha_diversity.html#other-data-manipulation-select-specific-taxa-merge-samples",
    "href": "practicals/alpha_diversity.html#other-data-manipulation-select-specific-taxa-merge-samples",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "6.3 Other data Manipulation : select specific taxa, merge samples",
    "text": "6.3 Other data Manipulation : select specific taxa, merge samples\n\n6.3.1 Select Actinobacteria AND Bacteroidetes: phyloseq::subset_taxa()\n\nmyselection1 &lt;- phyloseq::subset_taxa(Phylum_glom, Phylum == \"Actinobacteriota\" | Phylum == \"Bacteroidota\")\n\nphyloseq::plot_bar(myselection1, x = \"Description\", fill = \"Phylum\")\n\n\n\n\n\nphyloseq::plot_bar(myselection1, x = \"Description\",\n                   fill=\"Phylum\", facet_grid = ~Phylum) \n\n\n\n\n\n\n6.3.2 Keep all with the exception of a class, a genus etc (e.g. contamination)\n\nmyselection2 &lt;- phyloseq::subset_taxa(physeq, Class != \"Thermoplasmata\" | is.na(Class))\n\n\n\n6.3.3 Understand:\n! = means IS NOT\n| = AND\nIs.na = do not remove the NA (Not Assigned at the Class rank), by default it will be removed. be careful!\n\n\n6.3.4 Merge samples (groups, duplicates etc)\nUse a column from metadata to group/merge samples (North & South)\n\n(NordSud &lt;- phyloseq::merge_samples(physeq_rar, \"Geo\"))\n\nWarning in asMethod(object): NAs introduced by coercion\n\nWarning in asMethod(object): NAs introduced by coercion\n\nWarning in asMethod(object): NAs introduced by coercion\n\nWarning in asMethod(object): NAs introduced by coercion\n\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 209 taxa and 2 samples ]\nsample_data() Sample Data:       [ 2 samples by 26 sample variables ]\ntax_table()   Taxonomy Table:    [ 209 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 209 tips and 208 internal nodes ]\n\n\n\n\n6.3.5 Sample selection: phyloseq::subset_samples()\n\n(sub_North &lt;- phyloseq::subset_samples(pourcentS, Geo == \"North\"))\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 209 taxa and 9 samples ]\nsample_data() Sample Data:       [ 9 samples by 26 sample variables ]\ntax_table()   Taxonomy Table:    [ 209 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 209 tips and 208 internal nodes ]\nrefseq()      DNAStringSet:      [ 209 reference sequences ]\n\n\n\n\n6.3.6 Alternative way: phyloseq::prune_samples\nDefine what you want to keep\n\nkeep &lt;- c(\"S1B\", \"S2S\")\n\nThen extract these samples from pourcentS phyloseq object\n\nkeep2samples &lt;- phyloseq::prune_samples(keep, pourcentS)\nsample_names(keep2samples)\n\n[1] \"S1B\" \"S2S\""
  },
  {
    "objectID": "practicals/alpha_diversity.html#retrieve-sequences-from-a-phyloseq-object",
    "href": "practicals/alpha_diversity.html#retrieve-sequences-from-a-phyloseq-object",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "6.4 Retrieve sequences from a phyloseq object",
    "text": "6.4 Retrieve sequences from a phyloseq object\n\n6.4.1 One sequence:\n\nBiostrings::writeXStringSet(physeq_rar@refseq[\"ASV1\"],\n                            filepath = file.path(output_alpha,\"ASV1.fasta\"),\n                            format = \"fasta\")\n\n\n\n6.4.2 By name\n\nlistASV &lt;- c(\"ASV2\", \"ASV8\", \"ASV32\", \"ASV58\")\n\n\nBiostrings::writeXStringSet(physeq_rar@refseq[listASV],\n                            filepath = file.path(output_alpha,\"several_asvs.fasta\"),\n                            format = \"fasta\")\n\n\n\n6.4.3 From a selection\nLet’s export a fasta files of all ASVs with a maximum relative abundance superior to 10% in North samples:\n\nphyloseq::subset_samples(pourcentS, Geo == \"North\") |&gt;\n  phyloseq::filter_taxa(flist = function(x) max(x) &gt;= 10, prune = TRUE) |&gt;\n  phyloseq::refseq() |&gt;\n  Biostrings::writeXStringSet(\n    filepath = file.path(output_alpha, \"fancy_selection_asvs.fasta\"),\n    format = \"fasta\"\n  )\n\n\n\n6.4.4 Retrieve all sequences\n\nBiostrings::writeXStringSet(physeq_rar@refseq,\n                            filepath = file.path(output_alpha,\"all_asvs.fasta\"),\n                            format = \"fasta\")"
  },
  {
    "objectID": "practicals/beta_diversity.html",
    "href": "practicals/beta_diversity.html",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "",
    "text": "library(phyloseq)\nlibrary(ggplot2)\nlibrary(dplyr)\ndevtools::load_all()\n\n\noutput_beta &lt;- here::here(\"outputs\", \"beta_diversity\")\nif (!dir.exists(output_beta)) dir.create(output_beta, recursive = TRUE)\n\n\n\n\nLoad the data and inspect the phyloseq object\n\nphyseq &lt;- readRDS(here::here(\"data\",\n                             \"asv_table\",\n                             \"phyloseq_object_alpha_beta_div.rds\"))"
  },
  {
    "objectID": "practicals/beta_diversity.html#load-some-libraries",
    "href": "practicals/beta_diversity.html#load-some-libraries",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "",
    "text": "library(phyloseq)\nlibrary(ggplot2)\nlibrary(dplyr)\ndevtools::load_all()\n\n\noutput_beta &lt;- here::here(\"outputs\", \"beta_diversity\")\nif (!dir.exists(output_beta)) dir.create(output_beta, recursive = TRUE)"
  },
  {
    "objectID": "practicals/beta_diversity.html#load-the-data-in-r",
    "href": "practicals/beta_diversity.html#load-the-data-in-r",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "",
    "text": "Load the data and inspect the phyloseq object\n\nphyseq &lt;- readRDS(here::here(\"data\",\n                             \"asv_table\",\n                             \"phyloseq_object_alpha_beta_div.rds\"))"
  },
  {
    "objectID": "practicals/beta_diversity.html#normalisation",
    "href": "practicals/beta_diversity.html#normalisation",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "2.1 Normalisation",
    "text": "2.1 Normalisation\nHere we will consider two approaches for library size normalization. The first will involve simply subsampling the data without replacement; however, this approach comes with limitations that are well described here.\nThe second will employ a compositional data analysis approach and involves working with log-ratios.\n\n2.1.1 Rarefaction\nWe will subsample reads from each sample without replacement to a constant depth. Let see first how many reads we have per sample:\n\nrowSums(physeq@otu_table@.Data)\n\nS11B  S1B  S2B  S2S  S3B  S3S  S4B  S4S  S5B  S5S  S6B  S6S  S7B  S7S  S8B  S8S \n 975  837  893  983  878  889  917 1077 1018 1006 1076  937  878  936  846  958 \n S9B  S9S \n 888  991 \n\n\nWe will plot these results and look at the rank abudance of the reads\n\nreadsumsdf &lt;- data.frame(nreads = sort(taxa_sums(physeq), decreasing = TRUE),\n                        sorted = 1:ntaxa(physeq),\n                        type = \"OTUs\")\n\ntmp &lt;- data.frame(nreads = sort(sample_sums(physeq), decreasing = TRUE), \n                  sorted = 1:nsamples(physeq),\n                  type = \"Samples\")\n\nreadsumsdf &lt;- rbind(readsumsdf, tmp)\n\nhead(readsumsdf)\n\n     nreads sorted type\nASV1   1558      1 OTUs\nASV2    973      2 OTUs\nASV3    899      3 OTUs\nASV4    833      4 OTUs\nASV5    767      5 OTUs\nASV6    654      6 OTUs\n\n\n\nggplot(readsumsdf, aes(x = sorted, y = nreads)) +\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"Total number of reads\") +\n  scale_y_log10() +\n  facet_wrap(~type, nrow = 1, scales = \"free\")\n\n\n\n\nWe will now transform to equal sample sum (Only if the number of reads is not the same between samples) in order to be sure that the sampling effort is the same between samples.\n\n# set the seed for random sampling\n# it allows reproductibility\nset.seed(10000)\n\n# minimum reads in a sample\nmin(rowSums(physeq@otu_table@.Data))\n\n[1] 837\n\n\nThe minimun number of reads in a sample is 837. Lets do the randomization at 800 reads per sample in order to apply the process also in the sample having this minimum of reads.\n\nphyseq_rar &lt;- rarefy_even_depth(physeq, sample.size = 800)\nrowSums(physeq_rar@otu_table@.Data) #how many reads per sample\n\nS11B  S1B  S2B  S2S  S3B  S3S  S4B  S4S  S5B  S5S  S6B  S6S  S7B  S7S  S8B  S8S \n 800  800  800  800  800  800  800  800  800  800  800  800  800  800  800  800 \n S9B  S9S \n 800  800 \n\n\n\nphyseq\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 213 taxa and 18 samples ]\nsample_data() Sample Data:       [ 18 samples by 21 sample variables ]\ntax_table()   Taxonomy Table:    [ 213 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 213 tips and 212 internal nodes ]\nrefseq()      DNAStringSet:      [ 213 reference sequences ]\n\n\n\nphyseq_rar\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 208 taxa and 18 samples ]\nsample_data() Sample Data:       [ 18 samples by 21 sample variables ]\ntax_table()   Taxonomy Table:    [ 208 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 208 tips and 207 internal nodes ]\nrefseq()      DNAStringSet:      [ 208 reference sequences ]\n\n\n\n\n2.1.2 Centered log-ratio (CLR) transformation\nA detailed discussion of compositional data analysis (CoDA) is beyond the scope of this session but just know that microbiome data is compositional since reads total is constrained by the sequencing depth. Relative abundances (proportions) are obviously constraint by a sum equal to one. This total constraint induces strong dependencies among the observed abundances of the different taxa. In fact, nor the absolute abundance (read counts) nor the relative abundance (proportion) of one taxon alone are informative of the real abundance of the taxon in the environment. Instead, they provide information on the relative measure of abundance when compared to the abundance of other taxa in the same sample. For this reason, these data fail to meet many of the assumptions of our favorite statistical methods developed for unconstrained random variables. Working with ratios of compositional elements lets us transform these data to the Euclidian space and apply our favorite methods. There are different types of log-ratio “transformations” including the additive log-ratio, centered log-ratio, and isometric log-ratio transforms. Find more information here, here and here\nLet’s perform the CLR transformation:\n\n # we first replace the zeros using\n # the Count Zero Multiplicative approach\ntmp &lt;- zCompositions::cmultRepl(physeq@otu_table,\n                                method = \"CZM\",\n                                label = 0,\n                                z.warning = 1)\n\n# generate the centered log-ratio transformed. ASVs are in rows!!!!!\nphyseq_clr_asv &lt;- apply(tmp, 1, function(x) log(x) - mean(log(x)))\n\n\n#create a new phyloseq object with CLR tranformed counts\nphyseq_clr &lt;- physeq\notu_table(physeq_clr) &lt;- otu_table(t(physeq_clr_asv),\n                                   taxa_are_rows = FALSE)\ndata.frame(physeq_clr@otu_table@.Data[1:5, 1:10])\n\n         ASV1       ASV2     ASV3       ASV4     ASV5     ASV6       ASV7\nS11B 5.172800  3.6295018 4.853277  4.6591212 4.876534 4.099505  4.4536772\nS1B  4.630559 -0.6264429 3.561361 -0.6264429 4.357692 4.297068 -0.6264429\nS2B  4.065517 -0.7557464 3.859665  3.0123670 4.041986 4.255561 -0.7557464\nS2S  5.042825  4.8740037 4.738829  2.8930022 5.003215 4.169296  3.9916145\nS3B  4.440233 -0.6954498 3.828432 -0.6954498 4.254516 4.653155 -0.6954498\n           ASV8       ASV9      ASV10\nS11B  3.9369865  4.1241980 -0.6524920\nS1B  -0.6264429  3.7217036  4.4863097\nS2B  -0.7557464 -0.7557464  4.0655169\nS2S   4.6847617  4.2367369 -0.6558837\nS3B  -0.6954498 -0.6954498  4.4057470\n\n\nWe can see that the values are now no longer counts, but rather the dominance (or lack thereof) for each taxa relative to the geometric mean of all taxa on the logarithmic scale. This centered log-ratio (CLR) transformed table can be used directly in a PCA or RDA to generate a beta diveristy ordination using the Aitchison distance.\nTips: This chunk can be coded in one line using the microbiome package: physeq_clr &lt;- microbiome::transform(physeq, “clr”)"
  },
  {
    "objectID": "practicals/beta_diversity.html#treemaps",
    "href": "practicals/beta_diversity.html#treemaps",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "3.1 Treemaps",
    "text": "3.1 Treemaps\n\n3.1.1 What for?\nLooking at the composition of the meta community with a treemap allow roughly to detect if some taxa should not be present (contaminants) and observe if the dominanting taxa correspond to the habitat studied.\n\n\n3.1.2 Using the package treemap\n\n#pdf(file=\"treemap.pdf\", wi = 7, he = 7)\n\ntreemap::treemap(physeq_phylum, index=c(\"Class\", \"Family\"), vSize=\"Abundance\", type=\"index\",\n        fontsize.labels=c(15,12),                # size of labels. Give the size per level of aggregation: size for group, size for subgroup, sub-subgroups...\n        fontcolor.labels=c(\"white\",\"black\"),    # Color of labels\n        fontface.labels=c(2,1),                  # Font of labels: 1,2,3,4 for normal, bold, italic, bold-italic...\n        align.labels=list(\n          c(\"center\", \"center\"), \n          c(\"left\", \"bottom\")),                 # Where to place labels in the rectangle?\n        overlap.labels=0.5,                      # number between 0 and 1 that determines the tolerance of the overlap between labels. 0 means that labels of lower levels are not printed if higher level labels overlap, 1  means that labels are always printed. In-between values, for instance the default value .5, means that lower level labels are printed if other labels do not overlap with more than .5  times their area size.\n        inflate.labels=F, # If true, labels are bigger when rectangle is bigger.\n        border.col=c(\"black\",\"white\"),          #Color of the boders separating the taxonomic levels\n        border.lwds=c(4,2),\n        #palette = \"Set3\",                        # Select your color palette from the RColorBrewer presets or make your own.\n        fontsize.title=12\n)\n\n\n\n#dev.off()\n\n\n\n3.1.3 Using the package treemapify\n\ntmp &lt;- transform_sample_counts(physeq,function(x) {x/sum(x)} ) %&gt;%\n  psmelt() %&gt;%\n  group_by(Family, Class) %&gt;%\n  summarise(abundance = sum(Abundance)) %&gt;%\n  na.omit()\n\nggplot(tmp,aes(area=abundance,label=Family,fill=Class,subgroup=Class))+\n  treemapify::geom_treemap()+\n  treemapify::geom_treemap_subgroup_border() +\n  treemapify::geom_treemap_subgroup_text(place = \"centre\",\n                                         grow = T,\n                                         alpha = 0.5,\n                                         colour = \"black\",\n                                         fontface = \"italic\",\n                                         min.size = 0) +\n  treemapify::geom_treemap_text(colour = \"white\",\n                                place = \"topleft\",\n                                reflow = TRUE)+\n  theme(legend.position=\"none\")\n\n\n\nggsave(here::here(output_beta,\"treemap_treemapify.pdf\"))\n\n\n\n3.1.4 Observations\nHere we can observe that the meta-community is dominated by typical marine clades such as the AEGEAN marine group in Alphaproteobacteria or the SAR86 clade in Gammaproteobacteria. So everything is good so far."
  },
  {
    "objectID": "practicals/beta_diversity.html#stacked-barplots",
    "href": "practicals/beta_diversity.html#stacked-barplots",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "3.2 Stacked barplots",
    "text": "3.2 Stacked barplots\n\nggplot(physeq_phylum, aes(x = Sample, y = Abundance, fill = Family)) + \n  geom_bar(stat = \"identity\") +\n  # facet_wrap(~Treatment, nrow=1, scales = \"free_x\") +\n  ylab(\"Relative Abundance (Family &gt; 2%)\") +\n  scale_y_continuous(expand = c(0,0)) + #remove the space below the 0 of the y axis in the graph\n  ggtitle(\"Community composition\") +\n  theme_bw() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_text(angle = 45, size = 10,\n                                   hjust = 0.5, vjust = 0.8),\n        axis.ticks.x = element_blank(),\n        panel.background = element_blank(), \n        panel.grid.major = element_blank(),  #remove major-grid labels\n        panel.grid.minor = element_blank())  #remove minor-grid labels\n\n\n\nggsave(here::here(output_beta, \"asv_composition.pdf\"))\n\nHere we can already see some differences in the composition at the Family level with an enrichment in Pseudoalteromonadaceae in some samples and Cyanobiaceae. Note that we are limited by our ability to discernate between than more than 9-12 colors in this kind of graphic."
  },
  {
    "objectID": "practicals/beta_diversity.html#calculation",
    "href": "practicals/beta_diversity.html#calculation",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "4.1 Calculation",
    "text": "4.1 Calculation\nOver the years, ecologists have invented numerous ways of quantifying dissimilarity between pairs of ecosystems.Four components of species community beta-diveristy can be assessed using different distances or dissimilarities. Compostional distances or dissimilarities do not consider the relative abundance of taxa, only their presence (detection) or absence, which can make it (overly) sensitive to rare taxa, sequencing artefacts, and abundance filtering choices. Conversely, structural distances or dissimilarities do put (perhaps too much) more importance on highly abundant taxa, when determining dissimilarities. Phylogentic distances or dissimilarities take into account the phylogenetic relatedness of the taxa / sequences in your samples when calculating dissimilarity while taxnomic distances or dissimilarities do not.\n\n4.1.1 Compositional taxonomic\n\nphyseq_rar_jaccard &lt;- phyloseq::distance(physeq_rar,\n                                         method = \"jaccard\",\n                                         binary = TRUE)\n\n# trick to avoid negative egein values in PCoA\n# it recreates what ade4::dist.binary() does\nphyseq_rar_jaccard &lt;- sqrt(physeq_rar_jaccard)\n\n\n\n4.1.2 Compositional phylogenetic (Unweighted unifrac)\nThe GUniFrac package requires a rooted tree as input data. We can use the function midpoint() from the phangorn package to obtain the rooted tree.\nTo check if your tree is rooted, you may use this function:\n\nape::is.rooted(physeq_rar@phy_tree)\n\n[1] TRUE\n\n\nIf not, you can use the function midpoint() from the package phangorn\n\nphy_tree(physeq_rar) &lt;- phangorn::midpoint(physeq_rar@phy_tree)\n\nNow, Unifrac distances can be calculated\n\nunifracs &lt;- GUniFrac::GUniFrac(physeq_rar@otu_table@.Data, physeq_rar@phy_tree, alpha=c(0, 0.5, 1))$unifracs\n\nThe unifracs object is a list containing 5 distance matrices correspoonding to the weighted UniFrac (d_1), the unweighted UniFrac (d_UW), Variance adjusted UniFrac (d_VAW), GUniFrac with alpha = 0, GUniFrac with alpha = 0.5\n\nphyseq_rar_du &lt;- unifracs[, , \"d_UW\"]   # Unweighted UniFrac\n\n\n\n4.1.3 Structural taxonomic (Bray-Curtis)\n\n# physeq_rar_bray &lt;- vegan::vegdist(physeq_rar@otu_table@.Data, method = \"bray\")\n\ntmp &lt;- transform_sample_counts(physeq,function(x) {x/sum(x)} )\nphyseq_rar_bray &lt;- phyloseq::distance(tmp, method = \"bray\")\n\n\n\n4.1.4 Structural phylogenetic (Weighted UniFrac)\n\nphyseq_rar_dw &lt;- unifracs[, , \"d_1\"]   # Weighted UniFrac"
  },
  {
    "objectID": "practicals/beta_diversity.html#visualisation",
    "href": "practicals/beta_diversity.html#visualisation",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "4.2 Visualisation",
    "text": "4.2 Visualisation\nYou can actually calculate all these distances directly in phyloseq using dist.calc(). There are currently 44 explicitly supported method options in the phyloseq package, see here for more informations. Here, we will loop through each distance method, save each plot to a list and then plot these results in a combined graphic using ggplot2.\n\ndist_methods &lt;- unlist(distanceMethodList)\ndata.frame(position = seq_along(dist_methods),\n           dist_methods)\n\n            position dist_methods\nUniFrac1           1      unifrac\nUniFrac2           2     wunifrac\nDPCoA              3        dpcoa\nJSD                4          jsd\nvegdist1           5    manhattan\nvegdist2           6    euclidean\nvegdist3           7     canberra\nvegdist4           8         bray\nvegdist5           9   kulczynski\nvegdist6          10      jaccard\nvegdist7          11        gower\nvegdist8          12     altGower\nvegdist9          13     morisita\nvegdist10         14         horn\nvegdist11         15    mountford\nvegdist12         16         raup\nvegdist13         17     binomial\nvegdist14         18         chao\nvegdist15         19          cao\nbetadiver1        20            w\nbetadiver2        21           -1\nbetadiver3        22            c\nbetadiver4        23           wb\nbetadiver5        24            r\nbetadiver6        25            I\nbetadiver7        26            e\nbetadiver8        27            t\nbetadiver9        28           me\nbetadiver10       29            j\nbetadiver11       30          sor\nbetadiver12       31            m\nbetadiver13       32           -2\nbetadiver14       33           co\nbetadiver15       34           cc\nbetadiver16       35            g\nbetadiver17       36           -3\nbetadiver18       37            l\nbetadiver19       38           19\nbetadiver20       39           hk\nbetadiver21       40          rlb\nbetadiver22       41          sim\nbetadiver23       42           gl\nbetadiver24       43            z\ndist1             44      maximum\ndist2             45       binary\ndist3             46    minkowski\ndesigndist        47          ANY\n\n#Select the distances of interest\ndist_methods &lt;- dist_methods[c(1, 2, 10, 8)]\ndist_methods\n\n  UniFrac1   UniFrac2   vegdist6   vegdist4 \n \"unifrac\" \"wunifrac\"  \"jaccard\"     \"bray\" \n\n#Loop through each distance method, save each plot to a list, called plist.\nplist &lt;- vector(\"list\")\n\nfor(i in dist_methods){\n  # Calculate distance matrix\n  iDist &lt;- phyloseq::distance(physeq_rar, method = i)\n  # Calculate PCoA ordination\n  iMDS &lt;- ordinate(physeq_rar, \"MDS\", distance = iDist)\n  ## Make plot. Don't carry over previous plot (if error, p will be blank)\n  p &lt;- NULL\n  # Create plot, store as temp variable, p\n  p &lt;- plot_ordination(physeq_rar, iMDS, color= \"Geo\")\n  # Add title to each plot\n  p &lt;- p + ggtitle(paste(\"MDS using distance method \", i, sep=\"\"))\n  # Save the graphic to list\n  plist[[i]] = p \n}\n\nCombine results\n\ndf &lt;- plyr::ldply(plist, function(x) x$data)\nhead(df)\n\n      .id      Axis.1      Axis.2 SampName   Geo Description groupe Pres\n1 unifrac  0.09023445  0.06150644     S11B South     South5B    SGF   35\n2 unifrac -0.21048836 -0.19946687      S1B North     North1B    NBF   52\n3 unifrac -0.21001002 -0.08655455      S2B North     North2B    NBF   59\n4 unifrac  0.12583068  0.07022248      S2S North     North2S    NBS    0\n5 unifrac -0.31465014 -0.06077941      S3B North     North3B    NBF   74\n6 unifrac -0.16616937  0.01827175      S3S North     North3S    NBS    0\n  PicoEuk Synec Prochloro NanoEuk Crypto SiOH4   NO2   NO3   NH4   PO4    NT\n1    5370 46830       580    6010   1690 3.324 0.083 0.756 0.467 0.115 9.539\n2     660 32195     10675     955    115 1.813 0.256 0.889 0.324 0.132 9.946\n3     890 25480     16595     670    395 2.592 0.105 1.125 0.328 0.067 9.378\n4     890 25480     16595     670    395 3.381 0.231 0.706 0.450 0.109 8.817\n5     835 13340     25115    1115    165 1.438 0.057 1.159 0.369 0.174 8.989\n6     715 26725     16860     890    200 1.656 0.098 0.794 0.367 0.095 7.847\n     PT   Chla       T       S Sigma_t\n1 4.138 0.0182 23.0308 38.9967 26.9631\n2 3.565 0.0000 22.7338 37.6204 26.0046\n3 3.391 0.0000 22.6824 37.6627 26.0521\n4 3.345 0.0000 22.6854 37.6176 26.0137\n5 2.568 0.0000 21.5296 37.5549 26.2987\n6 2.520 0.0000 22.5610 37.5960 26.0332\n\nnames(df)[1] &lt;- \"distance\"\n\nggplot(df, aes(Axis.1, Axis.2, color = Geo)) +\n  geom_point(size=3, alpha=0.5) +\n  theme_bw() +\n  facet_wrap(~distance, scales=\"free\") +\n  ggtitle(\"PCoA (MDS) on various distance metrics\")\n\n\n\n\nWe can observe that there is a fairly good separation between North and South samples except for the Weighted UniFrac distance which tends to give too much weight to the most abundant ASVs that are also the most frequent."
  },
  {
    "objectID": "practicals/beta_diversity.html#hierarchical-ascendant-classification-hac",
    "href": "practicals/beta_diversity.html#hierarchical-ascendant-classification-hac",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "5.1 Hierarchical ascendant classification (HAC)",
    "text": "5.1 Hierarchical ascendant classification (HAC)\nA first step in many microbiome projects is to examine how samples cluster on some measure of (dis)similarity. There are many ways to do perform such clustering, see here. Since microbiome data is compositional, we will perform here a hierarchical ascendant classification (HAC) of samples based on Aitchison distance.\n\n#distance matrix calculation\nphyseq_clr_dist &lt;- phyloseq::distance(physeq_clr, method = \"euclidean\")\n\nLet’s see the different clustering obtained with the four aggregation criterion\n\n#Simple aggregation criterion\nspe_single &lt;- hclust(physeq_clr_dist, method = \"single\")\n\n#Complete aggregation criterion\nspe_complete &lt;- hclust(physeq_clr_dist, method = \"complete\")\n\n#Unweighted pair group method with arithmetic mean\nspe_upgma &lt;- hclust(physeq_clr_dist, method = \"average\")\n\n#Ward criterion\nspe_ward &lt;- hclust(physeq_clr_dist, method = \"ward.D\")\n\npar(mfrow = c(2, 2))\nplot(spe_single, main = \"single\")\nplot(spe_complete, main = \"complete\")\nplot(spe_upgma, main = \"UPGMA\")\nplot(spe_ward, main = \"ward\")\n\n\n\n\nRemember that clustering is a heuristic procedure, not a statistical test. The choices of an association coefficient and a clustering method influence the result. This stresses the importance of choosing a method that is consistent with the aims of the analysis."
  },
  {
    "objectID": "practicals/beta_diversity.html#cophenetic-correlation",
    "href": "practicals/beta_diversity.html#cophenetic-correlation",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "5.2 Cophenetic Correlation",
    "text": "5.2 Cophenetic Correlation\nA cophenetic matrix is a matrix representing the cophenetic distances among all pairs of objects. A Pearson’s r correlation, called the cophenetic correlation in this context, can be computed between the original dissimilarity matrix and the cophenetic matrix. The method with the highest cophenetic correlation may be seen as the one that produced the best clustering model for the distance matrix.\nLet us compute the cophenetic matrix and correlation of four clustering results presented above, by means of the function cophenetic() of package stats.\n\n#Cophenetic correlation\nspe_single_coph &lt;- cophenetic(spe_single)\ncor(physeq_clr_dist, spe_single_coph)\nspe_complete_coph &lt;- cophenetic(spe_complete)\ncor(physeq_clr_dist, spe_complete_coph)\nspe_upgma_coph &lt;- cophenetic(spe_upgma)\ncor(physeq_clr_dist, spe_upgma_coph)\nspe_ward_coph &lt;- cophenetic(spe_ward)\ncor(physeq_clr_dist, spe_ward_coph)\n\nWhich dendrogram retains the closest relationship to the Aitchinson distance matrix?\nTo illustrate the relationship between a distance matrix and a set of cophenetic matrices obtained from various methods, one can draw Shepard-like diagrams (Legendre and Legendre 1998, p. 377) by plotting the original distances against the cophenetic distances.\n\nplot_coph_cor &lt;- function(cophenetic_distance, hclust_type){\n\n  # first calculate the correlation between\n  # the cophenetic distance and the observed distance\n  cor_res &lt;- round(cor(physeq_clr_dist, cophenetic_distance),3)\n\n  # generate a scatter plot to visualise\n  # the relationship\n  plot(x = physeq_clr_dist,\n     y = cophenetic_distance,\n     xlab = \"Aitchison distance\",\n     ylab = \"Cophenetic distance\",\n     xlim = c(10, 35), ylim = c(10, 35),\n     main = c(hclust_type, paste(\"Cophenetic correlation \", cor_res)))\n  abline(0, 1)\n}\n\npar(mfrow=c(2,2))\n\nplot_coph_cor(cophenetic_distance = spe_complete_coph,\n              hclust_type = \"Single linkage\")\n\nplot_coph_cor(cophenetic_distance = spe_complete_coph,\n              hclust_type = \"Complete linkage\")\n\nplot_coph_cor(cophenetic_distance = spe_upgma_coph,\n              hclust_type = \"Average linkage\")\n\nplot_coph_cor(cophenetic_distance = spe_ward_coph,\n              hclust_type = \"Ward linkage\")\n\n\n\n\nIt seems clear that the UPGMA method give the most faithful representation of original distances."
  },
  {
    "objectID": "practicals/beta_diversity.html#looking-for-interpretable-clusters",
    "href": "practicals/beta_diversity.html#looking-for-interpretable-clusters",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "5.3 Looking for Interpretable Clusters",
    "text": "5.3 Looking for Interpretable Clusters\nTo interpret and compare clustering results, users generally look for interpretable clusters. This means that a decision must be made: at what level should the dendrogram be cut? Many indices (more than 30) has been published in the literature for finding the right number of clusters in a dataset. The process has been covered here. The fusion level values of a dendrogram are the dissimilarity values where a fusion between two branches of a dendrogram occurs. Plotting the fusion level values may help define cutting levels. Let us plot the fusion level values for for the UPGMA dendrogram.\n\n#Fusion level plot\npar(mfrow = c(1, 1))\n\nplot(x = spe_upgma$height,\n     y = phyloseq::nsamples(physeq_clr):2,\n     type = \"S\",\n     main = \"Fusion levels - Aitchison - Average\",\n     ylab = \"k (number of cluster)\",\n     xlab = \"h (node height)\")\n\ntext(x = spe_upgma$height,\n     y = phyloseq::nsamples(physeq_clr):2,\n     labels = phyloseq::nsamples(physeq_clr):2,\n     col = \"red\",\n     cex = 0.8)\n\n\n\n\nFrom right to left, this first graph shows clear jumps after each fusion between 2 groups. We’ll use the package NbClust which will compute, with a single function call, 24 indices for confirming the right number of clusters in the dataset:\n\ninstall.packages(\"NbClust\", lib = \".\")\nlibrary(\"NbClust\", lib.loc = \".\")\nnclust &lt;- nb_clust_all(data = t(physeq_clr_asv), seed = 1000)\n\n[1] \"Trying kl index...\"\n[1] \"Trying ch index...\"\n[1] \"Trying hartigan index...\"\n[1] \"Trying scott index...\"\n[1] \"Trying cindex index...\"\n[1] \"Trying db index...\"\n[1] \"Trying silhouette index...\"\n[1] \"Trying duda index...\"\n[1] \"Trying pseudot2 index...\"\n[1] \"Trying beale index...\"\n[1] \"Trying ratkowsky index...\"\n[1] \"Trying ball index...\"\n[1] \"Trying ptbiserial index...\"\n[1] \"Trying gap index...\"\n[1] \"Trying frey index...\"\n[1] \"Trying mcclain index...\"\n[1] \"Trying gamma index...\"\n[1] \"Trying gplus index...\"\n[1] \"Trying tau index...\"\n[1] \"Trying dunn index...\"\n[1] \"Trying hubert index...\"\n\n\n\n\n\n*** : The Hubert index is a graphical method of determining the number of clusters.\n                In the plot of Hubert index, we seek a significant knee that corresponds to a \n                significant increase of the value of the measure i.e the significant peak in Hubert\n                index second differences plot. \n \n[1] \"Trying sdindex index...\"\n[1] \"Trying dindex index...\"\n\n\n\n\n\n*** : The D index is a graphical method of determining the number of clusters. \n                In the plot of D index, we seek a significant knee (the significant peak in Dindex\n                second differences plot) that corresponds to a significant increase of the value of\n                the measure. \n \n[1] \"Trying sdbw index...\"\nBased on a number of criteria, we will select 2 clusters.\n\n\nNbClust confirm the identification of two clusters of samples. We will go back to the dendrogram and cut it at the corresponding distances.\n\n#Cut the dendrogram in order to obtain K groups and compare their compositionC\nk &lt;- 2 # Number of groups given by the fusion level plot\n\n#Cut the dendrogram\nspe_upgma_clust &lt;- cutree(tree = spe_upgma, k = k)\ntable(spe_upgma_clust)\n\nspe_upgma_clust\n 1  2 \n12  6 \n\nspe_upgma_clust2 &lt;- data.frame(UPGMA_clusters = spe_upgma_clust)\n\n\n# Plot dendrogram with group labels\nplot(spe_upgma,\n     hang = -1,\n     ylab = \"Height\",\n     main=\"Aitchison distance - UPGMA\")\n\nrect.hclust(spe_upgma,\n            k = k,\n            border = 2:6,\n            cluster = spe_upgma_clust)\n\nlegend(\"topright\",\n       paste(\"Cluster\", 1:k),\n       pch = 22,\n       col = 2:(k + 1),\n       bty = \"n\")\n\n\n\n\nDo the groups obtained make sense? Do you obtain enough groups containing a substantial number of sites?\nThere are several ways to measure the robustness of a clustering algorithm. Three commonly used metrics are the Dunn index, Davis-Bouldin index and Silhoutte index. The Dunn index is calculated as a ratio of the smallest inter-cluster distance to the largest intra-cluster distance. A high DI means better clustering since observations in each cluster are closer together, while clusters themselves are further away from each other. We’ll use the function cluster.stats() in fpc package for computing the Dunn index which can be used for cluster validation,\n\ncs &lt;- fpc::cluster.stats(d = physeq_clr_dist,\n                         clustering = spe_upgma_clust)\n\ncs$dunn\n\n[1] 0.9231545\n\n\nThe Dunn index is high indicating a good clustering of samples. Now that we identified two groups of samples based on their microbial community composition, we may want to look at which microbial clades or ASVs are enriched in each of the groups."
  },
  {
    "objectID": "practicals/beta_diversity.html#combining-clustering-and-z-score-heatmap",
    "href": "practicals/beta_diversity.html#combining-clustering-and-z-score-heatmap",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "5.4 Combining clustering and Z-score Heatmap",
    "text": "5.4 Combining clustering and Z-score Heatmap\nZ-score heatmap are normalized (centered around the mean (by line!!) & reduced (Standard deviation= SD). It’s the comparison on an observed value of a sample to the mean of the population. So, it answers to the question, how far from the population mean is a score for a given sample. The scores are given in SD to the population mean.\n\n5.4.1 Select the top 30 ASV\nHere we used ASV but of course you can do it on Family or genus taxonomic level!\n\n#Transform Row/normalized counts in percentage: transform_sample_counts\npourcentS &lt;- phyloseq::transform_sample_counts(physeq_rar, function(x) x/sum(x) * 100)\n#Selection of top 30 taxa \nmytop30 &lt;- names(sort(phyloseq::taxa_sums(pourcentS), TRUE)[1:30])\n#Extraction of taxa from the object pourcentS\nselection30 &lt;- phyloseq::prune_taxa(mytop30, pourcentS)\n#See new object with only the top 30 ASV\nselection30\n\n\n\n5.4.2 Get the otu_table & Z-score transformation\n\n#Retrieve abundance of ASV (otu_table) as table & put in data.prop variable\nselection30_asv &lt;- phyloseq::otu_table(selection30)\nselection30_sample &lt;- phyloseq::sample_data(selection30)\n\n#Change the rownames\n#See\nrownames(selection30_asv)\n\n [1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\"  \"S4B\"  \"S4S\"  \"S5B\"  \"S5S\" \n[11] \"S6B\"  \"S6S\"  \"S7B\"  \"S7S\"  \"S8B\"  \"S8S\"  \"S9B\"  \"S9S\" \n\n#Change... Why?\n\n# rownames(data.prop)&lt;-c(\"S11B_South5B\",\"S1B_North1B\",\"S2B_North2B\",\"S2S_North2S\",\"S3B_North3B\",\"S3S_North3S\",\"S4B_North4B\",\"S4S_North4S\",\"S5B_North5B\",\"S5S_North5S\",\"S6B_South1B\",\"S6S_South1S\",\"S7B_South2B\",\"S7S_South2S\",\"S8B_South3B\",\"S8S_South3S\",\"S9B_South4B\",\"S9S_South4S\")\n\nsample_new_names &lt;- paste(selection30_sample$SampName,\n                          selection30_sample$Description,\n                          sep = \"_\")\n\n#Z-score transformation (with scale)\nheat &lt;- t(base::scale(selection30_asv))\n#See\nhead(data.frame(heat))\n\n           S11B         S1B        S2B        S2S        S3B         S3S\nASV1  1.0670101 -0.36085474 -0.8368097  0.5070631 -0.6688256  0.08710287\nASV2 -0.3822681 -0.72549212 -0.7254921  0.5166521 -0.7254921 -0.59474010\nASV3  1.4657223 -1.12279860 -0.5254476  0.6692543 -0.3761099 -2.16816282\nASV4  0.2776466 -1.18129127 -0.9019202 -0.8087965 -1.1812913 -0.77775527\nASV5  1.1642633  0.31674810  0.2397013  1.3954038  0.3552715  0.20117785\nASV6  0.4514863 -0.01289961  0.7417276  0.3934381  1.4963548 -1.81239520\n            S4B        S4S         S5B        S5S         S6B         S6S\nASV1 -1.7327249 -0.3608547  1.48697039  2.2149015  1.48697039 -0.47284414\nASV2 -0.6110841 -0.6764601 -0.49667608 -0.7254921  0.38590007  3.34416457\nASV3 -0.6747854 -0.7245646  1.06748833 -1.0232401 -0.02765514  0.02212411\nASV4 -0.3121368 -1.1812913  1.67450193  1.1778422 -0.68463158 -0.56046666\nASV5 -0.3766734  0.5864120 -1.30123544  0.2782247  1.43392721 -1.30123544\nASV6  0.7997758 -1.8123952  0.04514863 -1.8123952 -0.59338206 -0.59338206\n            S7B         S7S        S8B        S8S        S9B          S9S\nASV1 -0.8928044  0.03110817 -0.6128309 -0.3888521 -0.5568362  0.003110817\nASV2  0.9742842 -0.18614003  0.4349321 -0.5293641  0.4022441  0.320524054\nASV3  0.6194751 -0.22677213  0.5696958  1.8639563 -0.1769929  0.768812836\nASV4  0.8363887  1.02263609  1.2088835  1.1778422  0.8053475 -0.591507891\nASV5 -1.3012354 -1.30123544 -1.3012354  0.3552715  1.2798335 -0.723384173\nASV6 -0.1870443  0.10319688  0.7417276  0.2192934  0.5095346  1.322210022\n\n\n\n\n5.4.3 Heat map Z-score\n\nComplexHeatmap::Heatmap(\n  heat,\n  row_names_gp = grid::gpar(fontsize = 6),\n  cluster_columns = FALSE,\n  heatmap_legend_param = list(direction = \"vertical\",\n                              title = \"Z-scores\", \n                              grid_width = unit(0.5, \"cm\"),\n                              legend_height = unit(3, \"cm\"))\n)\n\n\n\n\n\n\n5.4.4 Add the Taxonomy for ASV names\n\n#get taxnomic table\ntaxon &lt;- phyloseq::tax_table(selection30) |&gt;\n  as.data.frame()\n\n#concatene ASV with Phylum & Family names\nmyname &lt;- paste(rownames(taxon), taxon$Phylum, taxon$Family, sep=\"_\")\n#apply\ncolnames(selection30_asv) &lt;- myname\n\n\n\n5.4.5 Apply to the Heatmap\n\n#re-run Z-score to take into account the colnames change\nheat &lt;- t(scale(selection30_asv))\n\nmy_top_annotation &lt;- ComplexHeatmap::anno_block(gp = grid::gpar(fill =c(3,4)),\n                                               labels = c(1, 2),\n                                               labels_gp = grid::gpar(col = \"white\",\n                                                                      fontsize = 10))\n\nComplexHeatmap::Heatmap(\n  heat,\n  row_names_gp = grid::gpar(fontsize = 6),\n  cluster_columns =TRUE,\n  heatmap_legend_param = list(direction = \"vertical\",\n   title =\"Z-scores\",\n   grid_width = unit(0.5, \"cm\"),\n   legend_height = unit(4, \"cm\")),\n  top_annotation = ComplexHeatmap::HeatmapAnnotation(foo = my_top_annotation),\n  column_km = 2,\n  column_names_gp= grid::gpar(fontsize = 6)\n  )\n\n\n\n\n\n\n5.4.6 Add a boxplot of ASV Abundance distribution within sample\n\nboxplot &lt;- ComplexHeatmap::anno_boxplot(t(selection30_asv), \n                                        which = \"row\",\n                                        gp = grid::gpar(fill = \"turquoise3\"))\n\nmy_boxplot_left_anno &lt;- ComplexHeatmap::HeatmapAnnotation(Abund = boxplot,\n                                                          which = \"row\",\n                                                          width = unit(3, \"cm\"))\n\nmy_top_anno &lt;- ComplexHeatmap::anno_block(gp = grid::gpar(fill = c(3, 6)),\n                                          labels = c(\"South\", \"North\"),\n                                          labels_gp = grid::gpar(col = \"white\",\n                                                                fontsize = 10))\n\nmy_top_anno &lt;- ComplexHeatmap::HeatmapAnnotation(foo = my_top_anno)\n\nComplexHeatmap::Heatmap(\n  heat,\n  row_names_gp = grid::gpar(fontsize = 7),\n  left_annotation = my_boxplot_left_anno, \n  heatmap_legend_param = list(direction = \"vertical\",\n                              title =\"Z-scores\",\n                              grid_width = unit(0.5, \"cm\"),\n                              legend_height = unit(3, \"cm\")),\n  top_annotation = my_top_anno,\n  column_km = 2,\n  cluster_columns = TRUE,\n  column_dend_side = \"bottom\",\n  column_names_gp = grid::gpar(fontsize = 7)\n  )\n\n\n\n\nWe can now observe that microbial communities in samples from the south differ in their microbial composition from sample from the north. The significant effect of treatment (North/south) remains to be tested statistically, we’ll see how it is done in the hypothese testing section. This difference in community composition is due to the apparent differential abundance of many top ASV of the dataset. The identification of significant biomarkers in North and South samples will be covered in the differential abundance testing section."
  },
  {
    "objectID": "practicals/beta_diversity.html#principal-component-analysis-pca",
    "href": "practicals/beta_diversity.html#principal-component-analysis-pca",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "6.1 Principal component analysis (PCA)",
    "text": "6.1 Principal component analysis (PCA)\nPrincipal components analysis (PCA) is a method to summarise, in a low-dimensional space, the variance in a multivariate scatter of points. In doing so, it provides an overview of linear relationships between your objects and variables. This can often act as a good starting point in multivariate data analysis by allowing you to note trends, groupings, key variables, and potential outliers. Again, because of the compositional nature of microbiome data, we will use the Aitchinson distance here. Be aware that this is the CLR transformed ASV table which is used directly not the Aitchinson distance matrix. The function will calculate a euclidean distance on this CLR transformed table to get the Aitchison matrix. There are many packages allowing PCA analysis. We will use the recent PCAtools package wich provides functions for data exploration via PCA, and allows the user to generate publication-ready figures.\n\n6.1.1 Number of PCs to retain\nFirst, we will use a scree plot to examine the proportion of total variation explained by each PC.\n\n#prepare the ASV table to add taxonomy\ntax_CLR &lt;-  as.data.frame(tax_table(physeq_clr)) # get taxnomic table\n#concatene ASV with Family & Genus names\nASVname &lt;- paste(rownames(tax_CLR), tax_CLR$Family, tax_CLR$Genus,sep=\"_\")\n#apply \nrownames(physeq_clr_asv) &lt;- ASVname\np &lt;- PCAtools::pca(physeq_clr_asv,\n                   metadata = data.frame(sample_data(physeq_clr)))\nPCAtools::screeplot(p, axisLabSize = 18, titleLabSize = 22)\n\n\n\n#variance explained by each PC\n\nHere we see that the first PC really stands out with 31% of the variance explained and then we have a gradual decline for the remaining components. A scree plot on its own just shows the accumulative proportion of explained variation, but we want to determine the optimum number of PCs to retain.\n\n#Horn’s parallel analysis (Horn 1965) (Buja and Eyuboglu 1992)\nhorn &lt;- PCAtools::parallelPCA(physeq_clr_asv)\nhorn$n\n\n[1] 2\n\n#elbow method\nelbow &lt;- PCAtools::findElbowPoint(p$variance)\nelbow\n\nPC3 \n  3 \n\n\nThe two methods indicate that we should retain the first 2 or 3 PCs. The reason for this discrepancy is because finding the correct number of PCs is a difficult task and is akin to finding the ‘correct’ number of clusters in a dataset - there is no correct answer. Most studies take into account only the two first PCs.\n\n\n6.1.2 Plotting the ordination\n\n#Plotting the PCA\nPCAtools::biplot(\n  p,\n  lab = p$metadata$SampName,\n  colby = \"Geo\",\n  pointSize = 5,\n  hline = 0, vline = 0,\n  legendPosition = \"right\"\n)\n\n\n\n\nEach point is a sample, and samples that appear closer together are typically more similar to each other than samples which are further apart. So by colouring the points by treatment you can see that the microbiota from the North are often, but not always, highly distinct from sample from the south.\n\n\n6.1.3 Determine the variables that drive variation among each PC\nOne benefit of not using a distance matrix, is that you can plot taxa “loadings” onto your PCA axes, using the showLoadings = TRUE argument. PCAtools allow you to plots the number of taxa loading vectors you want beginning by those having the more weight on each PCs. The relative length of each loading vector indicates its contribution to each PCA axis shown, and allows you to roughly estimate which samples will contain more of that taxon.\n\nPCAtools::biplot(\n  p, \n  # loadings parameters\n  showLoadings = TRUE,\n  lengthLoadingsArrowsFactor = 1.5,\n  sizeLoadingsNames = 3,\n  colLoadingsNames = 'red4',\n  ntopLoadings = 3,\n  # other parameters\n  lab = p$metadata$X.SampleID,\n  colby = \"Geo\",\n  hline = 0, vline = 0,\n  legendPosition = \"right\"\n)\n\n\n\n\nASVs 7, 11 and 12 have a high contribution to PC1 while ASVs 38, 40, and 47 have a high contribution on the second PC. These ASVs belong to only two families. Samples from the South seems to be enriched in ASV7 while North samples contain higher abundances of ASV11 and 12. The two Noth sample outliers at the top of the plot are caracterized by a higher abundance of ASVs 38, 40, and 47.\n\n\n6.1.4 Correlate the principal components back to environmental data\nFurther exploration of the PCs can come through correlations with environmental data. Here, we will correlate the two first PCs with environmental data.\n\nPCAtools::eigencorplot(\n  p,\n  components = PCAtools::getComponents(p, 1:horn$n),\n  metavars = c('SiOH4','NO2','NO3','NH4','PO4',\n              'NT','PT','Chla',\"T\", \"S\", \"Sigma_t\"),\n  col = c('white', 'cornsilk1', 'gold',\n          'forestgreen', 'darkgreen'),\n  cexCorval = 1.2,\n  fontCorval = 2,\n  posLab = \"all\",\n  rotLabX = 45,\n  scale = TRUE,\n  main = bquote(PC ~ Spearman ~ r^2 ~ environmental ~ correlates),\n  plotRsquared = TRUE,\n  corFUN = \"spearman\",\n  corUSE = \"pairwise.complete.obs\",\n  corMultipleTestCorrection = 'BH',\n  signifSymbols = c(\"****\", \"***\", \"**\", \"*\", \"\"),\n  signifCutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 1)\n)\n\n\n\n\nThe only signficant correlation found is between the first PC1 explaining the separation between South and North samples and salinity. This is unteresting but correlation between variables does not automatically means that the change in one variable is the cause of the change in the values of the other variable. We’ll check later if there is a causal relationship between the salinity gradient and the difference observed in southern and northern bacterial communities."
  },
  {
    "objectID": "practicals/beta_diversity.html#principal-component-analysis-pcoa",
    "href": "practicals/beta_diversity.html#principal-component-analysis-pcoa",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "6.2 Principal component analysis (PCoA)",
    "text": "6.2 Principal component analysis (PCoA)\nPrincipal coordinates analysis (PCoA, also known as metric multidimensional scaling, MDS) attempts to represent the distances between samples in a low-dimensional, Euclidean space. In particular, it maximizes the linear correlation between the distances in the distance matrix, and the distances in a space of low dimension (typically, 2 or 3 axes are selected). As always, the choice of (dis)similarity measure is critical and must be suitable to the data in question. Here we will use the Bray-Curtis distance. When the distance metric is Euclidean, PCoA is equivalent to Principal Components Analysis. The interpretation of the results is the same as with PCA.\n\n#BPCoA on Bray-Curtis dissimilarity\npcoa_asv &lt;- ape::pcoa(physeq_rar_bray)\npcoa_coord &lt;- pcoa_asv$vectors[, 1:2]\n\n#Data frame for hull\nhull &lt;- data.frame(\"Axis.1\" = pcoa_coord[, 1],\n                   \"Axis.2\" = pcoa_coord[, 2],\n                   \"sample\" = as.data.frame(sample_data(physeq_rar@sam_data)))\n\n\n# North &lt;- hull[hull$sample.Geo  == \"North\", ][chull(hull[hull$sample.Geo ==  \"North\", c(\"Axis.1\", \"Axis.2\")]), ]  # hull values for North\n# South &lt;- hull[hull$sample.Geo == \"South\", ][chull(hull[hull$sample.Geo == \n#                                                          \"South\", c(\"Axis.1\", \"Axis.2\")]), ]  # hull values for Jellyfishes  \n\n# hull_data &lt;- rbind(North, South)\n\n#Vector of color for hulls\n# color &lt;- rep(\"#a65628\", length(hull_data$sample.Geo))\n# color[hull_data$sample.Geo == \"North\"] &lt;- \"#1919ff\"\n# hull_data &lt;- cbind(hull_data, color)\n\nhull_col &lt;- c(\"#a65628\",\"#1919ff\")\nnames(hull_col) &lt;- c(\"North\",\"South\")\n\nhull_data &lt;- hull %&gt;%\n  dplyr::group_by(sample.Geo) %&gt;%\n  dplyr::slice(chull(Axis.1,Axis.2)) %&gt;%\n  dplyr::mutate(color = hull_col[sample.Geo])\n\nhead(hull_data)\n\n# A tibble: 6 × 24\n# Groups:   sample.Geo [1]\n    Axis.1  Axis.2 sample.SampName sample.Geo sample.Description sample.groupe\n     &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;      &lt;chr&gt;              &lt;chr&gt;        \n1  0.242   -0.0992 S2S             North      North2S            NBS          \n2 -0.403   -0.130  S2B             North      North2B            NBF          \n3 -0.455   -0.0922 S3B             North      North3B            NBF          \n4 -0.471    0.0176 S3S             North      North3S            NBS          \n5  0.00454  0.407  S5S             North      North5S            NBS          \n6  0.102    0.327  S5B             North      North5B            NBF          \n# ℹ 18 more variables: sample.Pres &lt;int&gt;, sample.PicoEuk &lt;int&gt;,\n#   sample.Synec &lt;int&gt;, sample.Prochloro &lt;int&gt;, sample.NanoEuk &lt;int&gt;,\n#   sample.Crypto &lt;int&gt;, sample.SiOH4 &lt;dbl&gt;, sample.NO2 &lt;dbl&gt;,\n#   sample.NO3 &lt;dbl&gt;, sample.NH4 &lt;dbl&gt;, sample.PO4 &lt;dbl&gt;, sample.NT &lt;dbl&gt;,\n#   sample.PT &lt;dbl&gt;, sample.Chla &lt;dbl&gt;, sample.T &lt;dbl&gt;, sample.S &lt;dbl&gt;,\n#   sample.Sigma_t &lt;dbl&gt;, color &lt;chr&gt;\n\n\nNow that we prepared the data, lets plot the PCoA.\n\nggplot(data = hull, aes(x = Axis.1, y = Axis.2)) +\n  geom_hline(yintercept = 0, colour = \"lightgrey\", linetype = 2) +\n  geom_vline(xintercept = 0, colour = \"lightgrey\", linetype = 2) +\n  geom_polygon(data = hull_data,\n               aes(group = sample.Geo,\n                   fill = sample.Geo),\n               alpha = 0.3) + # add the convex hulls)\n  scale_fill_manual(values = c(\"Darkgrey\", \"#1919ff\")) +\n  geom_point(data = hull,\n             aes(color = sample.Geo,\n                 size = sample.S),\n             alpha = 0.7) +\n  scale_color_manual(values = c(\"Darkgrey\", \"#1919ff\")) +\n  xlab(paste(\"PCo1 (\", round(pcoa_asv$values$Relative_eig[1]*100, 1), \"%)\")) +\n  ylab(paste(\"PCo2 (\", round(pcoa_asv$values$Relative_eig[2]*100, 1), \"%)\")) +\n  theme_bw() +\n  coord_equal() +\n  theme(axis.title.x = element_text(size = 14), # remove x-axis labels\n        axis.title.y = element_text(size = 14), # remove y-axis labels\n        panel.background = element_blank(), \n        panel.grid.major = element_blank(),  #remove major-grid labels\n        panel.grid.minor = element_blank(),  #remove minor-grid labels\n        plot.background = element_blank())\n\n\n\n\nThe ordination of the samples in the PCoA is very similar to the one observed in the PCA with a clear segregation of North and South bacterial communities. This segregation may result from the increasing salinity gradient from North to South but it relaims to be tested.\nDo you see what is missing?\nIndeed, there are no species plotted on this ordination. That’s because we used a dissimilarity matrix (sites x sites) as input for the PCoA function. Hence, no species scores could be calculated. However, we could work around this problem with the function biplot.pcoa() from the ape package.\nPCoA suffers from a number of flaws, in particular the arch effect (see PCA for more information). These flaws stem, in part, from the fact that PCoA maximizes a linear correlation. Non-metric Multidimensional Scaling (NMDS) rectifies this by maximizing the rank order correlation."
  },
  {
    "objectID": "practicals/beta_diversity.html#non-metric-multidimensional-scaling-nmds",
    "href": "practicals/beta_diversity.html#non-metric-multidimensional-scaling-nmds",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "6.3 Non Metric Multidimensional Scaling (NMDS)",
    "text": "6.3 Non Metric Multidimensional Scaling (NMDS)\nNMDS attempts to represent the pairwise dissimilarity between objects in a low-dimensional space. Any dissimilarity coefficient or distance measure may be used to build the distance matrix used as input. NMDS is a rank-based approach. This means that the original distance data is substituted with ranks. While information about the magnitude of distances is lost, rank-based methods are generally more robust to data which do not have an identifiable distribution.\nNMDS is an iterative algorithm. NMDS routines often begin by random placement of data objects in ordination space. The algorithm then begins to refine this placement by an iterative process, attempting to find an ordination in which ordinated object distances closely match the order of object dissimilarities in the original distance matrix. The stress value reflects how well the ordination summarizes the observed distances among the samples.\nNMDS is not an eigenanalysis. This has three important consequences:\n\nThere is no unique ordination result\nThe axes of the ordination are not ordered according to the variance they explain\nThe number of dimensions of the low-dimensional space must be specified before running the analysis\n\nAxes are not ordered in NMDS. vegan::metaMDS() automatically rotates the final result of the NMDS using PCA to make axis 1 correspond to the greatest variance among the NMDS sample points.\n\n#NMDS plot on Aitchison distance\nphyseq_clr_nmds &lt;- vegan::metaMDS(physeq_clr_dist, k=2, trymax=100) #Aitchison distance\n\nA useful way to assess the appropriateness of an NMDS result is to compare, in a Shepard diagram, the distances among objects in the ordination plot with the original distances.\n\nvegan::stressplot(physeq_clr_nmds)\n\n\n\n\nThere is a good non-metric fit between observed dissimilarities (in our distance matrix) and the distances in ordination space. Also the stress of our final result was good.\ndo you know how much the stress is?\nThe stress value can be used as an indicator of the goodness-of-fit. Stress values &gt;0.2 are generally poor and potentially not interpretable, whereas values &lt;0.1 are good and &lt;0.05 are excellent, leaving little danger of misinterpretation.\nSo we can go further and plot the results:\n\nnmds_coord &lt;- data.frame(physeq_clr_nmds$points)\n\n#Data frame for hull\nhull &lt;- data.frame(\"Axis.1\" = nmds_coord[,1],\n                   \"Axis.2\" = nmds_coord[,2],\n                   \"sample\" = as.data.frame(sample_data(physeq_clr@sam_data)))\n\n# North &lt;- hull[hull$sample.Geo  == \"North\", ][chull(hull[hull$sample.Geo == \n#                                                                 \"North\", c(\"Axis.1\", \"Axis.2\")]), ]  # hull values for North\n# South &lt;- hull[hull$sample.Geo == \"South\", ][chull(hull[hull$sample.Geo == \n#                                                                \"South\", c(\"Axis.1\", \"Axis.2\")]), ]  # hull values for Jellyfishes  \n\n# hull_data &lt;- rbind(North, South)\n\n# #Vector of color for hulls\n# color &lt;- rep(\"#a65628\", length(hull_data$sample.Geo))\n# color[hull_data$sample.Geo == \"North\"] &lt;- \"#1919ff\"\n# hull_data &lt;- cbind(hull_data, color)\n\nhull_col &lt;- c(\"#a65628\",\"#1919ff\")\nnames(hull_col) &lt;- c(\"North\",\"South\")\n\nhull_data &lt;- hull %&gt;%\n  dplyr::group_by(sample.Geo) %&gt;%\n  dplyr::slice(chull(Axis.1,Axis.2)) %&gt;%\n  dplyr::mutate(color = hull_col[sample.Geo])\n\n#pdf(file=\"NMDS_Aitchison.pdf\", wi = 7, he = 7)\nggplot(hull,aes(x = Axis.1, y = Axis.2)) +\n  geom_hline(yintercept = 0, colour = \"lightgrey\", linetype = 2) + \n  geom_vline(xintercept = 0, colour = \"lightgrey\", linetype = 2) +\n  geom_polygon(data = hull_data,\n               aes(group = sample.Geo,\n                   fill = sample.Geo),\n               alpha = 0.3) + # add the convex hulls)\n  scale_fill_manual(values = c(\"Darkgrey\", \"#1919ff\")) +\n  geom_point(data = hull,\n             aes(color = sample.Geo,\n                 size = sample.S),\n             alpha = 0.7) +\n  scale_color_manual(values = c(\"Darkgrey\", \"#1919ff\")) +\n  geom_text(data = hull_data,\n            x = -0, y = -9,\n            label = paste(\"Stress =\", round(physeq_clr_nmds$stress, 2)),\n            colour = \"Black\",\n            size = 5)  +\n  xlab(paste(\"MDS1\")) +\n  ylab(paste(\"MDS2\")) +\n  theme_bw() +\n  coord_equal() +\n  theme(axis.title.x = element_text(size=14), # remove x-axis labels\n        axis.title.y = element_text(size=14), # remove y-axis labels\n        panel.background = element_blank(), \n        panel.grid.major = element_blank(),  #remove major-grid labels\n        panel.grid.minor = element_blank(),  #remove minor-grid labels\n        plot.background = element_blank())\n\n\n\n#dev.off()\n\nWe observe the same ordiantion pattern of the samples as in the PCA and PCoA. There are no species scores (same problem as we encountered with PCoA). We can work around this problem, by using the wascores function giving metaMDS the original community matrix as input and specifying the distance measure.\nThe next question is: Which environmental variable is driving the observed differences in species composition? Similarly to what we have done with PCA, we can correlate environmental variables with our ordination axes.\n\n# Correlation with environmental data\ndata.frame(names(hull))\n\n          names.hull.\n1              Axis.1\n2              Axis.2\n3     sample.SampName\n4          sample.Geo\n5  sample.Description\n6       sample.groupe\n7         sample.Pres\n8      sample.PicoEuk\n9        sample.Synec\n10   sample.Prochloro\n11     sample.NanoEuk\n12      sample.Crypto\n13       sample.SiOH4\n14         sample.NO2\n15         sample.NO3\n16         sample.NH4\n17         sample.PO4\n18          sample.NT\n19          sample.PT\n20        sample.Chla\n21           sample.T\n22           sample.S\n23     sample.Sigma_t\n\nenv &lt;- hull[, 13:23]\n\n# The function envfit will add the environmental variables as vectors to the ordination plot\nef &lt;- vegan::envfit(physeq_clr_nmds, env, permu = 1000)\nef\n\n\n***VECTORS\n\n                  NMDS1    NMDS2     r2   Pr(&gt;r)    \nsample.SiOH4   -0.95409 -0.29952 0.2717 0.102897    \nsample.NO2     -0.44259 -0.89672 0.3271 0.062937 .  \nsample.NO3      0.94086  0.33880 0.2986 0.069930 .  \nsample.NH4     -0.48808 -0.87280 0.4484 0.018981 *  \nsample.PO4     -0.67398 -0.73875 0.2498 0.099900 .  \nsample.NT       0.02371 -0.99972 0.0526 0.688312    \nsample.PT      -0.61900 -0.78539 0.3745 0.035964 *  \nsample.Chla    -0.96843 -0.24930 0.2016 0.192807    \nsample.T       -0.87263 -0.48838 0.3250 0.051948 .  \nsample.S       -0.93218 -0.36199 0.7607 0.000999 ***\nsample.Sigma_t -0.96163 -0.27437 0.2116 0.205794    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nPermutation: free\nNumber of permutations: 1000\n\n# The two last columns are of interest: the squared correlation coefficient and the associated p-value\n# Plot the vectors of the significant correlations and interpret the plot\nplot(physeq_clr_nmds, type = \"t\", display = \"sites\")\nplot(ef, p.max = 0.05)\n\n\n\n\nHere again, we can see that the salinity is strongly correlated with the first axis separating samples from the South and the North. To a lesser extent, new environmental variables related with the trophic conditions of the habitat (NH4 and PT) were correlated with the second axis of the NMDS. The detection of these new relations between microbial communities and the environment may be related to the fact that NMDS is best suited to detect the non linear response of microbes to environmental gradients.\nMany different types of indirect gradient analysis are available outthere. In the following graph, we offer suggestions of some of the appropriate choices based on data input structure and expected relationships among variables."
  },
  {
    "objectID": "practicals/beta_diversity.html#permutational-multiple-analysis-of-variance-permanova",
    "href": "practicals/beta_diversity.html#permutational-multiple-analysis-of-variance-permanova",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "7.1 PERmutational Multiple ANalysis Of VAriance (PERMANOVA)",
    "text": "7.1 PERmutational Multiple ANalysis Of VAriance (PERMANOVA)\nPERMANOVA was proposed by Anderson and McArdle to apply the powerful ANOVA to multivariate ecological datasets. PERMANOVA is one of most widely used nonparametric methods to fit multivariate models to microbiome data. It is a multivariate analysis of variance based on distance matrices and permutation. It does this by partitioning the sums of squares for the within- and between-cluster components using the concept of centroids. Many permutations of the data (i.e. random shuffling) are used to generate the null distribution. Find more informations on PERMANOVA here and on the adonis2() function here Now let us evaluate whether the group (North vs. South) has a significant effect on overall bacterial community composition.\n\n#PERMANOVA\nmetadata &lt;- data.frame(sample_data(physeq_clr))\nresults_permanova &lt;- vegan::adonis2(physeq_clr_dist ~ Geo,\n                                    data = metadata,\n                                    perm = 1000)\nresults_permanova\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ Geo, data = metadata, permutations = 1000)\n         Df SumOfSqs      R2      F   Pr(&gt;F)   \nGeo       1   1135.5 0.20329 4.0825 0.001998 **\nResidual 16   4450.1 0.79671                   \nTotal    17   5585.6 1.00000                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere we can see that the North/South grouping explain significantly (p &lt; 0.001) 20% of the variance in the ASV Aitchison matrix. In other words Nothern and Southern bacterial differ significatively in their bacterial composition. The test from ADONIS can be confounded by differences in dispersion (or spread) so we want to check this as well..\n\n# Testing the assumption of similar multivariate spread among the groups (ie. analogous to variance homogeneity)\nanova(vegan::betadisper(physeq_clr_dist, metadata$Geo))\n\nAnalysis of Variance Table\n\nResponse: Distances\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nGroups     1 49.657  49.657  13.915 0.001822 **\nResiduals 16 57.096   3.569                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere the groups have significant different spreads and permanova result may be impacted by that although PERMANOVA is very robust to difference in group dispersion. We can also check which taxa contribute most to the community differences using the ancient adonis() function and the ASV table of CLR transformed counts.\n\n#Show coefficients for the top taxa separating the groups\n\npermanova &lt;- vegan::adonis(t(physeq_clr_asv) ~ Geo,\n                            data = metadata,\n                            permutations = 1000,\n                            method = \"euclidean\")\n\ncoef &lt;- coefficients(permanova)[\"Geo1\",]\n\ntop.coef &lt;- coef[rev(order(abs(coef)))[1:10]]\n\npar(mar = c(3, 14, 2, 1))\n\nbarplot(sort(top.coef),\n        horiz = TRUE,\n        las = 1,\n        main = \"Top taxa\",\n        cex.names = 0.7)\n\n\n\n\nAre these ASVs the same or different compared to ASV contributing the most to PC axes?\nadonis() and adonis2() allow us to explore the effect of categorical or continuous variables.\nNB: An important difference between adonis et adonis2: in adonis terms are tested sequentially and this is the only option. This means that the order you enter your variables is important (if design is unbalanced). This is because the first explanatory variable is added to the model. Then the next one is added to see if it explains significantly more variation not explained by the previous variables. This is equivalent to using by=“terms” in adonis2. If you don’t want the order to matter you can use adonis2 with by=“margin”, or if you want to check if the model as a whole is significant you can use by=NULL. Order does not matter when by=“margin” because the significance is tested against a model that includes all other variables not just the ones preceding it in the formula.\n\n#Permanova on continuous variables\npermanova_S &lt;- vegan::adonis2(physeq_clr_dist ~ S,\n                              data = metadata,\n                              perm = 1000)\npermanova_S\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ S, data = metadata, permutations = 1000)\n         Df SumOfSqs      R2      F   Pr(&gt;F)    \nS         1   1294.1 0.23168 4.8247 0.000999 ***\nResidual 16   4291.5 0.76832                    \nTotal    17   5585.6 1.00000                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npermanova_NH4 &lt;- vegan::adonis2(physeq_clr_dist ~ NH4,\n                                data = metadata,\n                                perm = 1000)\npermanova_NH4\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ NH4, data = metadata, permutations = 1000)\n         Df SumOfSqs      R2      F  Pr(&gt;F)  \nNH4       1    769.8 0.13782 2.5575 0.01598 *\nResidual 16   4815.8 0.86218                 \nTotal    17   5585.6 1.00000                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npermanova_PT &lt;- vegan::adonis2(physeq_clr_dist ~ PT,\n                               data = metadata,\n                               perm = 1000)\npermanova_PT\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ PT, data = metadata, permutations = 1000)\n         Df SumOfSqs      R2      F  Pr(&gt;F)  \nPT        1    697.3 0.12483 2.2822 0.01898 *\nResidual 16   4888.3 0.87517                 \nTotal    17   5585.6 1.00000                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe result confirm that salinity and to a lesser extent NH4 and PT are important factors shaping microbial communities but what about the other variables? Lets construct a model with all the co-variables.\n\n#Inspecting co-variables\npermanova_all &lt;- vegan::adonis2(physeq_clr_dist ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t,\n                                by=\"margin\",\n                                data=metadata,\n                                perm=1000)\n\npermanova_all\n\nPermutation test for adonis under reduced model\nMarginal effects of terms\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t, data = metadata, permutations = 1000, by = \"margin\")\n         Df SumOfSqs      R2      F Pr(&gt;F)\nSiOH4     1    291.5 0.05219 1.0594 0.3217\nNO2       1    243.4 0.04357 0.8846 0.5425\nNO3       1    239.8 0.04293 0.8715 0.5634\nNH4       1    253.2 0.04533 0.9203 0.5145\nPO4       1    232.7 0.04165 0.8456 0.5914\nNT        1    234.6 0.04200 0.8527 0.6034\nPT        1    234.9 0.04206 0.8539 0.5734\nChla      1    200.8 0.03594 0.7296 0.7692\nT         1    285.9 0.05118 1.0390 0.3856\nS         1    286.2 0.05124 1.0402 0.3816\nSigma_t   1    285.3 0.05108 1.0370 0.3896\nResidual  6   1650.8 0.29555              \nTotal    17   5585.6 1.00000              \n\n\nWhat happened? Why none of the variables has no significant effect any more ?\nThe temptation to build an ecological model using all available information (i.e., all variables) is hard to resist. Lots of time and money are exhausted gathering data and supporting information. We also hope to identify every significant variable to more accurately characterize relationships with biological relevance. Collinearity, or excessive correlation among explanatory variables, can complicate or prevent the identification of an optimal set of explanatory variables for a statistical model. Let’s take a look at which explanatory variables are correlated.\n\n# inpecting autocorrélation\n# compute the correlation matrix\ncor_metadadata &lt;- cor(metadata[, 11:21], method = \"spearman\")\n\ncor_mtest &lt;- function(mat, ...) {\n  mat &lt;- as.matrix(mat)\n  n &lt;- ncol(mat)\n  p_mat &lt;- matrix(NA, n, n)\n  diag(p_mat) &lt;- 0\n  for (i in 1:(n - 1)) {\n    for (j in (i + 1):n) {\n      tmp &lt;- cor.test(mat[, i], mat[, j], method = \"spearman\", ...)\n      p_mat[i, j] &lt;- p_mat[j, i] &lt;- tmp$p.value\n    }\n  }\n  colnames(p_mat) &lt;- rownames(p_mat) &lt;- colnames(mat)\n  p_mat\n}\n\n# matrix of the p-value of the correlation\np_mat &lt;- cor_mtest(metadata[, 11:21])\n\n# Leave blank on no significant coefficient\ncorrplot::corrplot(cor_metadadata,\n                   type = \"upper\",\n                   order = \"hclust\",\n                   p.mat = p_mat,\n                   sig.level = 0.05,\n                   insig = \"blank\")\n\n\n\n\nWe can see that many explanatory variables are correlated. Lets remove some of them. We’ll keep S as a proxy of PO4, Sigma-t, NH4 and NO2. NO3 as a proxy of SiOH4. Chla as a proxy of PT.\n\npermanova_cor_pars &lt;- vegan::adonis2(physeq_clr_dist ~ S + NO3 + NT + Chla + T,\n                                     by = \"margin\",\n                                     data = metadata,\n                                     perm = 1000)\npermanova_cor_pars\n\nPermutation test for adonis under reduced model\nMarginal effects of terms\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ S + NO3 + NT + Chla + T, data = metadata, permutations = 1000, by = \"margin\")\n         Df SumOfSqs      R2      F  Pr(&gt;F)  \nS         1    568.2 0.10173 2.0376 0.03896 *\nNO3       1    215.5 0.03858 0.7727 0.70230  \nNT        1    263.4 0.04716 0.9446 0.46653  \nChla      1    170.9 0.03060 0.6129 0.94605  \nT         1    304.5 0.05452 1.0921 0.31169  \nResidual 12   3346.3 0.59910                 \nTotal    17   5585.6 1.00000                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe updated PERMANOVA model is improved over the original. We see that salinity is again significantly related to the response variable. However, the model with only salinity is even much better. The take home message is that true relationships among variables will be masked if explanatory variables are collinear. This creates problems in model creation which lead to complications in model inference. Taking the extra time to evaluate collinearity is a critical first step to creating more robust ecological models."
  },
  {
    "objectID": "practicals/beta_diversity.html#analysis-of-similarity-anosim",
    "href": "practicals/beta_diversity.html#analysis-of-similarity-anosim",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "7.2 ANalysis Of SIMilarity (ANOSIM)",
    "text": "7.2 ANalysis Of SIMilarity (ANOSIM)\nANOSIM tests for significant difference between two or more classes of objects based on any (dis)similarity measure (Clarke 1993). It compares the ranks of distances between objects of different classes with ranks of object distances within classes. The basis of this approach is similar to the NMDS ordination technique described above.\n\n#ANOSIM\nvegan::anosim(physeq_clr_dist, metadata$Geo, permutations = 1000)\n\n\nCall:\nvegan::anosim(x = physeq_clr_dist, grouping = metadata$Geo, permutations = 1000) \nDissimilarity: euclidean \n\nANOSIM statistic R: 0.5628 \n      Significance: 0.001998 \n\nPermutation: free\nNumber of permutations: 1000\n\n\nSimilarly to PERMANOVA, the result of ANOSIM indicates a significant effect of the Norther or Southern origin of the sample on bacterial communities.\nA more formal approach to hypotheses testing can be done using redundancy analysis or canonical correspondence analysis that directly uses information on metadata fields when generating the ordinations and conducting testing. These approaches directly test hypotheses about environmental variables."
  },
  {
    "objectID": "practicals/beta_diversity.html#redundant-analysis-rda",
    "href": "practicals/beta_diversity.html#redundant-analysis-rda",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "8.1 Redundant analysis (RDA)",
    "text": "8.1 Redundant analysis (RDA)\n\n8.1.1 Running the RDA\nRDA is a method combining regression and principal component analysis (PCA). RDA computes axes that are linear combinations of the explanatory variables. In RDA, one can truly say that the axes explain or model (in the statistical sense) the variation of the dependent matrix.\n\n# RDA of the Aitchinson distance\n# constrained by all the environmental variables\n# contained in metadata\n#\n# Observe the shortcut formula\nspe_rda &lt;- vegan::rda(t(physeq_clr_asv) ~ .,\n                      metadata[, 11:21])\nhead(summary(spe_rda))  # Scaling 2 (default)\n\n\nCall:\nrda(formula = t(physeq_clr_asv) ~ SiOH4 + NO2 + NO3 + NH4 + PO4 +      NT + PT + Chla + T + S + Sigma_t, data = metadata[, 11:21]) \n\nPartitioning of variance:\n              Inertia Proportion\nTotal          328.56     1.0000\nConstrained    231.46     0.7044\nUnconstrained   97.11     0.2956\n\nEigenvalues, and their contribution to the variance \n\nImportance of components:\n                         RDA1     RDA2     RDA3     RDA4     RDA5     RDA6\nEigenvalue            85.2928 30.29173 20.29415 18.85659 15.83909 12.98651\nProportion Explained   0.2596  0.09219  0.06177  0.05739  0.04821  0.03952\nCumulative Proportion  0.2596  0.35179  0.41355  0.47094  0.51915  0.55868\n                          RDA7     RDA8     RDA9   RDA10   RDA11      PC1\nEigenvalue            11.78027 10.97738 10.18119 7.94385 7.01222 28.88564\nProportion Explained   0.03585  0.03341  0.03099 0.02418 0.02134  0.08791\nCumulative Proportion  0.59453  0.62794  0.65893 0.68310 0.70445  0.79236\n                           PC2     PC3      PC4      PC5     PC6\nEigenvalue            16.45693 16.3958 15.58129 11.19715 8.59184\nProportion Explained   0.05009  0.0499  0.04742  0.03408 0.02615\nCumulative Proportion  0.84245  0.8923  0.93977  0.97385 1.00000\n\nAccumulated constrained eigenvalues\nImportance of components:\n                         RDA1    RDA2     RDA3     RDA4     RDA5     RDA6\nEigenvalue            85.2928 30.2917 20.29415 18.85659 15.83909 12.98651\nProportion Explained   0.3685  0.1309  0.08768  0.08147  0.06843  0.05611\nCumulative Proportion  0.3685  0.4994  0.58706  0.66853  0.73696  0.79307\n                         RDA7     RDA8     RDA9   RDA10  RDA11\nEigenvalue            11.7803 10.97738 10.18119 7.94385 7.0122\nProportion Explained   0.0509  0.04743  0.04399 0.03432 0.0303\nCumulative Proportion  0.8440  0.89139  0.93538 0.96970 1.0000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n* General scaling constant of scores:  8.645047 \n\n\nSpecies scores\n\n                                                 RDA1      RDA2     RDA3\nASV1_Cyanobiaceae_Synechococcus CC9902        -0.1033  0.108773  0.04666\nASV2_Pseudoalteromonadaceae_Pseudoalteromonas -0.7807 -0.229145 -0.22860\nASV3_Clade I_Clade Ia                         -0.2568  0.002182 -0.22536\nASV4_NA_NA                                    -0.6996  0.193071  0.23547\nASV5_Clade I_Clade Ia                          0.5264 -0.195773  0.23032\nASV6_Clade II_NA                              -0.2542 -0.344583 -0.32380\n....                                                                    \n                                                  RDA4     RDA5     RDA6\nASV1_Cyanobiaceae_Synechococcus CC9902         0.12535 -0.01552  0.06487\nASV2_Pseudoalteromonadaceae_Pseudoalteromonas -0.33352  0.13369  0.08880\nASV3_Clade I_Clade Ia                          0.04191 -0.04528 -0.11436\nASV4_NA_NA                                    -0.20648 -0.23531  0.06807\nASV5_Clade I_Clade Ia                          0.05792  0.40196 -0.22286\nASV6_Clade II_NA                               0.31352 -0.10920 -0.06137\n....                                                                    \n\n\nSite scores (weighted sums of species scores)\n\n       RDA1     RDA2    RDA3    RDA4     RDA5    RDA6\nS11B -1.703 -1.23820  2.9437  0.2362  1.13728 -0.4405\nS1B   2.565 -0.13340 -0.7868  5.7453  3.30268 -3.3657\nS2B   3.022 -2.96571  0.4021  0.9802 -3.09213  0.9282\nS2S  -1.731 -1.82618  2.0707  0.3281 -0.66853 -1.6638\nS3B   3.624 -1.55655 -1.2829  2.0701 -2.02586  1.7347\nS3S   3.165 -0.08923  2.8998 -2.0441 -0.08464  2.0314\n....                                                 \n\n\nSite constraints (linear combinations of constraining variables)\n\n        RDA1    RDA2    RDA3    RDA4    RDA5    RDA6\nS11B -1.2105 -0.7764  3.0649  0.2199  1.2569  0.7586\nS1B   1.7387  0.3983 -0.3817  5.4943  3.2411 -2.7484\nS2B   2.0536 -3.3237  0.6260  1.4897 -2.8936  0.1774\nS2S   0.5936 -2.0609  1.1588  0.1736 -0.8183 -1.8069\nS3B   4.1498 -1.1569 -1.6837  1.1942 -2.4216  2.5295\nS3S   2.0704 -0.1285  3.6947 -1.1733  0.3885  1.8438\n....                                                \n\n\nBiplot scores for constraining variables\n\n            RDA1     RDA2     RDA3     RDA4     RDA5      RDA6\nSiOH4   -0.57424 -0.21106 -0.25450 -0.25678 -0.02349 -0.213981\nNO2     -0.51463 -0.10086 -0.08171  0.34294  0.35340  0.013696\nNO3      0.59878  0.05632 -0.04267 -0.02065 -0.30772  0.095439\nNH4     -0.63097 -0.49073 -0.01146 -0.07457  0.25646  0.259440\nPO4     -0.49369 -0.05367 -0.31521  0.04459  0.19877  0.304690\nNT       0.02778 -0.05873 -0.28198  0.59590  0.14825 -0.392684\nPT      -0.61634 -0.27995 -0.01129  0.12013  0.07328 -0.533916\nChla    -0.47936 -0.07832 -0.06090 -0.01293 -0.11376  0.179421\nT       -0.57485  0.21879  0.26190  0.53662 -0.42902  0.007286\nS       -0.93622  0.00815 -0.06712  0.05543  0.04078  0.183950\nSigma_t -0.52380 -0.20293 -0.31121 -0.40702  0.43162  0.205711\n\n\nThe included environmental variables explain 70.44% of the variation in bacterial community composition across sites. 29.56 % of the variance is unexplained. However, we’ll see that the propotion of variance explained is much lower. The R2 from the summary measures the strength of the canonical relationship between the response variables (Y matrix, ASVs) and the explanatory variables (X matrix) by calculating the proportion of the variation of Y explained by the variables in X. However, this R2 is biased. We calculate an Adjusted R2, which also measures the strength of the relationship between Y and X, but applies a correction of the R2 to take into account the number of explanatory variables. This is the statistic that should be reported.\n\n# Unadjusted R^2 retrieved from the rda object\nR2 &lt;- vegan::RsquareAdj(spe_rda)$r.squared\nR2\n\n[1] 0.7044457\n\n# Adjusted R^2 retrieved from the rda object\nR2adj &lt;- vegan::RsquareAdj(spe_rda)$adj.r.squared\nR2adj\n\n[1] 0.1625961\n\n\nIn reality, the proportion of variance explained dropped to 16.25 %. The numerical output shows that the first two canonical axes explain together 35.1% of the total variance of the data, the first axis alone explaining 25.9%. These are unadjusted values, however. Since R2 adj = 16.2 %, the percentages of accumulated constrained adj eigenvalues show that the first axis alone explains 0.162 * 0.368 = 0.059 or 5.9% variance. Because ecological data are generally quite noisy, one should never expect to obtain a very high value of R2 . Furthermore, the first unconstrained eigenvalue (PC1), the first unconstrained axe for the residuals, is comparatively high, which means that it does display an important residual structure of the response data that is not explain by the environmental parameters measure here.\n\n\n8.1.2 Significance testing\nThe interpretation of the constrained ordination must be preceded by a test of statistical significance (see below). As in multiple regression, a non-significant result must not be interpreted and must be discarded.\n\n# Global test of the RDA result\nanova(spe_rda, step = 1000)\n\nPermutation test for rda under reduced model\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = t(physeq_clr_asv) ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t, data = metadata[, 11:21])\n         Df Variance      F Pr(&gt;F)  \nModel    11  231.456 1.3001  0.096 .\nResidual  6   97.109                \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Tests of all canonical axes\nanova(spe_rda, by = \"axis\", step = 1000)\n\nPermutation test for rda under reduced model\nForward tests for axes\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = t(physeq_clr_asv) ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t, data = metadata[, 11:21])\n         Df Variance      F Pr(&gt;F)\nRDA1      1   85.293 5.2699  0.108\nRDA2      1   30.292 1.8716  0.614\nRDA3      1   20.294 1.2539  0.999\nRDA4      1   18.857 1.1651  1.000\nRDA5      1   15.839 0.9786  1.000\nRDA6      1   12.987 0.8024  1.000\nRDA7      1   11.780 0.7279  1.000\nRDA8      1   10.977 0.6783  1.000\nRDA9      1   10.181 0.6291  0.999\nRDA10     1    7.944 0.4908  0.993\nRDA11     1    7.012 0.4333  0.911\nResidual  6   97.109              \n\n\nHere we can see that ur full model is statistically non significant (p = 0.08), and every canonical axis resulting from the RDA are not either statistically significant (p &gt; 0.05). This RDA model is not interpretable.\nCan you tell why?\n\n\n8.1.3 Selecting variables\nIt happens sometimes that one wishes to reduce the number of explanatory variables. The reasons vary: search for parsimony, rich data set but poor a priori hypotheses and possible strong linear dependencies (correlations) among the explanatory variables in the RDA model, which could render the regression coefficients of the explanatory variables in the model unstable.\nA simple approach to identify collinearity among explanatory variables is the use of variance inflation factors (VIF). VIF calculations are straightforward and easily comprehensible; the higher the value, the higher the collinearity. VIF measure the proportion by which the variance of a regression coefficient is inflated in the presence of other explanatory variables. VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least examined, and avoided if possible.\n\n# Variance inflation factors (VIF)\nvegan::vif.cca(spe_rda)\n\n      SiOH4         NO2         NO3         NH4         PO4          NT \n   4.066588    3.489186    3.634643   16.867288    8.819736    4.908553 \n         PT        Chla           T           S     Sigma_t \n   6.835572    2.264012 5417.455601 8388.550079 6878.896122 \n\n\nSalinity, Temperature and Sigma.t have very hight VIFs wich confirm the collinearities observed earlier between explanatory variables (see the PERMANOVA section). A reduction of the number of explanatory variables is justified. In order to simplify this model, we can perform a forward selection (or backwards or stepwise). These types of selections help us select variables that are statistically important. However, it is important to note that selecting variables ecologically is much more important than performing selection in this way. If a variable of ecological interest is not selected, this does not mean it has to be removed from the RDA. Here, we will be performing forward selection on our 11 environmental variables. To do this, we can use the ordiR2step() function:\n\n# Forward selection of explanatory variables using vegan's ordiR2step()\nstep_forward &lt;- vegan::ordiR2step(vegan::rda(t(physeq_clr_asv) ~ 1,\n                                             data = metadata[, 11:21]),\n                                  scope = formula(spe_rda),\n                                  direction = \"forward\",\n                                  pstep = 1000)\n\nStep: R2.adj= 0 \nCall: t(physeq_clr_asv) ~ 1 \n \n                R2.adjusted\n+ S              0.18366030\n&lt;All variables&gt;  0.16259613\n+ NH4            0.08392874\n+ PT             0.07013415\n+ T              0.06719602\n+ NO3            0.05904665\n+ SiOH4          0.05787026\n+ Sigma_t        0.05002017\n+ NO2            0.03846019\n+ PO4            0.03190148\n+ Chla           0.02451726\n&lt;none&gt;           0.00000000\n+ NT            -0.01448677\n\n\nHere, we are essentially adding one variable at a time, and retaining it if it significantly increases the model’s adjusted R2. The forward selection show us that a model with only salinity has higher R2 adjust than with all variable and explain 18.4 % of the variance. Lets calculate this most parsimonious RDA and check its significance.\n\n# Parsimonious RDA\nspe_rda_pars &lt;- vegan::rda(t(physeq_clr_asv) ~ S, data = metadata[, 11:21])\nanova(spe_rda_pars, step = 1000)\n\nPermutation test for rda under reduced model\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = t(physeq_clr_asv) ~ S, data = metadata[, 11:21])\n         Df Variance      F Pr(&gt;F)    \nModel     1   76.122 4.8247  0.001 ***\nResidual 16  252.443                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(spe_rda_pars, step = 1000, by = \"axis\")\n\nPermutation test for rda under reduced model\nForward tests for axes\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = t(physeq_clr_asv) ~ S, data = metadata[, 11:21])\n         Df Variance      F Pr(&gt;F)    \nRDA1      1   76.122 4.8247  0.001 ***\nResidual 16  252.443                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR2adj_pars &lt;- vegan::RsquareAdj(spe_rda_pars)$adj.r.squared\n\n# Compare variance inflation factors\nvegan::vif.cca(spe_rda)\n\n      SiOH4         NO2         NO3         NH4         PO4          NT \n   4.066588    3.489186    3.634643   16.867288    8.819736    4.908553 \n         PT        Chla           T           S     Sigma_t \n   6.835572    2.264012 5417.455601 8388.550079 6878.896122 \n\nvegan::vif.cca(spe_rda_pars)\n\nS \n1 \n\n\nNow, both the model and the first canonical axis resulting from the RDA are statistically significant (p &lt; 0.05). The VIF of salinity is only 1. This RDA model is interpretable. Lets plot it.\n\n\n8.1.4 RDA plot\n\n# Preparation of the data for the plot\n#\n# View analysis results\nii &lt;- summary(spe_rda_pars)\n\n# Depending on the drawing result\n# the drawing data can be enlarged or\n# reduced to a certain extent, as follows\nsp &lt;- as.data.frame(ii$species[, 1:2]) * 2\nsp_top &lt;- sp[order(abs(sp$RDA1), decreasing = TRUE), ][1:6, ]\n\nst &lt;- as.data.frame(ii$sites[, 1:2])\nst &lt;- merge(st,\n      metadata[\"Geo\"],\n      by = \"row.names\")\n\nyz &lt;- t(as.data.frame(ii$biplot[, 1:2]))\nrow.names(yz) &lt;- \"Salinity\"\nyz &lt;- as.data.frame(yz)\n\neigen_values &lt;- format(100 *ii$cont[[1]][2,], digits=4)\n\n#plot\nggplot() +\n  geom_point(data = st, size = 4,\n             aes(x = RDA1, y = PC1,\n                 shape = Geo, fill = Geo)) +\n  scale_shape_manual(values = c(21:25)) +\n  geom_segment(data = sp_top,\n               arrow = arrow(angle = 22.5,\n                             length = unit(0.35, \"cm\"),\n                             type = \"closed\"),\n               linetype = 1, size = 0.6, colour = \"red\",\n               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +\n  ggrepel::geom_text_repel(data = sp_top,\n                           aes(x = RDA1, y = PC1, label = row.names(sp_top))) +\n  geom_segment(data = yz,\n               arrow = arrow(angle = 22.5,\n                             length = unit(0.35,\"cm\"),\n                             type = \"closed\"),\n               linetype = 1, size = 0.6, colour = \"blue\",\n               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +\n  ggrepel::geom_text_repel(data = yz, aes(RDA1, PC1, label=row.names(yz)))+\n  labs(x = paste(\"RDA 1 (\", eigen_values[1], \"%)\", sep = \"\"),\n       y = paste(\"PC 1 (\", eigen_values[2], \"%)\", sep = \"\"))+\n  geom_hline(yintercept = 0,linetype = 3,size = 1) + \n  geom_vline(xintercept = 0,linetype = 3,size = 1)+\n  guides(shape = guide_legend(title = NULL,\n         color = \"black\"),\n         fill = guide_legend(title = NULL))+\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nOne of the most powerful aspects of RDA is the simultaneous visualization of your response and explanatory variables (i.e. species and environmental variables). From this ordination, we can really say now that salinity is the main environmental driver measured shaping bacterial communities. Among all the ASVs, some are more related to this gradient of salinity. This is the case of ASV 12 and 11 for which abundance increase when salinity decreases and ASV 7 which presents the opposite pattern. These differential abundance patterns can be explored with many kind of analyses (see next chapter) but what is really powerful with RDA is that you highlight gradient relationships not a difference of abundance between two conditions. However, a large part of the variance in the bacterial community remains unexplained. Variance in species communities can be explained by deterministic processes such as species sorting (influence of the environment as we’ve seen here) but also by stochastic processes such as dispersal which depend, among other things, of the distance between communities. Since we have this information, lets take a look at a very common pattern in community ecology: the distance-decay pattern."
  },
  {
    "objectID": "practicals/beta_diversity.html#multiple-regression-on-dissimilarity-matrices-mrm",
    "href": "practicals/beta_diversity.html#multiple-regression-on-dissimilarity-matrices-mrm",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "8.2 Multiple Regression on dissimilarity Matrices (MRM)",
    "text": "8.2 Multiple Regression on dissimilarity Matrices (MRM)\nThe decay of assemblage similarity with spatial distance can be explained by alternative mechanisms: dispersal limitation and species sorting. To understand their relative contributions, we compare the decay in bacterial similarity with spatial distance and, independently, with environmental distance. You will find excellent articles on distance-decay relationship here and here.\nA combination of Mantel correlation and multiple regression, multiple regression on distance matrices (MRM; Manly, 1986; Smouse et al., 1986; Legendre et al., 1994) allows a regression-type analysis of two or more (dis)similarity matrices, using permutations to determine the significance of the coefficients of determination. One matrix must contain (dis)similarities calculated from response data, such as OTU abundances, and the other matrices must contain (dis)similarities calculated from explanatory data (e.g. environmental parameters or space).\nFirst we calculate the spatial distance matrix. In order to calculate kilometric distance bewtween sampling points from geographic coordinates, we used the SpatialEpi package and the latlong2grid() function. Here, you will load the result of this function because there is a conflict with this package and the betapart package we use after.\n\n#library(SpatialEpi)\n#ANFcoord &lt;- read.table(\"Location_coordinates.txt\", sep = \"\\t\", row.names = 1, header = T)\n#ANF_km &lt;- latlong2grid(ANFcoord[,1:2])\n#rownames(ANF_km) &lt;- rownames(ANFcoord)\n\nANF_km &lt;- readRDS(here::here(\"data\",\"beta_diversity\",\"spatial_distance.rds\"))\nANF_km_dist &lt;- dist(ANF_km)\n\nThen, The relationship between microbial pairwise similarity and spatial distance is assessed by fitting negative exponential function describing the decay in microbial similarity with spatial distance.\n\n#Calculate and add model to the plot\n\nANF_decay_exp &lt;- betapart::decay.model(physeq_clr_dist/100,\n                                       ANF_km_dist,\n                                       y.type=\"dissim\",\n                                       model.type=\"exp\",\n                                       perm=100)\n\n#Plot Distance decay relationships\nplot(ANF_km_dist, physeq_clr_dist/100,\n     ylim=c(0, max(physeq_clr_dist/100)),\n     xlim=c(0, max(ANF_km_dist)),\n     xlab = \"Distance (km)\", ylab = \"Dissimilarity (CLR)\")\n\nbetapart::plot.decay(ANF_decay_exp, col = \"blue\",\n                     remove.dots = TRUE, add = TRUE)\n\nlegend(\"bottomright\",\n       paste(\"exp: (Beta =\", round(ANF_decay_exp$second.parameter, 4),\n             \", Rsqr =\", round(ANF_decay_exp$pseudo.r.squared, 2),\n             \", p =\", round(ANF_decay_exp$p.value, 2)),\n       fill = \"blue\")\n\n\n\n\nThe negative exponential model significantly explained the decay in similarity with spatial distance (p &lt; 0.01). But what is the contribution of dispersal and species sorting in this pattern? Lets find out by decomposing the variance between the spatial and the envirnomental matrices.\n\n#Variance partitioning\n#Microbiam matrix (response)\nphyseq_clr_dist_square &lt;- phyloseq::distance(physeq_clr,\n                                             method = \"euclidean\",\n                                             diag = TRUE,\n                                             upper = TRUE)\n\n#Spatial matrix (explicative)\nANF_km_dist_square &lt;- dist(ANF_km, diag = TRUE, upper = TRUE)\n\n#environmental matrix (explicative)\nenvdata &lt;- dist(metadata[,11:21], diag = TRUE, upper = TRUE)\n\n\n#Multiple regressions on Matrices (MRM) - attention les colonnes et lignes des matrices doivent correspondrent (pas besoin d'avoir les mêmes noms)\n\necodist::MRM(physeq_clr_dist_square ~ envdata + ANF_km_dist_square, nperm=1000) # 0.366\n\n$coef\n                   physeq_clr_dist_square  pval\nInt                           19.45167946 0.908\nenvdata                        1.28567618 0.001\nANF_km_dist_square             0.01828172 0.001\n\n$r.squared\n      R2     pval \n0.366774 0.001000 \n\n$F.test\n       F   F.pval \n43.44112  0.00100 \n\necodist::MRM(physeq_clr_dist_square ~ envdata, nperm=1000) # 0.212\n\n$coef\n        physeq_clr_dist_square  pval\nInt                  21.042622 0.967\nenvdata               1.609333 0.001\n\n$r.squared\n       R2      pval \n0.2122659 0.0010000 \n\n$F.test\n       F   F.pval \n40.68905  0.00100 \n\necodist::MRM(physeq_clr_dist_square ~ ANF_km_dist_square, nperm=1000) # 0.238\n\n$coef\n                   physeq_clr_dist_square  pval\nInt                           22.34249373 0.354\nANF_km_dist_square             0.02210456 0.004\n\n$r.squared\n       R2      pval \n0.2384328 0.0040000 \n\n$F.test\n       F   F.pval \n47.27535  0.00400 \n\nmodEvA::varPart(A = 0.212, B = 0.238, AB = 0.366,\n                A.name = \"Environmental\",\n                B.name = \"Dispersal limitation\")\n\n\n\n\n                                   Proportion\nEnvironmental                           0.128\nDispersal limitation                    0.154\nEnvironmental_Dispersal limitation      0.084\nUnexplained                             0.634\n\n\nUsing multiple regression on distance matrices (MRM), spatial and environmental variables proved significant predictors of beta diversity and together explained 36.7 % of variation in dissimilarity of microbial communities. Variance partitioning was subsequently used to partition the variation into purely spatial, purely environmental and spatially-structured environmental components. With 15,4%, the amount of variation in dissimilarity explained by the purely spatial component was higher than the variation explained by the environmental component, indicating that dispersal is an important process shaping our communities.\nSimilarly to indirect gradient analyses, many different types of direct gradient analysis are available outthere. In the following graph, we offer suggestions of some of the appropriate choices based on data input structure and expected relationships among variables."
  },
  {
    "objectID": "practicals/beta_diversity.html#linear-discriminant-analysis-effect-size-lefse",
    "href": "practicals/beta_diversity.html#linear-discriminant-analysis-effect-size-lefse",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "9.1 Linear discriminant analysis Effect Size (LEFse)",
    "text": "9.1 Linear discriminant analysis Effect Size (LEFse)\nLEFSE has been developped by Segata et al. (2011). LEFse first use the non-parametric factorial Kruskal-Wallis (KW) sum-rank test to detect features with significant differential abundance with respect to the class of interest; biological consistency is subsequently investigated using a set of pairwise tests among subclasses using the (unpaired) Wilcoxon rank-sum test. As a last step, LEfSe uses LDA to estimate the effect size of each differentially abundant features.\n\n#LEFSE\nmm_lefse &lt;- microbiomeMarker::run_lefse(physeq, norm = \"CPM\",\n                                        wilcoxon_cutoff = 0.01,\n                                        group = \"Geo\",\n                                        taxa_rank = \"none\",\n                                        kw_cutoff = 0.01,\n                                        multigrp_strat = TRUE,\n                                        lda_cutoff = 4)\n\nmm_lefse_table &lt;- data.frame(mm_lefse@marker_table)\nmm_lefse_table\n\n         feature enrich_group   ef_lda       pvalue         padj\nmarker1    ASV11        North 4.746047 0.0015574784 0.0015574784\nmarker2    ASV12        North 4.699727 0.0045142882 0.0045142882\nmarker3    ASV10        North 4.661376 0.0022950748 0.0022950748\nmarker4    ASV18        North 4.460565 0.0045142882 0.0045142882\nmarker5    ASV35        North 4.183570 0.0045142882 0.0045142882\nmarker6    ASV49        North 4.025863 0.0045142882 0.0045142882\nmarker7     ASV2        South 4.950924 0.0039173223 0.0039173223\nmarker8     ASV8        South 4.706448 0.0020814438 0.0020814438\nmarker9     ASV7        South 4.670957 0.0010275895 0.0010275895\nmarker10    ASV3        South 4.433849 0.0091897421 0.0091897421\nmarker11   ASV13        South 4.406032 0.0073724319 0.0073724319\nmarker12   ASV27        South 4.333577 0.0008112059 0.0008112059\n\np_LDAsc &lt;- microbiomeMarker::plot_ef_bar(mm_lefse)\ny_labs &lt;- ggplot_build(p_LDAsc)$layout$panel_params[[1]]$y$get_labels()\np_abd &lt;- microbiomeMarker::plot_abundance(mm_lefse, group = \"Geo\") +\n  scale_y_discrete(limits = y_labs)\ngridExtra::grid.arrange(p_LDAsc, p_abd, nrow = 1)\n\n\n\n\nLEFse identifies 12 biomarkers and among them ASV 7, 11 and 12 that we already identifies ealier with other methods."
  },
  {
    "objectID": "practicals/beta_diversity.html#differential-analysis-of-compositions-of-microbiomes-with-bias-correction-ancom-bc",
    "href": "practicals/beta_diversity.html#differential-analysis-of-compositions-of-microbiomes-with-bias-correction-ancom-bc",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "9.2 Differential analysis of compositions of microbiomes with bias correction (ANCOM-BC)",
    "text": "9.2 Differential analysis of compositions of microbiomes with bias correction (ANCOM-BC)\nThe ANCOM-BC methodology assumes that the observed sample is an unknown fraction of a unit volume of the ecosystem, and the sampling fraction varies from sample to sample. ANCOM-BC accounts for sampling fraction by introducing a sample-specific offset term in a linear regression framework, that is estimated from the observed data. The offset term serves as the bias correction, and the linear regression framework in log scale is analogous to log-ratio transformation to deal with the compositionality of microbiome data. Furthermore, this method provides p-values and confidence intervals for each taxon. It also controls the FDR and it is computationally simple to implement.\n\n#ancomBC\nmm_ancombc &lt;- run_ancombc_patched(\n  physeq,\n  group = \"Geo\",\n  taxa_rank = \"none\",\n  pvalue_cutoff = 0.001,\n  p_adjust = \"fdr\"\n)\n\nmm_ancombc_table &lt;- data.frame(mm_ancombc@marker_table)\nmm_ancombc_table\n\n         feature enrich_group      ef_W       pvalue         padj\nmarker1     ASV2        South  3.980197 6.885820e-05 7.230111e-04\nmarker2     ASV7        South  4.341347 1.416118e-05 1.652137e-04\nmarker3     ASV8        South  4.532481 5.829496e-06 1.020162e-04\nmarker4    ASV10        North -4.775089 1.796277e-06 6.286968e-05\nmarker5    ASV11        North -5.811580 6.188594e-09 3.249012e-07\nmarker6    ASV12        North -4.466839 7.938375e-06 1.041912e-04\nmarker7    ASV18        North -4.561024 5.090471e-06 1.020162e-04\nmarker8    ASV27        South  5.874154 4.250091e-09 3.249012e-07\nmarker9    ASV35        North -4.483869 7.330158e-06 1.041912e-04\nmarker10   ASV49        North -4.680720 2.858686e-06 7.504051e-05\n\nan_ef &lt;- microbiomeMarker::plot_ef_bar(mm_ancombc)\ny_labs &lt;- ggplot_build(an_ef)$layout$panel_params[[1]]$y$get_labels()\nan_abd &lt;- microbiomeMarker::plot_abundance(mm_ancombc, group = \"Geo\") +\n  scale_y_discrete(limits = y_labs)\ngridExtra::grid.arrange(an_ef, an_abd, nrow = 1)\n\n\n\n\nANCOM-BC identifies 10 biomarkers and all in common with the results of the LEFse analysis."
  },
  {
    "objectID": "practicals/beta_diversity.html#anova-like-differential-expression-aldex2",
    "href": "practicals/beta_diversity.html#anova-like-differential-expression-aldex2",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "9.3 ANOVA-like differential expression (ALDEx2)",
    "text": "9.3 ANOVA-like differential expression (ALDEx2)\nALDEx2 estimates technical variation within each sample per taxon by utilizing the Dirichlet distribution. It furthermore applies the centered-log-ratio transformation (or closely related log-ratio transforms). Depending on the experimental setup, it will perform a two sample Welch’s T-test and Wilcoxon-test or a one-way ANOVA and Kruskal-Wallis-test. The Benjamini-Hochberg procedure is applied in any case to correct for multiple testing.\n\nmm_aldex &lt;- microbiomeMarker::run_aldex(physeq, group = \"Geo\",\n                                        norm = \"CPM\",\n                                        taxa_rank = \"none\",\n                                        p_adjust = \"fdr\")\n\nmm_aldex_table &lt;- data.frame(mm_aldex@marker_table)\nmm_aldex_table\n\n        feature enrich_group ef_aldex       pvalue       padj\nmarker1   ASV27        North 2.095543 0.0003582814 0.03277281\n\n\nALDEx2 is much more stringent and identifies only 1 biomarker, ASV 27 which has been identified by the two other DAA methods. The others do not reach the FDR cut-off used here; although, they likely have “largish” effect sizes. Often, if I consider performing DA testing, I will run several models and focus on the intersection of OTUs given by at least two methods. Here it would be the 10 ASV identified with the ANCOM-BC."
  },
  {
    "objectID": "practicals/ampliseq.html",
    "href": "practicals/ampliseq.html",
    "title": "Preprocessing with nf-core/ampliseq",
    "section": "",
    "text": "1 Prepare workspace\nConnect to BioPipes VM using ifb.m4.2xlarge (8 vCPU, 32Go GB RAM, 200Go GB local disk) and then:\nwget https://github.com/ANF-MetaBioDiv/course-material/archive/refs/tags/v2.tar.gz\ntar -xzf v2.tar.gz\ncd course-material-2/\n\n\n2 List files to analyse\nFirst of of all, you need a table listing all the samples you want to analyse and their corresponding fastq files (forward and reverse in case of paired-end sequencing). In case your samples are coming from multiple runs, the run id will be indicated in a fourth column. Below a bash command to generate such a file for the practical:\nls data/raw/ | \\\n  paste - - | \\\n  awk '\n    BEGIN {OFS = FS = \"\\t\"; print \"sampleID\",\"run\",\"forwardReads\",\"reverseReads\"}\n    {\n      sample = $1; sub(/_.+$/,\"\",sample)\n      run = \"run_01\"\n      fw_file = \"data/raw/\" $1\n      rv_file = \"data/raw/\" $2\n      print sample, run, fw_file, rv_file\n    }\n  ' &gt; practicals/ampliseq_files/samplesheet.tsv\nand an overview of the generated file\n\n\n\n\n\n\n\n\n\nsampleID\nrun\nforwardReads\nreverseReads\n\n\n\n\nS11B\nrun_01\ndata/raw/S11B_R1.fastq.gz\ndata/raw/S11B_R2.fastq.gz\n\n\nS1B\nrun_01\ndata/raw/S1B_R1.fastq.gz\ndata/raw/S1B_R2.fastq.gz\n\n\nS2B\nrun_01\ndata/raw/S2B_R1.fastq.gz\ndata/raw/S2B_R2.fastq.gz\n\n\nS2S\nrun_01\ndata/raw/S2S_R1.fastq.gz\ndata/raw/S2S_R2.fastq.gz\n\n\nS3B\nrun_01\ndata/raw/S3B_R1.fastq.gz\ndata/raw/S3B_R2.fastq.gz\n\n\nS3S\nrun_01\ndata/raw/S3S_R1.fastq.gz\ndata/raw/S3S_R2.fastq.gz\n\n\nS4B\nrun_01\ndata/raw/S4B_R1.fastq.gz\ndata/raw/S4B_R2.fastq.gz\n\n\nS4S\nrun_01\ndata/raw/S4S_R1.fastq.gz\ndata/raw/S4S_R2.fastq.gz\n\n\nS5B\nrun_01\ndata/raw/S5B_R1.fastq.gz\ndata/raw/S5B_R2.fastq.gz\n\n\nS5S\nrun_01\ndata/raw/S5S_R1.fastq.gz\ndata/raw/S5S_R2.fastq.gz\n\n\nS6B\nrun_01\ndata/raw/S6B_R1.fastq.gz\ndata/raw/S6B_R2.fastq.gz\n\n\nS6S\nrun_01\ndata/raw/S6S_R1.fastq.gz\ndata/raw/S6S_R2.fastq.gz\n\n\nS7B\nrun_01\ndata/raw/S7B_R1.fastq.gz\ndata/raw/S7B_R2.fastq.gz\n\n\nS7S\nrun_01\ndata/raw/S7S_R1.fastq.gz\ndata/raw/S7S_R2.fastq.gz\n\n\nS8B\nrun_01\ndata/raw/S8B_R1.fastq.gz\ndata/raw/S8B_R2.fastq.gz\n\n\nS8S\nrun_01\ndata/raw/S8S_R1.fastq.gz\ndata/raw/S8S_R2.fastq.gz\n\n\nS9B\nrun_01\ndata/raw/S9B_R1.fastq.gz\ndata/raw/S9B_R2.fastq.gz\n\n\nS9S\nrun_01\ndata/raw/S9S_R1.fastq.gz\ndata/raw/S9S_R2.fastq.gz\n\n\n\n\n\n3 Make nextflow available\nIf first time connecting to the ampliseq_vm\nconda init\nThen, each time you’re opening a terminal\nconda activate nextflow\n\n\n4 Run nf-core/ampliseq\nThis is an example of a command to launch nf-core/ampliseq:\nnextflow run nf-core/ampliseq \\\n  -bg \\\n  -r 2.14.0 \\\n  -profile docker \\\n  -c \"practicals/ampliseq_files/ampliseq_vm.config\" \\\n  -params-file practicals/ampliseq_files/ampliseq_parameters_simple.yaml\nWith run you specify the workflow you want to use. The option -bg allows you to run the workflow as a background job, meaning that you can close your ssh connection, connect later to your VM, the workflow will still be running as long as the VM is running. Remove this option if you want to visualise progress bars. With -r you can call a specific version of the workflow you want to use, this is highly recommended for reproducibility purpose. With -profile you can call lists of pre set parameters. In our case we are calling the profile docker telling nextflow to download and use docker images of the tools needed for our workflow. With -c you can call a file with workflow execution configurations. Here we use configurations from practicals/ampliseq_files/ampliseq_vm.config to specify the maximum amount of ressources allocated to our workflow. Finally we are calling the parameters file practicals/ampliseq_files/ampliseq_parameters_simple.yaml. This where you will for exemple specify the primers used for the amplification. Let’s have a closer look at this file:\n# Main arguments\n\ninput: \"practicals/ampliseq_files/samplesheet.tsv\"\nFW_primer: \"CCTACGGGNBGCASCAG\"\nRV_primer: \"GACTACNVGGGTATCTAAT\"\noutdir: \"outputs/ampliseq\"\nThese are required parameters you need to specify on order to be able to run nf-core/ampliseq. The parameter input is the path the the table listing all the files you want to analyse. Primers are specified with FW_primer and RV_primer and the output directory with outdir. But as you will see later there are many more parameters to fine tune your workflow, for a complete list have a look here.\n\n\n5 Main outputs\nHere is a simplified tree structure illustrating the key output files and directories produced by the nf-core/ampliseq pipeline:\noutputs/ampliseq/\n├── summary_report/\n│   └── summary_report.html         # Pipeline summary report: overview of read counts, stats, and key results\n├── multiqc/\n│   └── multiqc_report.html         # Aggregated QC report for all samples\n├── qiime2/\n│   ├── abundance_tables/           # Exported ASV abundance tables (e.g. BIOM, TSV formats)\n│   └── input/\n│       ├── table.qza               # QIIME 2 feature table (ASV counts per sample)\n│       └── taxonomy.qza            # QIIME 2 artifact with taxonomy assignment per ASV\n├── barrnap/\n│   └── summary.tsv                 # Summary of rRNA detection (e.g. 16S) by Barrnap for each sample\n├── cutadapt/\n│   └── cutadapt_summary.tsv        # Adapter trimming statistics: read counts before/after trimming\n├── dada2/\n│   ├── ASV_seqs.fasta              # Representative ASV sequences in FASTA format\n│   ├── ASV_table.tsv               # Tab-separated ASV abundance table (samples × ASVs)\n│   ├── ASV_tax.silva_138_2.tsv     # ASVs annotated with taxonomy from SILVA 138.2 database\n│   └── DADA2_stats.tsv             # Read filtering and denoising stats per sample\n├── fastqc/                         # Contains raw and trimmed read quality reports (per-sample)\n├── input/\n│   └── samplesheet.tsv             # Metadata table listing input samples and file paths\n├── phyloseq/\n│   └── dada2_phyloseq.rds          # RDS object containing full phyloseq object (ASVs, taxonomy, metadata)\n└── pipeline_info/                  # Nextflow logs, execution reports, and trace info\n\n.nextflow.log                       # Nextflow log file (useful for debugging)\n\n\n6 Tune an rerun\nYou can decide later to rerun your workflow with different parameters. An example of a more detailed parameter file:\n# Main arguments\n\ninput: \"practicals/ampliseq_files/samplesheet.tsv\"\nFW_primer: \"CCTACGGGNBGCASCAG\"\nRV_primer: \"GACTACNVGGGTATCTAAT\"\noutdir: \"outputs/ampliseq\"\n\n# Read trimming and quality filtering\n\ntrunclenf: 250\ntrunclenr: 220\nmaxee: 3\n\n# Amplicon Sequence Variants (ASV) calculation\n\nsample_inference: \"pooled\"\n\n# ASV post processing\n\nmin_len_asv: 200\n\n# Taxonomic database\n\ndada_ref_taxonomy: \"greengenes2=2024.09\"\n\n# ASV filtering\n\nexclude_taxa: mitochondria,chloroplast # default values\nmin_frequency: 10\nmin_samples: 2\nAdd the option -resume to avoid redoing analyses already done during the previous run:\nnextflow run nf-core/ampliseq \\\n  -resume \\\n  -bg \\\n  -r 2.14.0 \\\n  -profile docker \\\n  -c \"practicals/ampliseq_files/ampliseq_vm.config\" \\\n  -params-file practicals/ampliseq_files/ampliseq_parameters_tuned.yaml\n\n\n7 Add metadata for postprocessing\nnf-core/ampliseq allows you to run some alpha and beta diversity analyses on your ASV table. To do so you need to provide a table with the metadata. This table will contain the sample ids in the column ID and as many columns as descriptors you want to specify. These descriptors have to be categorical, you can’t for example add continuous values such as temperature measurements for example.\nSo let’s create such a table\ncat data/context/mapfileFA.txt | \\\n  tr '\\r' '\\n' | \\\n  awk '\n    BEGIN {FS=OFS=\"\\t\"; print \"ID\", \"geo\", \"depth\"}\n    NR &gt; 1 {\n      sample = $1\n      geo = $2\n      depth = $1; sub(/S[0-9]+/, \"\", depth)\n      print sample, geo, depth\n    }\n  ' &gt; practicals/ampliseq_files/ampliseq_metadata.tsv\n\n\n\nID\nGeo\ndepth\n\n\n\n\nS1B\nNorth\nB\n\n\nS2B\nNorth\nB\n\n\nS2S\nNorth\nS\n\n\nS3B\nNorth\nB\n\n\nS3S\nNorth\nS\n\n\nS4B\nNorth\nB\n\n\nS4S\nNorth\nS\n\n\nS5B\nNorth\nB\n\n\nS5S\nNorth\nS\n\n\nS6B\nSouth\nB\n\n\nS6S\nSouth\nS\n\n\nS7B\nSouth\nB\n\n\nS7S\nSouth\nS\n\n\nS8B\nSouth\nB\n\n\nS8S\nSouth\nS\n\n\nS9B\nSouth\nB\n\n\nS9S\nSouth\nS\n\n\nS11B\nSouth\nB\n\n\n\nNow your metada table have been created you can refer to it in the parameter file and rerun ampliseq with the -resume option\nnextflow run nf-core/ampliseq \\\n  -resume \\\n  -bg \\\n  -r 2.14.0 \\\n  -profile docker \\\n  -c \"practicals/ampliseq_files/ampliseq_vm.config\" \\\n  -params-file practicals/ampliseq_files/ampliseq_parameters_tuned_with_metadata.yaml"
  }
]