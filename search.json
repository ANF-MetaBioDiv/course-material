[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ANF MetaBioDiv",
    "section": "",
    "text": "Welcome to the first edition of the ANF Exploration de la Diversité Taxonomique des Ecosystèmes par Metabarcoding. The aim of this course is to teach you how to run microbial ecology analyses (mostly alpha and beta diversity) from metabarcoding raw sequencing data using R.\n\n\n\nMonday 5th:\n\n09h30: Participants arrival\n12h30: \n14h00: R practical by Marc Garel + check technical issues\n19h00: \n\nTuesday 6th:\n\n08h30: Introduction to metabarcoding by Loïs Maignien\n10h15: \n10h30: Analysing metabarcoding data with dada2 by Nicolas Henry\n11h30: Preprocessing: dada2 by Nicolas Henry\n12h30: \n14h00: Introduction to phyloseq\n15h00: Preprocessing: dada2 and Preprocessing: phyloseq by Nicolas Henry with \n18h00: free time\n19h00: \n\nWednesday 7th:\n\n09h00: Course on alpha diversity 1/2 by Loïs Maignien\n10h15: \n10h30: Alpha diversity practical by Loïs Maignien\n12h30: \n14h00: Course on alpha diversity 2/2 by Loïs Maignien\n15h00: Alpha diversity practical by Loïs Maignien with \n18h00: free time\n19h00: \n\nThursday 8th:\n\n09h00: Course on beta diversity 1/2 by Jean-Christophe Auguet\n10h15: \n10h30: Beta diversity practical by Jean-Christophe Auguet\n12h30: \n14h00: Course on beta diversity 2/2 by Jean-Christophe Auguet\n15h00: Beta diversity practical by Jean-Christophe Auguet with \n18h00: free time\n19h00:  \n\nFriday 9th:\n\n09h00: À la carte with \n12h30: \n14h00: End of the course"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Organisation committee and intervenants\nNicolas Henry, ABiMS & FR2022 Tara GOSEE, Station Biologique de Roscoff\nErwan Corre, ABiMS, Station Biologique de Roscoff\nJean-Christophe Auguet, Marbec, Montpellier\nLois Maignien, BEEP, Université de Brest\nMarc Garel, MIO, Marseille\nFabrice Armougom, MIO, Marseille\nSamuel Chaffron, LS2N, Université de Nantes\n\n\nSponsors\nPlateforme OMICS, MIO, Marseille\nSociété Française de Bio-Informatique\nInstitut Français de Bioinformatique\nThanks the French Institute of Bioinformatics – IFB CNRS UAR3601 – for providing life science data and tools, storage and computing resources.\n\n\nPartners\n\n   \n \n \n\n\n\nLibraries used in this course\n\nrenv::dependencies() |> \n    dplyr::pull(Package) |>\n    unique() |>\n    sort()\n\nFinding R package dependencies ... [12/16] \b\b\b\b\b\b\b\b[13/16] \b\b\b\b\b\b\b\b[14/16] \b\b\b\b\b\b\b\b[15/16] \b\b\b\b\b\b\b\b[16/16] Done!\n\n\n [1] \"ape\"               \"base\"              \"betapart\"         \n [4] \"Biostrings\"        \"ComplexHeatmap\"    \"corrplot\"         \n [7] \"dada2\"             \"DECIPHER\"          \"devtools\"         \n[10] \"digest\"            \"dplyr\"             \"ecodist\"          \n[13] \"fpc\"               \"FSA\"               \"ggplot2\"          \n[16] \"ggpmisc\"           \"ggpubr\"            \"ggrepel\"          \n[19] \"grid\"              \"gridExtra\"         \"GUniFrac\"         \n[22] \"here\"              \"knitr\"             \"microbiome\"       \n[25] \"microbiomeMarker\"  \"MicrobiotaProcess\" \"modEvA\"           \n[28] \"parallel\"          \"patchwork\"         \"PCAtools\"         \n[31] \"phangorn\"          \"phyloseq\"          \"plotly\"           \n[34] \"plyr\"              \"RColorBrewer\"      \"renv\"             \n[37] \"rmarkdown\"         \"stats\"             \"tidyverse\"        \n[40] \"treemap\"           \"treemapify\"        \"vegan\"            \n[43] \"zCompositions\""
  },
  {
    "objectID": "practicals/rforbeginer.html",
    "href": "practicals/rforbeginer.html",
    "title": "Part 0: R for beginner",
    "section": "",
    "text": "To install Cran R, you must go to https://cran.r-project.org/, and download the install file for your favorite operating system, click on the .exe, .dmg, .pkg, .deb, respectively for Windows, MacOS and Linux-debian.\nAnd click on follow… until to reach successful installation Then download and install the IDE Rstudio https://www.rstudio.com/products/rstudio/.\nEverything is free to download\n\n\n\nWhere am I?\nTo get the current working directory\n\ngetwd()\n\n[1] \"/home/nicolas/Documents/anf-metabarcoding/practicals\"\n\n\nTo change my working directory from the console\n\nsetwd(\"/path/to/my/fancy/project/\")\n\nIn Rstudio, we can change the working directory by navigating in folder in File panel and clicking on menu More\nIf you are using a Rproject, you don’t need to change your working directory.\nHow can I find documentation about function?\nThe command help() is the 911\n\n# exemple with function read.table\nhelp(\"read.table\")\n#other exemple of 911\nexample(\"plot\")\n??plot()"
  },
  {
    "objectID": "practicals/rforbeginer.html#installation",
    "href": "practicals/rforbeginer.html#installation",
    "title": "Part 0: R for beginner",
    "section": "2.1 Installation",
    "text": "2.1 Installation\nYou can install new packages by clicking directly in Rstudio or by command line (the best way for me)\n\ninstall.packages(\"your_package\") # for packages on CRAN mirror\n\nFor packages from Bioconductor (specifically for bioinformatic):\n\nBiocManager::install(\"your_package\")\n\nor from github (using the package devtools)\n\ndevtools::install_github(\"your_package\")"
  },
  {
    "objectID": "practicals/rforbeginer.html#using-functions-from-a-package",
    "href": "practicals/rforbeginer.html#using-functions-from-a-package",
    "title": "Part 0: R for beginner",
    "section": "2.2 Using functions from a package",
    "text": "2.2 Using functions from a package\nTo use functions from a specific package you can either load the entire package:\n\nlibrary(\"your_package\")\n\nor call the function this way:\n\nyour_package::yourfunction()"
  },
  {
    "objectID": "practicals/rforbeginer.html#expression",
    "href": "practicals/rforbeginer.html#expression",
    "title": "Part 0: R for beginner",
    "section": "3.1 Expression",
    "text": "3.1 Expression\nAn expression is directly evaluated and the result is displayed on terminal Example :\n\n2 + 3\n\n[1] 5\n\nsqrt(25)\n\n[1] 5"
  },
  {
    "objectID": "practicals/rforbeginer.html#affectation-in-an-object",
    "href": "practicals/rforbeginer.html#affectation-in-an-object",
    "title": "Part 0: R for beginner",
    "section": "3.2 Affectation in an object",
    "text": "3.2 Affectation in an object\nAn assignment is an expression stored in object or variable. In this example expression, constant, array, matrix, data frame, list Example :\n\na <- 2 + 3\n\nYou can also assigned a expression to variable using =, like in most of other languages.\n\nb = 3 + 3\n\nThere are debates about which one to use. It is not really important which one you use, just be consistant and always use the same way to assign.\nTo list object/variable from your environment:\n\nls()\n\n[1] \"a\" \"b\""
  },
  {
    "objectID": "practicals/rforbeginer.html#type-of-objects",
    "href": "practicals/rforbeginer.html#type-of-objects",
    "title": "Part 0: R for beginner",
    "section": "3.3 Type of objects",
    "text": "3.3 Type of objects\n\n3.3.1 Vectors\nVectors are objects composed by values with the same type (i.e, numeric, characters…)\n\nV1 <- c(2, 6, 9) # numeric vector\nV2 <- c(\"monday\", \"Tuesday\", \"Wednesday\")# character vector\nV3 <- rep(6, 3) # repetition of the same value\nV4 <- seq(1, 3, 0.1)\nV5 <- 1:100\nV5\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\n\nTo know the number of value inside a vector\n\nlength(V1)\n\n[1] 3\n\n\nWhat do you think about V4?\nFilter a vector according to criteria\n\n# Example : with list of value (a vector)\n\nx <- c(1, 3, 5, 3, 2, 1, 4, 6, 4, 7, 5, 4, 3)\n\n# get element from 2 to 6\n\nx[2:6]\n\n[1] 3 5 3 2 1\n\n# get elements 3 et 5 from x.\n\nx[c(3, 5)]\n\n[1] 5 2\n\n# get value more than 20.\n\nx[x > 20]\n\nnumeric(0)\n\n# get value of  x where x is equal to 21.\n\nx[x == 21]\n\nnumeric(0)\n\n# return elements form x the the value different from 5\n\nx[x != 5]\n\n [1] 1 3 3 2 1 4 6 4 7 4 3\n\n\nFilter a vector according to several criteria\n\n# 3 lists : ages, sexes et poids\n\nage <- c(20, 30, 40,\n         15, 22, 24,\n         36, 38)\n\nsexe <- c(\"F\", \"M\", \"F\",\n          \"M\", \"F\", \"M\",\n          \"F\", \"M\")\n\npoids <- c(75, 76, 73,\n           72, 64, 76,\n           73, 72)\n\n# get value from age greater than 20 and less than 30.\n\nage[age > 20 & age < 30]\n\n[1] 22 24\n\n# Recovering \"poids\" for those who are older than 25 and female\n\npoids[age > 25 & sexe == \"F\"]\n\n[1] 73 73\n\n#Retrieve age values below 20 or above 30.\n\nage[age < 20 | age > 30]\n\n[1] 40 15 36 38\n\n\nExo1\nConsidering the vector a such as a <- c(\"lannister\", \"targaryen\", \"baratheon\", \"starck\", \"greyjoy\")\n\nWhat is the length of the vector?\nTry doing a[1:3]. What do you get?\nCreate a new vector b containing only lannister and starck.\nTry doing a[-1]. What do you get?\nSort by alphabetical order using sort()\n\nExo2\n\nCreate a vector a containing all integers from 1 to 100.\nAdd the values 200, 201, 202 to the vector a.\nCreate a vector b containing all even integers from 2 to 100 using seq()\n\n\n\n3.3.2 Matrices\nMatrices are objects in which the elements are arranged in a two-dimensional rectangular layout. As for vector all the elements are of the same type.\n\nm1 <- matrix(1:12, ncol = 3, byrow = TRUE)\nm2 <- matrix(1:12, ncol = 3, byrow = FALSE)\nm1\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n[4,]   10   11   12\n\n# to know the dimension of the matrix (number of line and number of column)\ndim(m1)\n\n[1] 4 3\n\nncol(m1)\n\n[1] 3\n\nnrow(m1)\n\n[1] 4\n\n\nSome operation on matrix\n\n#Selection all data inside 2 column\nc2 <- m1[, 2]\nc2\n\n[1]  2  5  8 11\n\n#Select data inside 3rd column and 4th line\nm1[4, 3]\n\n[1] 12\n\n#delete a column\nm3 <- m1[, -2]\nm3\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    4    6\n[3,]    7    9\n[4,]   10   12\n\nm3[2]\n\n[1] 4\n\n\nExo3\n\nRun the command a <- rep(c(0,1), 50). What happened?\nUse a to construct a matrix A with 10 rows and 10 columns.\nPrint the dimensions of this matrix.\nUse t() on this matrix to create a matrix B. What happened?\nThe commands A[1:5, ] and B[, 1:5] retrieve the first 5 rows of A and the first 5 columns of B. Use these commands to retrieve the rows containing only 1s from A and the columns containing only 0s from B.\n\nExo 4 sup\n\nCreate matrix M\n\n\\[M = \\begin{bmatrix}3 & 5 & 6\\\\\n-1 & 2 & 2 \\\\\n1 & -1 & -1 \\\\\n\\end{bmatrix}\\]\n\nDisplay the dimension of A, its number of columns, its number of rows and its length\nExtract the second column of A, then the first row\nExtract the element at the third position of the first line;\nCompute the sum of the columns and rows of A using colSums(), rowSums()\n\n\n\n3.3.3 Data frames\nData frames are objects composed by vector where the value are of different modes (i.e, numeric, characters…)\n\n3.3.3.1 Data frame examples\nLoad a data frame\n\ndata(iris)\n\nVisualise the data frame in a table\n\nView(iris)\n\nDisplay its internal structure\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\n\nWhat can we notice?\n\n\n3.3.3.2 How to build your own data frame\n\ndate <- c(\"1_monday\", \"2_Tuesday\", \"3_Wednesday\",\n          \"4_Thursday\", \"5_Friday\", \"6_Sturday\",\n          \"7_Sunday\")\n\nis.character(date)\n\n[1] TRUE\n\n# temperature in deg Celsius\ntemperature <- c(24, 27, 25,\n               22, 30, 21,\n               28)\n\nis.numeric(temperature)\n\n[1] TRUE\n\n# rain in mm\nrain <- c(1, 0, 0,\n          5, 2, 0,\n          0)\n\nis.numeric(rain)\n\n[1] TRUE\n\n# add column together\ndf <- cbind(date, temperature, rain)\nstr(df)\n\n chr [1:7, 1:3] \"1_monday\" \"2_Tuesday\" \"3_Wednesday\" \"4_Thursday\" ...\n - attr(*, \"dimnames\")=List of 2\n  ..$ : NULL\n  ..$ : chr [1:3] \"date\" \"temperature\" \"rain\"\n\n# make data.frame\ndf <- data.frame(date, temperature)\nstr(df)\n\n'data.frame':   7 obs. of  2 variables:\n $ date       : chr  \"1_monday\" \"2_Tuesday\" \"3_Wednesday\" \"4_Thursday\" ...\n $ temperature: num  24 27 25 22 30 21 28\n\ndf$rain <- rain\n\n#Give me the difference between cbind() and data.frame()\nView(df)\n\n#To select a column or vector\ndf$temperature\n\n[1] 24 27 25 22 30 21 28\n\ndf[, 2]\n\n[1] 24 27 25 22 30 21 28\n\n# here we use list() instead of c()\n# because there is multiple class in inside row\n\nday <- list(\"8_monday\", 29, 1)\nnew_def <- rbind(df, day)# add row to a data frame\nnew_def\n\n         date temperature rain\n1    1_monday          24    1\n2   2_Tuesday          27    0\n3 3_Wednesday          25    0\n4  4_Thursday          22    5\n5    5_Friday          30    2\n6   6_Sturday          21    0\n7    7_Sunday          28    0\n8    8_monday          29    1\n\n\n\n\n3.3.3.3 Use dplyr to select, filter a data frame\ndplyr is part of the library set named tidyverse (contraction of “tidy” and “universe”, it’s a tidy universe). tidyverse packages are designed to work together and thus follow the same code logic and a common grammar.\nThe pipe, %>%, is one of the useful elements of the tidyverse. It allows to structure sequences of operations by minimizing the creation of intermediate objects and by facilitating the addition of a step anywhere in this sequence. Note that from R 4.1 you can use a new pipe, |> without the need of loading any library.\nThe most commonly used tidyverse packages are loaded in your session:\n\nggplot2\ndplyr\ntidyr\nreadr\ntibble\nstringr\n\n\ntidyverse::tidyverse_packages()\n\n [1] \"broom\"         \"cli\"           \"crayon\"        \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"readr\"        \n[21] \"readxl\"        \"reprex\"        \"rlang\"         \"rstudioapi\"   \n[25] \"rvest\"         \"stringr\"       \"tibble\"        \"tidyr\"        \n[29] \"xml2\"          \"tidyverse\"    \n\n\n\nlibrary(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n#To select a variable with tidyverse\n#Command line widely used to select data\niris$Sepal.Width %>%\n  head()\n\n[1] 3.5 3.0 3.2 3.1 3.6 3.9\n\niris[, \"Sepal.Width\"] %>%\n  head()\n\n[1] 3.5 3.0 3.2 3.1 3.6 3.9\n\n#With dplyr\nselect(iris, Sepal.Width) %>%\n  head()\n\n  Sepal.Width\n1         3.5\n2         3.0\n3         3.2\n4         3.1\n5         3.6\n6         3.9\n\n\n\n#Command line widely used to select data\niris[, c(\"Sepal.Length\", \"Sepal.Width\", \"Species\")] %>%\n  head()\n\n  Sepal.Length Sepal.Width Species\n1          5.1         3.5  setosa\n2          4.9         3.0  setosa\n3          4.7         3.2  setosa\n4          4.6         3.1  setosa\n5          5.0         3.6  setosa\n6          5.4         3.9  setosa\n\n#With tidyverse command\niris %>%\n  select(Sepal.Length, Sepal.Width, Species) %>%\n  head()\n\n  Sepal.Length Sepal.Width Species\n1          5.1         3.5  setosa\n2          4.9         3.0  setosa\n3          4.7         3.2  setosa\n4          4.6         3.1  setosa\n5          5.0         3.6  setosa\n6          5.4         3.9  setosa\n\n\nTo sort and select data inside data frame\n\n# Command line widely used to select data\niris[which(iris$Sepal.Width > 3 & iris$Species == \"virginica\"), ] %>%\n  head()\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n101          6.3         3.3          6.0         2.5 virginica\n110          7.2         3.6          6.1         2.5 virginica\n111          6.5         3.2          5.1         2.0 virginica\n116          6.4         3.2          5.3         2.3 virginica\n118          7.7         3.8          6.7         2.2 virginica\n121          6.9         3.2          5.7         2.3 virginica\n\n#With tidyverse command\niris %>%\n  filter(Sepal.Width > 3) %>%\n  filter(Species == \"virginica\") %>%\n  head()\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n1          6.3         3.3          6.0         2.5 virginica\n2          7.2         3.6          6.1         2.5 virginica\n3          6.5         3.2          5.1         2.0 virginica\n4          6.4         3.2          5.3         2.3 virginica\n5          7.7         3.8          6.7         2.2 virginica\n6          6.9         3.2          5.7         2.3 virginica"
  },
  {
    "objectID": "practicals/rforbeginer.html#definition",
    "href": "practicals/rforbeginer.html#definition",
    "title": "Part 0: R for beginner",
    "section": "4.1 Definition",
    "text": "4.1 Definition\nFunction are a compilation of command line with different instructions inside one object to simplify code. A function is composed by arguments and options.\nfunction(argument1, argument2, option1, … ,option10)"
  },
  {
    "objectID": "practicals/rforbeginer.html#usual-functions-for-data-frame",
    "href": "practicals/rforbeginer.html#usual-functions-for-data-frame",
    "title": "Part 0: R for beginner",
    "section": "4.2 Usual functions for data frame",
    "text": "4.2 Usual functions for data frame\n\nhead() # to know first line of your data frame\nclass()# return the class of the object. Ex : data.frame, matrix, list ....\nstr()# return the structure of the object. Ex : numeric, factor, character....\nnames()# to get or set the names of an object\nsum() # for addition\nmin() # return the minimum of the vector\nmax() # return the minimum of the vector\nrow.names() # attribute names for lines of the data frame\ncolnames() # attribute names for column of the data frame\napply() # Returns a vector or array or list of values obtained by applying a function to margins of an array or matrix.\n\nExample function row.names, class and str\n\ndf2 <- data.frame(x = c(TRUE, FALSE, NA, NA), y = c(12, 34, 56, 78))\ndf2\n\n      x  y\n1  TRUE 12\n2 FALSE 34\n3    NA 56\n4    NA 78\n\nrow.names(df2) <- paste(\"row\", 1 : 4, sep = \"_\")\ndf2 # what do you see\n\n          x  y\nrow_1  TRUE 12\nrow_2 FALSE 34\nrow_3    NA 56\nrow_4    NA 78\n\nclass(df2)\n\n[1] \"data.frame\"\n\nstr(df2)\n\n'data.frame':   4 obs. of  2 variables:\n $ x: logi  TRUE FALSE NA NA\n $ y: num  12 34 56 78\n\n\nExample function apply\n\nhead(df)\n\n         date temperature rain\n1    1_monday          24    1\n2   2_Tuesday          27    0\n3 3_Wednesday          25    0\n4  4_Thursday          22    5\n5    5_Friday          30    2\n6   6_Sturday          21    0\n\nclass(df)\n\n[1] \"data.frame\"\n\nstr(df)\n\n'data.frame':   7 obs. of  3 variables:\n $ date       : chr  \"1_monday\" \"2_Tuesday\" \"3_Wednesday\" \"4_Thursday\" ...\n $ temperature: num  24 27 25 22 30 21 28\n $ rain       : num  1 0 0 5 2 0 0\n\n# return mean for the numerical column of the data.frame. apply(data,margin,fun). \n# For margin parameter the value 1 return mean for each row, \n# for margin=2 return mean for each selected column.\napply(df[, 2:3], 2, mean)\n\ntemperature        rain \n  25.285714    1.142857 \n\n\nExample function plot\nThe function plot() is a very useful function to make a graph for examination for your data set\nLet’s have a look at the documentation of this function ?plot\nExo 5\nLoad data set iris using data()\n\nGive the class Sepal.Width and Species vectors\nWhat is the minimum / maximum / average sepal length of these irises?\nWhat is the values of the 10 first sepals?\nCalculate standard deviation for every numeric vector\nCalculate standard mean for every numeric vector\nCreate a data frame with mean and sd as line and give a name for each line\nAn error of 0.5cm was made in the measurement of the length of the sepal of the 41st iris: add 0.5cm to this measurement\nPlot Sepal.Length as fonction of Sepal.Width adding title “Sepal” xlab “Sepal.Length” and ylab “Sepal.Length”\nRun once again plot giving the following parameters pch=19, cex=2, col=“red”, cex.axis=2, cex.lab=2. What do you see?\n\n\n4.2.1 How to import external data frame issue from .txt or .csv\nTo import data set, the function read.table() or read.csv() are commonly used.\nread.table(file, header = FALSE, sep = \"\", dec = \".\", ...)\nThe main parameter are :\n\nfile : add the pathway and the name of the file\nheader : a logical value (TRUE or FALSE)indicating whether the file contains the names of the variables as its first line.\nsep : the field separator character. Values on each line of the file are separated by this character. If sep = “” (the default for read.table) the separator is ‘white space’, that is one or more spaces, tabs, newlines or carriage returns.\ndec : the character used in the file for decimal points.\n\n\nds <- read.table(here::here(\"data\",\n                            \"rforbeginers\",\n                            \"exemple_read.txt\"),\n                 header = TRUE,\n                 sep = \";\",\n                 dec = \",\")\n\nWhy I use the parameter header=TRUE ?\n\n\n4.2.2 To export data set as .txt to read in excel\nThe function is similar to read.table()\nwrite.table(x, file = \"\", sep = \" \",na = \"NA\", dec = \".\", ... )\n\nx : this is your data.frame\nfile : give a name for your file\nsep : cf read.table\ndec : cf read.table\nna : give a symbole for missing data, by convention is NA\n\n\nwrite.table(ds, \"ds.txt\", sep = \"\\t\", dec = \".\")\n\nTo keep our working directory tidy, we now delete ds.txt\n\nfile.remove(\"ds.txt\")\n\n[1] TRUE"
  },
  {
    "objectID": "courses/dada2.html#i-received-data",
    "href": "courses/dada2.html#i-received-data",
    "title": "Analysing metabarcoding data with dada2",
    "section": "I received data",
    "text": "I received data\n\nhere::here(\"data\",\"raw\") |>\n    list.files()\n\n [1] \"S11B_R1.fastq.gz\" \"S11B_R2.fastq.gz\" \"S1B_R1.fastq.gz\"  \"S1B_R2.fastq.gz\" \n [5] \"S2B_R1.fastq.gz\"  \"S2B_R2.fastq.gz\"  \"S2S_R1.fastq.gz\"  \"S2S_R2.fastq.gz\" \n [9] \"S3B_R1.fastq.gz\"  \"S3B_R2.fastq.gz\"  \"S3S_R1.fastq.gz\"  \"S3S_R2.fastq.gz\" \n[13] \"S4B_R1.fastq.gz\"  \"S4B_R2.fastq.gz\"  \"S4S_R1.fastq.gz\"  \"S4S_R2.fastq.gz\" \n[17] \"S5B_R1.fastq.gz\"  \"S5B_R2.fastq.gz\"  \"S5S_R1.fastq.gz\"  \"S5S_R2.fastq.gz\" \n[21] \"S6B_R1.fastq.gz\"  \"S6B_R2.fastq.gz\"  \"S6S_R1.fastq.gz\"  \"S6S_R2.fastq.gz\" \n[25] \"S7B_R1.fastq.gz\"  \"S7B_R2.fastq.gz\"  \"S7S_R1.fastq.gz\"  \"S7S_R2.fastq.gz\" \n[29] \"S8B_R1.fastq.gz\"  \"S8B_R2.fastq.gz\"  \"S8S_R1.fastq.gz\"  \"S8S_R2.fastq.gz\" \n[33] \"S9B_R1.fastq.gz\"  \"S9B_R2.fastq.gz\"  \"S9S_R1.fastq.gz\"  \"S9S_R2.fastq.gz\""
  },
  {
    "objectID": "courses/dada2.html#what-am-i-going-to-do-with-that",
    "href": "courses/dada2.html#what-am-i-going-to-do-with-that",
    "title": "Analysing metabarcoding data with dada2",
    "section": "What am I going to do with that?",
    "text": "What am I going to do with that?\n\nhere::here(\"data\",\"raw\",\"S11B_R1.fastq.gz\") |>\n    gzfile() |>\n    readLines(n = 4) |>\n    cat(sep=\"\\n\")\n\n@M01522:260:000000000-C3YFC:1:2114:21886:9214 1:N:0:CTTGTA\nCCTACGGGGGGCAGCAGTAGGGAATTTTGCGCAATGGGCGAAAGCCTGACGCAGCAACGCCGCGTGATCGATGAAGCTTCTAGGAGCGTAAAGATCTGTCGTGAGGGAAGAAAAATTCGGAGGTAAATAATTTTCGTTTTTGACGGTACCTCACAAGAAAGCACCGGCTAACTTCGTGCCAGCAGCCGCGGTAATACGAGGGGTGCTAGCGTTGTCCGGAATCATTGGGCGTAAAGGGTCCGTAGGCGGTTTAACAAGTCAATTGTTAAAGACATCGGCTTAACCGATGAAGT\n+\nGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGEGGFGGGGGGGGGGGGGGFGGGFGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGFGGGGGGGGGFGGGGGGGGGGGGGDFGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGEEGGGGCGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGEEGGGGGGC8CD8CGGGGGCE:FGGGGGGGFFG7FFFGFFGF:@?FFBEFFFFFFF3>BFFF*\n\n\nWe need a bioinformatic pipeline to:\n\nFilter out wrong sequences, such as sequencing errors\nGet a format suitable for diversity and community composition analyses of our samples"
  },
  {
    "objectID": "courses/dada2.html#overview",
    "href": "courses/dada2.html#overview",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Overview",
    "text": "Overview\nTwo files (R1 and R2) per sequencing run or per sample (100 first nucleotides):\nR1:\n\n\n@M01522:260:000000000-C3YFC:1:2114:21886:9214 1:N:0:CTTGTA\nCCTACGGGGGGCAGCAGTAGGGAATTTTGCGCAATGGGCGAAAGCCTGACGCAGCAACGCCGCGTGATCGATGAAGCTTCTAGGAGCGTAAAGATCTGTC\n+\nGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGEGGFGGGGGGGGGGGGGGFGGGFGGGGGGGGGGGGGGGGGGGGGGGGG\n\n\nR2:\n\n\n@M01522:260:000000000-C3YFC:1:2114:21886:9214 2:N:0:CTTGTA\nGACTACCAGGGTATCTAATCCTGTTCGCTCCCCACGCTTTCGTCCCTCAGCGTCAGTTTTAGGCCAGAAAGTTGCCTTCGCCATTGGTGTTCCTTCTGAT\n+\nCCCCCFGGGGGGGGGGGGGGGGGGGCEGGGGGGGGGGEEEFGG>GGGGGGGGGGGGFGGGG?FGGGGGFGFGGFGGFGGCGEGGGGGGGG>FGGGGGGGG\n\n\nPer record: identifier, sequence, quality"
  },
  {
    "objectID": "courses/dada2.html#identifier",
    "href": "courses/dada2.html#identifier",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Identifier",
    "text": "Identifier\n\n\n@M01522:260:000000000-C3YFC:1:2114:21886:9214 1:N:0:CTTGTA\n\n\n\n\n\nValue\nDescription\n\n\n\n\nM05074\nthe unique instrument id\n\n\n31\nthe run id\n\n\n000000000-BC3R3\nthe flowcell id\n\n\n1\nflowcell lane\n\n\n1101\ntile number within the flowcell lane\n\n\n13622\n‘x’-coordinate within the tile\n\n\n1477\n‘y’-coordinate within the tile\n\n\n1\nthe member of a pair\n\n\nN\nY if the read is filtered (did not pass)\n\n\n0\n0: none of the control bits are on\n\n\n1\nindex sequence"
  },
  {
    "objectID": "courses/dada2.html#sequence",
    "href": "courses/dada2.html#sequence",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Sequence",
    "text": "Sequence\n\n\n\nThe tag informs you from which sample the read come from\nThe primer used for the amplification\nThe targeted sequence (metabarcode)"
  },
  {
    "objectID": "courses/dada2.html#quality",
    "href": "courses/dada2.html#quality",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Quality",
    "text": "Quality\nQuality score encoded using ASCII characters:\n\n\n\n\n\nASCII character\nQuality score\n\n\n\n\n!\n0\n\n\n”\n1\n\n\n#\n2\n\n\n\n\n\n\n\nASCII character\nQuality score\n\n\n\n\nG\n38\n\n\nH\n39\n\n\nI\n40\n\n\n\n\n\nThe Phred quality score Q is related to the base calling error probability P according to the following formula:\n\\[Q = -10\\log_{10}P\\]\n\\[P=10^{Q/-10}\\]\n\nIn raw data reads, the quality score rarely exceed 40, but higher scores are possible when different raw reads are assembled"
  },
  {
    "objectID": "courses/dada2.html#strategies",
    "href": "courses/dada2.html#strategies",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Strategies",
    "text": "Strategies\n\n\nGenetic clustering based approaches producing OTUs:\n\nUPARSE\nSwarm (could be seen as denoising too)\n\nDenoising approaches producing ASVs:\n\nDeblur\nDADA2"
  },
  {
    "objectID": "courses/dada2.html#dada2-quest-ce-que-cest",
    "href": "courses/dada2.html#dada2-quest-ce-que-cest",
    "title": "Analysing metabarcoding data with dada2",
    "section": "DADA2, qu’est-ce que c’est?",
    "text": "DADA2, qu’est-ce que c’est?\n\n\nDADA (Divisive Amplicon Denoising Algorithm) an algorithm to denoise Roche’s 454 platform errors (Rosen et al. 2012)\nDADA2 implements a new quality-aware model of Illumina amplicon errors (Callahan et al. 2016)\nDADA2 is an open-source R package https://github.com/benjjneb/dada2"
  },
  {
    "objectID": "courses/dada2.html#dada2-the-full-amplicon-workflow",
    "href": "courses/dada2.html#dada2-the-full-amplicon-workflow",
    "title": "Analysing metabarcoding data with dada2",
    "section": "DADA2, the full amplicon workflow",
    "text": "DADA2, the full amplicon workflow\n\nQuality assessment → plotQualityProfile()\nLength trimming → filterAndTrim()\nQuality filtering → filterAndTrim()\nDenoising → dada()\nMerging pair-end reads → mergePairs()\nChimera identification → removeBimeraDenovo()\nTaxonomic assignment → assignTaxonomy()\n\nBut some preliminary steps are missing…"
  },
  {
    "objectID": "courses/dada2.html#artificial-sequences",
    "href": "courses/dada2.html#artificial-sequences",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Artificial sequences",
    "text": "Artificial sequences\n\nTags are used to encode the sample provenance of the reads. Reads need to be grouped by sample provenance (demultiplexing)\nPrimer sequences will bias the error model built by DADA2 and need to be removed (primer trimming).\nBoth task can be achieved using Cutadapt, a command line-tool to find and remove error-tolerantly adapters from reads (Martin et al. 2011)."
  },
  {
    "objectID": "courses/dada2.html#demultiplexing-using-cutadapt",
    "href": "courses/dada2.html#demultiplexing-using-cutadapt",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Demultiplexing using cutadapt",
    "text": "Demultiplexing using cutadapt\nIf your tags are in a fasta file with corresponding sample names as header, you can use this command-line:\n\n\ncutadapt \\\n    -g file:${BARCODES} \\\n    -o {name}_R1.fastq.gz \\\n    -p {name}_R2.fastq.gz \\\n    ${R1_FILE} \\\n    ${R2_FILE}\n\n# \n# tags to look for at the beginning (5') of R1 files. ${BARCODES} is a fasta file containing the tags\n# demultiplexed R1 file output. name will be replace by the name of the tag\n# same as above but with R2 files\n# input R1 file\n# input R2 file\n\n\nYou end up with as many R1 and R2 files as samples you have\n\n\n\n\n\n\nHelp! My reads are mixed-orientated\n\n\nRun cutadapt a second time, looking for tags in R2.\nKeep the outputs of the two rounds separated for the rest of the workflow."
  },
  {
    "objectID": "courses/dada2.html#primer-removal-using-cutadapt",
    "href": "courses/dada2.html#primer-removal-using-cutadapt",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Primer removal using cutadapt",
    "text": "Primer removal using cutadapt\nTo remove forward and reverse primer sequences form pair-end read files:\n\n\ncutadapt \\\n    -e 0.1 \\\n    -g ${PRIMER_FORWARD} \\\n    -G ${PRIMER_REVERSE} \\\n    --report=minimal \\\n    --discard-untrimmed \\\n    --minimum-length ${MIN_LENGTH} \\\n    --no-indels \\\n    -o ${FORWARD} \\\n    -p ${REVERSE} \\\n    ${R1_FILE} \\\n    ${R2_FILE} 1> ${LOG}\n\n# \n# error tolerance (default value)\n# forward primer\n# reverse primer\n# ask to print primer trimming statistics\n# reads not containing primers are discarded\n# read with a length below this threshold after trimming are discarded\n# no indels allowed when mathing primer to reads\n# R1 output\n# R2 output\n# R1 input\n# R2 input; 1> ${LOG} export the report in the file ${LOG}\n\n\nAs for demultiplexing, if reads are mix-orientated, run cutadapt twice"
  },
  {
    "objectID": "courses/dada2.html#check-reads-quality",
    "href": "courses/dada2.html#check-reads-quality",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Check reads quality",
    "text": "Check reads quality\n\n\nCheck the overall quality of a sequencing run using plotQualityProfile()\nOutside of DADA2, you can also use FASTQC\nIf the overall quality is too low, you will probably have to resequence your samples\n\n\n\n\nA quality drop is often observed in the end of the reads\n\n\ngreen line: mean\norange line (plain): median\norange line (dashed): 25th and 75th quantiles"
  },
  {
    "objectID": "courses/dada2.html#trimming-and-filtering",
    "href": "courses/dada2.html#trimming-and-filtering",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Trimming and filtering",
    "text": "Trimming and filtering\nTrimming, at a given length, will improve the overall read quality\n\n\n\n\n\n\nDanger zone\n\n\nAfter trimming, make sure that forward and reverse reads are still long enough to overlap\n\n\n\nReads of low quality and/or with ambiguous nucleotides (N) after trimming are filtered out.\nBoth length trimming and quality filtering are achieved using the function filterAndTrim()"
  },
  {
    "objectID": "courses/dada2.html#denoising",
    "href": "courses/dada2.html#denoising",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Denoising",
    "text": "Denoising\nIs sequence \\(i\\) generated by sequence \\(j\\) because of sequencing errors?\n\nIn order to define if \\(i\\) is an error of \\(j\\) and perform denoising using DADA2, we need to compute:\n\nthe error rate \\(\\lambda_{ji}\\)\nthe abundance p-value \\(p_A(j \\rightarrow i)\\)"
  },
  {
    "objectID": "courses/dada2.html#error-rate",
    "href": "courses/dada2.html#error-rate",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Error rate",
    "text": "Error rate\n\nThe rate at which an amplicon read with sequence i is produced from sample sequence j is reduced to the product over the transition probabilities between the L aligned nucleotides:\n\n\\[\\lambda_{ji} = \\prod_{l=0}^L p(j(l) \\rightarrow i(l),q_i(l))\\]"
  },
  {
    "objectID": "courses/dada2.html#the-abundance-p-value",
    "href": "courses/dada2.html#the-abundance-p-value",
    "title": "Analysing metabarcoding data with dada2",
    "section": "The abundance p-value",
    "text": "The abundance p-value\nThe abundance p-value (\\(p_A\\)) is the probability of all reads of \\(i\\) (\\(a_i\\)) or more being produced from \\(j\\) during amplification ore sequencing.\n\\[p_A(j \\rightarrow i) = \\frac{1}{1- \\rho_{\\mathrm{pois}}(n_j\\lambda_{ji},0)} \\sum_{a=a_i}^\\infty \\rho_{\\mathrm{pois}}(n_j\\lambda_{ji},a)\\]\nA low p-value indicate that it is unlikely that \\(i\\) is noise from amplifying and sequencing \\(j\\)\n\nThe discrete nature of the Poisson distribution is also why this is a probability mass function and not a density function"
  },
  {
    "objectID": "courses/dada2.html#the-divisive-partitioning-algorithm",
    "href": "courses/dada2.html#the-divisive-partitioning-algorithm",
    "title": "Analysing metabarcoding data with dada2",
    "section": "The divisive partitioning algorithm",
    "text": "The divisive partitioning algorithm\n\nall unique sequences into a single partition\n\\(p_A\\) of all sequences against most abundant sequence (center)\nif smallest p-value below \\(\\Omega_A\\): new partition\n\\(p_A\\) of all sequences against center of new partition\nevery sequence join the partition most likely to have produced it\n\nRepeat steps 3 to 5 until all abundance p-values are greater than \\(\\Omega_A\\)"
  },
  {
    "objectID": "courses/dada2.html#learn-the-error-model",
    "href": "courses/dada2.html#learn-the-error-model",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Learn the error model",
    "text": "Learn the error model\nHow do we compute \\(\\lambda_{ji}\\) if we don’t know the error rate for each possible transition?\nThe error rates will be learned from the data using learnErrors()\n\nThe learnErrors method learns this error model from the data, by alternating estimation of the error rates and inference of sample composition until they converge on a jointly consistent solution"
  },
  {
    "objectID": "courses/dada2.html#visualise-the-error-model",
    "href": "courses/dada2.html#visualise-the-error-model",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Visualise the error model",
    "text": "Visualise the error model\nYou can visualise the estimated error rates using the function plotErrors()"
  },
  {
    "objectID": "courses/dada2.html#run-the-dada2-algorithm",
    "href": "courses/dada2.html#run-the-dada2-algorithm",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Run the DADA2 algorithm",
    "text": "Run the DADA2 algorithm\n\nAfter dereplicating your sequences (derepFastq()), denoise using the function dada()\nBy default sample inference is performed on each sample individually (pool = FALSE).\nIf you are interested in rare variants present in several samples use pool = TRUE\nWhen working on big data, pool = \"pseudo\" is an interesting alternative to pool = TRUE"
  },
  {
    "objectID": "courses/dada2.html#merge-paired-reads",
    "href": "courses/dada2.html#merge-paired-reads",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Merge paired reads",
    "text": "Merge paired reads\nMerge forward and reverse reads using mergePairs()\n\n\nminOverlap: minimum size of overlap\nmaxMismatch: maximum number of mismatches\njustConcatenate: in case your reads don’t overlap"
  },
  {
    "objectID": "courses/dada2.html#remove-chimeras",
    "href": "courses/dada2.html#remove-chimeras",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Remove chimeras",
    "text": "Remove chimeras\n\nChimeras are artifact sequences formed by two or more biological sequences incorrectly joined together.\nWe find and remove bimeras (two-parent chimeras) using the function removeBimeraDenovo()\nChimeric sequences are identified if they can be exactly reconstructed by combining a left-segment and a right-segment from two more abundant “parent” sequences.\nCan be done per sample (method=\"per-sample\"), for the entire dataset (method=\"pooled\") or in a consensus way (method=\"consensus\")\n\n\nChimeras are artifact sequences formed by two or more biological sequences incorrectly joined together. This often occurs during PCR reactions using mixed templates (i.e., uncultured environmental samples). Incomplete extensions during PCR allow subsequent PCR cycles to use a partially extended strand to bind to the template of a different, but similar, sequence. This partially extended strand then acts as a primer to extend and form a chimeric sequence. Once created, the chimeric sequence is then further amplified in subsequent cycles. The end result is a PCR artifact that does not represent a sequence that exists in nature."
  },
  {
    "objectID": "courses/dada2.html#taxonomic-assignment",
    "href": "courses/dada2.html#taxonomic-assignment",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Taxonomic assignment",
    "text": "Taxonomic assignment\n\nTaxonomic assignment within DADA2 workflow, assignTaxonomy(), is achieved using a native implementation of the naive Bayesian classifier method (Wang et al. 2007).\nReference fastas for the three most common 16S databases: Silva, RDP and GreenGenes are maintained by dada2’s team.\nFor eukaryotes, a dada2 formatted version of PR2 can be found here."
  },
  {
    "objectID": "courses/dada2.html#extra-filtering-steps",
    "href": "courses/dada2.html#extra-filtering-steps",
    "title": "Analysing metabarcoding data with dada2",
    "section": "Extra filtering steps",
    "text": "Extra filtering steps\n\nASVs can be filtered out if:\n\nsequence has an unexpected length\nnot assigned to the desired taxonomic group\nconsidered as contaminant (present in negative controls)"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html",
    "href": "practicals/preprocessing_dada2.html",
    "title": "Preprocessing : dada2",
    "section": "",
    "text": "To begin with, download the course repository on your computer or virtual machine.\nTo do so, visit the repository on github (ANF-metabarcoding) and download it as a zip file.\nOnce on your machine, unzip the file and place the resulting folder in the most covenient location (~/Documents/ for example).\n\n\n\nSave as a variable the path to the folder where you will place the references databases.\n\nrefdb_folder <- here::here(\"data\", \"refdb\")\nrefdb_folder\n\n[1] \"/home/nicolas/Documents/anf-metabarcoding/data/refdb\"\n\n\nThe reason why we use here::here() is that when you render a Rmarkdown file, the working directory is where the Rmarkdown file is:\n\ngetwd()\n\n[1] \"/home/nicolas/Documents/anf-metabarcoding/practicals\"\n\n\nWhereas here::here() point to the root of the R project\n\nhere::here()\n\n[1] \"/home/nicolas/Documents/anf-metabarcoding\"\n\n\nNow, let’s create the folder directly from R:\n\nif (!dir.exists(refdb_folder)) dir.create(refdb_folder)\n\nYou can also create the folder from RStudio in the Files window\nTip: You can access the documentation of any R function using ? in the console. If you to know everything about the function dir.create(), simply run ?dir.create()\nThe Silva reference database, commonly used to assign 16S metabarcoding data, will be used in practical.\nIn case you are working with 18S sequences, you will have better assignements using PR2 (https://pr2-database.org/) or EukRibo (https://doi.org/10.5281/zenodo.6327891) especially if you are interested in protists.\nThe following code downloads dada2 formated silva reference databases. If you are not confortable with it, you can simply download the reference database files from your web browser here and here.\n\n# R stop dowloading after timeout which is\n# 60 seconds by default\ngetOption(\"timeout\")\n\n[1] 60\n\n# so we change timeout to be 20 minutes\noptions(timeout = 1200)\n\n# we save in variable the path to the refdb\n# in the working space\nsilva_train_set <- file.path(refdb_folder,\n                             \"silva_nr99_v138.1_train_set.fa.gz\")\n\nsilva_species_assignment <- file.path(refdb_folder,\n                                      \"silva_species_assignment_v138.1.fa.gz\")\n\n# then we download the files if they don't already exist\n\nif (!file.exists(silva_train_set)) {\n  download.file(\n    \"https://zenodo.org/record/4587955/files/silva_nr99_v138.1_train_set.fa.gz\",\n    silva_train_set,\n    quiet = TRUE\n  )\n}\n\nif (!file.exists(silva_species_assignment)) {\n  download.file(\n    \"https://zenodo.org/record/4587955/files/silva_species_assignment_v138.1.fa.gz\",\n    silva_species_assignment,\n    quiet = TRUE\n  )\n}\n\n\n\n\nWe will use in this practical R functions especially written for this course. The “classic” way to import functions is to use source() with the name of the R script to source.\nInstead, we use devtools::load_all(). This function will source all the scripts from the folder R/ along with the documentation in man/ `\n\ndevtools::load_all()"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#locate-the-sequencing-files",
    "href": "practicals/preprocessing_dada2.html#locate-the-sequencing-files",
    "title": "Preprocessing : dada2",
    "section": "2.1 Locate the sequencing files",
    "text": "2.1 Locate the sequencing files\nSave the path to the directory containing your raw data (paired-end sequencing fastq files) in a variable named path_to_fastqs\n\npath_to_fastqs <- here::here(\"data\", \"raw\")\n\nThe gzipped (compressed) FASTQ formated “forward” (R1) and “reverse” (R2) files are named as follow:\n\n${SAMPLENAME}_R1.fastq.gz for the forward files\n${SAMPLENAME}_R2.fastq.gz for the reverse files.\n\nWe list the forward files using the function list.files(). The argument pattern gives you the possibility to only select file names matching a regular expression. In our case, we select all file names finising by _R1.fastq.gz.\n\nfnFs <- sort(list.files(path_to_fastqs,\n                        pattern = \"_R1.fastq.gz\",\n                        full.names = TRUE))\n\nWe do the same for reverse samples.\n\nfnRs <- sort(list.files(path_to_fastqs,\n                        pattern = \"_R2.fastq.gz\",\n                        full.names = TRUE))\n\nTo understand: What fnFs & fnRs variables contain?\n\nhead(fnFs)\n\n[1] \"/home/nicolas/Documents/anf-metabarcoding/data/raw/S11B_R1.fastq.gz\"\n[2] \"/home/nicolas/Documents/anf-metabarcoding/data/raw/S1B_R1.fastq.gz\" \n[3] \"/home/nicolas/Documents/anf-metabarcoding/data/raw/S2B_R1.fastq.gz\" \n[4] \"/home/nicolas/Documents/anf-metabarcoding/data/raw/S2S_R1.fastq.gz\" \n[5] \"/home/nicolas/Documents/anf-metabarcoding/data/raw/S3B_R1.fastq.gz\" \n[6] \"/home/nicolas/Documents/anf-metabarcoding/data/raw/S3S_R1.fastq.gz\""
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#extract-sample-names",
    "href": "practicals/preprocessing_dada2.html#extract-sample-names",
    "title": "Preprocessing : dada2",
    "section": "2.2 Extract sample names",
    "text": "2.2 Extract sample names\n\nsample_names <- basename(fnFs) |>\n  strsplit(split = \"_\") |>\n  sapply(`[`, 1)\n\nTo understand:\nbasename(): remove path to only keep file name.\n|>: R “pipe”. It allows you to chain functions, avoiding intermediate variables and nested parenthesis. It basically transfers the output of the left expression to the input of the right expression. You need R > 4.1 to use this pipe, otherwise use %>% from magrittr.\nstrsplit(): split character chain according to a defined pattern. ?strsplit for documentation.\nsapply(): apply a function to each element of a list or vector. The output is simplified to be vector.\nLet’s go step by step. First list the R1 file names.\n\nbasename(fnFs) |>\n  head()\n\n[1] \"S11B_R1.fastq.gz\" \"S1B_R1.fastq.gz\"  \"S2B_R1.fastq.gz\"  \"S2S_R1.fastq.gz\" \n[5] \"S3B_R1.fastq.gz\"  \"S3S_R1.fastq.gz\" \n\n\nWe can see that the sample name is before the first _. With strsplit(), we can split each file name into a 2 elements vector. The result is a list of 2 elements vectors.\n\nbasename(fnFs) |>\n  strsplit(split = \"_\") |>\n  head()\n\n[[1]]\n[1] \"S11B\"        \"R1.fastq.gz\"\n\n[[2]]\n[1] \"S1B\"         \"R1.fastq.gz\"\n\n[[3]]\n[1] \"S2B\"         \"R1.fastq.gz\"\n\n[[4]]\n[1] \"S2S\"         \"R1.fastq.gz\"\n\n[[5]]\n[1] \"S3B\"         \"R1.fastq.gz\"\n\n[[6]]\n[1] \"S3S\"         \"R1.fastq.gz\"\n\n\nNow, We just have to extract the first element for each file.\n\nbasename(fnFs) |>\n  strsplit(split = \"_\") |>\n  sapply(`[`, 1) |>\n  head()\n\n[1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\" \n\n\nTip: you can achieve the same thing using regular expressions:\n\ngsub(\"^.+/|_.+$\", \"\", fnFs) |> head()\n\n[1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\" \n\n\nRegular expressions are extremly useful. If you are keen to learn how to use them, have a look here"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#prepare-outputs",
    "href": "practicals/preprocessing_dada2.html#prepare-outputs",
    "title": "Preprocessing : dada2",
    "section": "4.1 Prepare outputs",
    "text": "4.1 Prepare outputs\nWe first create a folder where to save the reads once they are trimmed:\n\npath_to_trimmed_reads <- here::here(\"outputs\",\n                                    \"dada2\",\n                                    \"trimmed\")\n\nif (!dir.exists(path_to_trimmed_reads)) dir.create(path_to_trimmed_reads)\n\nThen we prepare a list of paths where to save the results (e.g. sequences without primers)\n\nnopFw <- file.path(path_to_trimmed_reads, basename(fnFs))\nnopRv <- file.path(path_to_trimmed_reads, basename(fnRs))\n\nhead(nopFw)\n\n[1] \"/home/nicolas/Documents/anf-metabarcoding/outputs/dada2/trimmed/S11B_R1.fastq.gz\"\n[2] \"/home/nicolas/Documents/anf-metabarcoding/outputs/dada2/trimmed/S1B_R1.fastq.gz\" \n[3] \"/home/nicolas/Documents/anf-metabarcoding/outputs/dada2/trimmed/S2B_R1.fastq.gz\" \n[4] \"/home/nicolas/Documents/anf-metabarcoding/outputs/dada2/trimmed/S2S_R1.fastq.gz\" \n[5] \"/home/nicolas/Documents/anf-metabarcoding/outputs/dada2/trimmed/S3B_R1.fastq.gz\" \n[6] \"/home/nicolas/Documents/anf-metabarcoding/outputs/dada2/trimmed/S3S_R1.fastq.gz\""
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#remove-primers",
    "href": "practicals/preprocessing_dada2.html#remove-primers",
    "title": "Preprocessing : dada2",
    "section": "4.2 Remove primers",
    "text": "4.2 Remove primers\nThe data you are working with correspond to the V3-V4 region using the primers Pro341F (CCTACGGGNBGCASCAG) and Pro805R (GACTACNVGGGTATCTAAT) Save into variables the forward and reverse primers.\n\nprimer_fwd  <- \"CCTACGGGNBGCASCAG\"\n#regular expression: CCTACGGG.[CGT]GCA[GC]CAG\nprimer_rev  <- \"GACTACNVGGGTATCTAAT\"\n\nLet’s have a closer look to sequences:\n\nseq_zoom <- Biostrings::readDNAStringSet(fnFs[1],\n                             format = \"fastq\",\n                             nrec = 10)\n\nseq_zoom\n\nDNAStringSet object of length 10:\n     width seq                                              names               \n [1]   293 CCTACGGGGGGCAGCAGTAGGGA...ACATCGGCTTAACCGATGAAGT M01522:260:000000...\n [2]   293 CCTACGGGTGGCACCAGTAGGGA...CGGGGCTTAACCTCGGAACTGC M01522:260:000000...\n [3]   292 CCTACGGGGCGCAGCAGGCGCGA...GGGACCGGGAGAGGTGTGAGGT M01522:260:000000...\n [4]   293 CCTACGGGGTGCAGCAGTAGGGA...TCAAAACTCCCAGTCTAGAGTT M01522:260:000000...\n [5]   291 CCTACGGGTGGCAGCAGTGGGGA...GCAGTGGAAACTGTTGGGCTTG M01522:260:000000...\n [6]   293 CCTACGGGATGCAGCAGGCGCGA...GGGACCGGGAGAGGTGTGGGGG M01522:260:000000...\n [7]   292 CCTACGGGATGCAGCAGTGGGGA...TTTAATCCTGATGAGCTAGAAA M01522:260:000000...\n [8]   293 CCTACGGGGCGCAGCAGTAGGGA...TTAAAACTTTTGTTCTGGAATT M01522:260:000000...\n [9]   292 CCTACGGGTTGCAGCAGTGGGGA...ATTAAAACTTTTCAGCTAGAGT M01522:260:000000...\n[10]   293 CCTACGGGAGGCAGCAGTGGGGA...CCCGGGCTCAACCTGGGAACGG M01522:260:000000...\n\n\nUse the function dada2::removePrimers() twice to remove the primers from forward fnFs and reverse fnRs reads and save the results in nopFs and nopRs respectively.\n\ndada2::removePrimers(fn = fnFs,\n                     fout = nopFw,\n                     primer.fwd = primer_fwd,\n                     max.mismatch = 1,\n                     verbose = TRUE)\n\ndada2::removePrimers(fn = fnRs,\n                     fout = nopRv,\n                     primer.fwd = primer_rev,\n                     max.mismatch = 1,\n                     verbose = TRUE)"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#for-more-complex-situations",
    "href": "practicals/preprocessing_dada2.html#for-more-complex-situations",
    "title": "Preprocessing : dada2",
    "section": "4.3 For more complex situations",
    "text": "4.3 For more complex situations\nIf you have to deal with a lot of samples and/or mixed orientated reads, we would recommend using dedicated tools such as cutadapt.\nIf you have to deal with mix-orientated paired-end reads, you may find inspiration here"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#learn-the-error-model",
    "href": "practicals/preprocessing_dada2.html#learn-the-error-model",
    "title": "Preprocessing : dada2",
    "section": "6.1 Learn the error model",
    "text": "6.1 Learn the error model\nTo be able to denoise your data, you need an error model. The error model will tell you at which rate a nucleotide is replace by another for a given quality score. For example, for a quality score Q of 30, what is the probability of an A being wrongly read as a T.\nThis error model can be learnt directly from the data with the function dada2::learnErrors(). You can come back to the course for more details about the maths behind.\n\nerrF <- dada2::learnErrors(filtFs,\n                           randomize = TRUE,\n                           multithread = TRUE)\n\n5155290 total bases in 18715 reads from 18 samples will be used for learning the error rates.\n\nerrR <- dada2::learnErrors(filtRs,\n                           randomize = TRUE,\n                           multithread = TRUE)\n\n5277647 total bases in 18715 reads from 18 samples will be used for learning the error rates.\n\n\nYou can visualise the resulting error model using the function dada2::plotErrors()\n\ndada2::plotErrors(errF, nominalQ=TRUE)\n\nWarning: Transformation introduced infinite values in continuous y-axis\nTransformation introduced infinite values in continuous y-axis"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#dereplication",
    "href": "practicals/preprocessing_dada2.html#dereplication",
    "title": "Preprocessing : dada2",
    "section": "6.2 Dereplication",
    "text": "6.2 Dereplication\nBefore denoising, we need to dereplicate the sequences. It means, for each unique sequence, count the number of reads.\nThe dereplication is achieved using the function dada2::derepFastq()\n\nderepFs <- dada2::derepFastq(filtFs, verbose = TRUE)\n\nderepRs <- dada2::derepFastq(filtRs, verbose = TRUE)"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#run-dada",
    "href": "practicals/preprocessing_dada2.html#run-dada",
    "title": "Preprocessing : dada2",
    "section": "6.3 Run dada",
    "text": "6.3 Run dada\nNow we are ready to run the denoising algorithm with dada2::dada(). As input, we need the error model and the dereplicated sequences.\n\ndadaFs <- dada2::dada(derepFs, err = errF, multithread = TRUE)\n\nSample 1 - 994 reads in 633 unique sequences.\nSample 2 - 1051 reads in 683 unique sequences.\nSample 3 - 1058 reads in 671 unique sequences.\nSample 4 - 1046 reads in 661 unique sequences.\nSample 5 - 1044 reads in 670 unique sequences.\nSample 6 - 1132 reads in 665 unique sequences.\nSample 7 - 1058 reads in 649 unique sequences.\nSample 8 - 1135 reads in 563 unique sequences.\nSample 9 - 1049 reads in 668 unique sequences.\nSample 10 - 1055 reads in 578 unique sequences.\nSample 11 - 1035 reads in 597 unique sequences.\nSample 12 - 1025 reads in 563 unique sequences.\nSample 13 - 997 reads in 586 unique sequences.\nSample 14 - 1008 reads in 578 unique sequences.\nSample 15 - 976 reads in 595 unique sequences.\nSample 16 - 1051 reads in 604 unique sequences.\nSample 17 - 956 reads in 566 unique sequences.\nSample 18 - 1045 reads in 582 unique sequences.\n\ndadaRs <- dada2::dada(derepRs, err = errR, multithread = TRUE)\n\nSample 1 - 994 reads in 730 unique sequences.\nSample 2 - 1051 reads in 763 unique sequences.\nSample 3 - 1058 reads in 780 unique sequences.\nSample 4 - 1046 reads in 747 unique sequences.\nSample 5 - 1044 reads in 762 unique sequences.\nSample 6 - 1132 reads in 796 unique sequences.\nSample 7 - 1058 reads in 763 unique sequences.\nSample 8 - 1135 reads in 733 unique sequences.\nSample 9 - 1049 reads in 777 unique sequences.\nSample 10 - 1055 reads in 718 unique sequences.\nSample 11 - 1035 reads in 727 unique sequences.\nSample 12 - 1025 reads in 672 unique sequences.\nSample 13 - 997 reads in 700 unique sequences.\nSample 14 - 1008 reads in 709 unique sequences.\nSample 15 - 976 reads in 699 unique sequences.\nSample 16 - 1051 reads in 762 unique sequences.\nSample 17 - 956 reads in 674 unique sequences.\nSample 18 - 1045 reads in 724 unique sequences."
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#r-objects",
    "href": "practicals/preprocessing_dada2.html#r-objects",
    "title": "Preprocessing : dada2",
    "section": "11.1 R objects",
    "text": "11.1 R objects\nThe results can be exported as a R objects, one object for the ASV table and another one for the taxonomy.\n\nexport_folder <- here::here(\"outputs\", \"dada2\", \"asv_table\")\n\nif (!dir.exists(export_folder)) dir.create(export_folder)\n\nsaveRDS(object = seqtab_nochim,\n        file = file.path(export_folder, \"seqtab_nochim.rds\"))\n\nsaveRDS(object = taxonomy,\n        file = file.path(export_folder, \"taxonomy.rds\"))"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#text-files",
    "href": "practicals/preprocessing_dada2.html#text-files",
    "title": "Preprocessing : dada2",
    "section": "11.2 Text files",
    "text": "11.2 Text files\nWe recommand to export your results as text files. They are then easy reusable by other programs/languages.\nBut before, we need to format the data a little bit.\nFirst we create a new variable to collect the ASV sequences:\n\nasv_seq <- colnames(seqtab_nochim)\n\nWe create unique ids for each ASV. The sequence itself is an unique id, but we would like to have something shorter. The ids are generated using the cryptographic hash function SHA-1. A given sequence will always give you the same result, which means that if you have the same id in two different datasets, it means that it is the same sequence. It won’t be true for arbitrary ids such as ASV1, ASV2 and so on.\nTo do so we use the function digest::digest():\n\nasv_id <- sapply(asv_seq,\n                 function(x) unname(digest::digest(x, algo = \"sha1\")))\n\nand rename the different variables with the new ids\n\nrow.names(taxonomy) <- colnames(seqtab_nochim) <- names(asv_seq) <- asv_id\n\nBefore exporting the data frames (taxonomy and seqtab_nochim) as a text file, we convert their row names (ASV ids) into a new column named asv. This is achieved using the custom function df_export()\n\ntaxonomy_export <- df_export(taxonomy, new_rn = \"asv\")\n\nseqtab_nochim_export <- t(seqtab_nochim)\nseqtab_nochim_export <- df_export(seqtab_nochim_export, new_rn = \"asv\")\n\nFinally, we can export the taxonomy\n\nwrite.table(taxonomy_export,\n            file = file.path(export_folder, \"taxonomy.tsv\"),\n            quote = FALSE,\n            sep = \"\\t\",\n            row.names = FALSE)\n\nthe ASV table\n\nwrite.table(seqtab_nochim_export,\n            file = file.path(export_folder, \"asv_table.tsv\"),\n            quote = FALSE,\n            sep = \"\\t\",\n            row.names = FALSE)\n\nand the sequences as a fasta file\n\ncat(paste0(\">\", names(asv_seq), \"\\n\", asv_seq),\n    sep = \"\\n\",\n    file = file.path(export_folder, \"asv.fasta\"))"
  },
  {
    "objectID": "practicals/preprocessing_dada2.html#log",
    "href": "practicals/preprocessing_dada2.html#log",
    "title": "Preprocessing : dada2",
    "section": "11.3 Log",
    "text": "11.3 Log\nStatistics about each preprocessing can also be exported.\nFirst this table need to be assembled:\n\ngetN <- function(x) sum(dada2::getUniques(x))\n\nlog_table <- data.frame(input = out[, 1],\n                    filtered = out[, 2],\n                    denoisedF = sapply(dadaFs, getN),\n                    denoisedR = sapply(dadaRs, getN),\n                    merged = sapply(mergers, getN),\n                    nonchim = rowSums(seqtab_nochim),\n                    perc_retained = rowSums(seqtab_nochim) / out[, 1] * 100)\n\nrownames(log_table) <- sample_names\n\nThen it can be exported:\n\ndf_export(log_table, new_rn = \"sample\") |>\n  write.table(file = file.path(export_folder, \"log_table.tsv\"),\n              quote = FALSE,\n              sep = \"\\t\",\n              row.names = FALSE)"
  },
  {
    "objectID": "courses/phyloseq.html#asv-table",
    "href": "courses/phyloseq.html#asv-table",
    "title": "Introduction to phyloseq",
    "section": "ASV table",
    "text": "ASV table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS11B\nS1B\nS2B\nS2S\nS3B\nS3S\nS4B\nS4S\nS5B\nS5S\nS6B\nS6S\nS7B\nS7S\nS8B\nS8S\nS9B\nS9S\n\n\n\n\n8e57b5813bc7e9f8e856bee05e4dfc9461d3ab0d\n101\n52\n40\n97\n51\n72\n11\n63\n160\n161\n138\n62\n41\n70\n47\n59\n60\n78\n\n\n75ca2ab3b10206afb2a3fec2fa754eed9c74a10f\n93\n17\n43\n71\n40\n0\n38\n32\n49\n31\n49\n34\n46\n44\n58\n75\n45\n57\n\n\n7636c4b6a068bda08f8403aa30257c8bb0e600a1\n22\n0\n0\n66\n8\n0\n0\n0\n0\n0\n68\n236\n86\n32\n46\n7\n82\n56\n\n\nda30b71ca1d8c9535e53e7625851ed01643cecab\n74\n48\n0\n93\n42\n36\n33\n55\n0\n0\n67\n29\n0\n0\n48\n71\n67\n0\n\n\n9afe9ffe57ea2823eeac848b4298d427a7c6f3d2\n61\n0\n0\n10\n0\n23\n26\n0\n51\n63\n21\n17\n62\n84\n60\n70\n49\n14\n\n\nab1fe7bea9d0c4e38d145e8b804f46ec19d91a75\n44\n0\n0\n30\n0\n0\n0\n0\n53\n33\n63\n45\n23\n63\n50\n47\n49\n54\n\n\n054cb44ce6443de3df2b08f84d9a4476ed68bd10\n27\n0\n0\n53\n0\n0\n9\n10\n9\n0\n46\n57\n61\n28\n59\n22\n39\n54\n\n\n1de36a7cc825dfa5d6ff68ca3c90c14568a3c17b\n0\n48\n32\n0\n42\n41\n33\n37\n85\n58\n0\n0\n0\n46\n0\n0\n0\n43\n\n\n99989ba2a095c5f9ec9c1ee5b7ab39c9d135ead8\n33\n47\n49\n34\n60\n0\n0\n0\n0\n0\n30\n13\n26\n41\n37\n41\n0\n41\n\n\n9ae12a481d70e09f45bff758cb0cfbef14e12571\n0\n47\n52\n0\n64\n40\n39\n130\n0\n54\n0\n0\n0\n0\n0\n0\n0\n0"
  },
  {
    "objectID": "courses/phyloseq.html#information-about-one-asv",
    "href": "courses/phyloseq.html#information-about-one-asv",
    "title": "Introduction to phyloseq",
    "section": "Information about one ASV",
    "text": "Information about one ASV\n\nTaxonomy\n\n\ntaxonomy[1,]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKingdom\nPhylum\nClass\nOrder\nFamily\nGenus\nSpecies\n\n\n\n\n8e57b5813bc7e9f8e856bee05e4dfc9461d3ab0d\nBacteria\nCyanobacteria\nCyanobacteriia\nSynechococcales\nCyanobiaceae\nSynechococcus CC9902\nNA\n\n\n\n\n\n\nSequence\n\n\nasv_seq[[\"8e57b5813bc7e9f8e856bee05e4dfc9461d3ab0d\"]]\n\n406-letter DNAString object\nseq: TGGGGAATTTTCCGCAATGGGCGAAAGCCTGACGGA...TGACGCTCATGGACGAAAGCCAGGGGAGCGAAAGGG"
  },
  {
    "objectID": "courses/phyloseq.html#information-about-the-samples",
    "href": "courses/phyloseq.html#information-about-the-samples",
    "title": "Introduction to phyloseq",
    "section": "Information about the samples",
    "text": "Information about the samples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeo\nDescription\ngroupe\nPres\nPicoEuk\nSynec\nProchloro\nNanoEuk\nCrypto\nSiOH4\nNO2\nNO3\nNH4\nPO4\nNT\nPT\nChla\nT\nS\nSigma_t\n\n\n\n\nS1B\nNorth\nNorth1B\nNBF\n52\n660\n32195\n10675\n955\n115\n1.813\n0.256\n0.889\n0.324\n0.132\n9.946\n3.565\n0.0000\n22.7338\n37.6204\n26.0046\n\n\nS2B\nNorth\nNorth2B\nNBF\n59\n890\n25480\n16595\n670\n395\n2.592\n0.105\n1.125\n0.328\n0.067\n9.378\n3.391\n0.0000\n22.6824\n37.6627\n26.0521\n\n\nS2S\nNorth\nNorth2S\nNBS\n0\n890\n25480\n16595\n670\n395\n3.381\n0.231\n0.706\n0.450\n0.109\n8.817\n3.345\n0.0000\n22.6854\n37.6176\n26.0137\n\n\nS3B\nNorth\nNorth3B\nNBF\n74\n835\n13340\n25115\n1115\n165\n1.438\n0.057\n1.159\n0.369\n0.174\n8.989\n2.568\n0.0000\n21.5296\n37.5549\n26.2987\n\n\nS3S\nNorth\nNorth3S\nNBS\n0\n715\n26725\n16860\n890\n200\n1.656\n0.098\n0.794\n0.367\n0.095\n7.847\n2.520\n0.0000\n22.5610\n37.5960\n26.0332\n\n\nS4B\nNorth\nNorth4B\nNBF\n78\n2220\n3130\n29835\n2120\n235\n2.457\n0.099\n1.087\n0.349\n0.137\n8.689\n3.129\n0.0000\n18.8515\n37.4542\n26.9415\n\n\nS4S\nNorth\nNorth4S\nNBS\n78\n2220\n3130\n29835\n2120\n235\n2.457\n0.099\n1.087\n0.349\n0.137\n8.689\n3.129\n0.0000\n18.8515\n37.4542\n26.9415\n\n\nS5B\nNorth\nNorth5B\nNBF\n42\n1620\n55780\n23795\n2555\n1355\n2.028\n0.103\n1.135\n0.216\n0.128\n8.623\n3.137\n0.0102\n24.1905\n38.3192\n26.1037\n\n\nS5S\nNorth\nNorth5S\nNBS\n0\n1620\n56555\n22835\n2560\n945\n2.669\n0.136\n0.785\n0.267\n0.114\n9.146\n3.062\n0.0000\n24.1789\n38.3213\n26.1065\n\n\nS6B\nSouth\nSouth1B\nSGF\n13\n2520\n39050\n705\n3630\n1295\n2.206\n0.249\n0.768\n0.629\n0.236\n9.013\n3.455\n0.0000\n22.0197\n39.0877\n27.3241"
  },
  {
    "objectID": "courses/phyloseq.html#subset-samples",
    "href": "courses/phyloseq.html#subset-samples",
    "title": "Introduction to phyloseq",
    "section": "Subset samples",
    "text": "Subset samples\n\nsouth_context <- subset(context, Geo == \"South\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeo\nDescription\ngroupe\nPres\nPicoEuk\nSynec\nProchloro\nNanoEuk\nCrypto\nSiOH4\nNO2\nNO3\nNH4\nPO4\nNT\nPT\nChla\nT\nS\nSigma_t\n\n\n\n\nS6B\nSouth\nSouth1B\nSGF\n13\n2520\n39050\n705\n3630\n1295\n2.206\n0.249\n0.768\n0.629\n0.236\n9.013\n3.455\n0.0000\n22.0197\n39.0877\n27.3241\n\n\nS6S\nSouth\nSouth1S\nSGS\n0\n2435\n35890\n915\n3735\n1300\n3.004\n0.251\n0.927\n0.653\n0.266\n8.776\n3.230\n0.0134\n22.0515\n39.0884\n27.3151\n\n\nS7B\nSouth\nSouth2B\nSGF\n26\n0\n0\n0\n4005\n1600\n3.016\n0.157\n0.895\n0.491\n0.176\n8.968\n4.116\n0.0000\n23.6669\n38.9699\n26.7536\n\n\nS7S\nSouth\nSouth2S\nSGS\n0\n4535\n26545\n1340\n6585\n1355\n1.198\n0.165\n1.099\n0.432\n0.180\n8.256\n3.182\n0.0000\n23.6814\n38.9708\n26.7488\n\n\nS8B\nSouth\nSouth3B\nSGF\n33\n0\n0\n0\n5910\n1590\n3.868\n0.253\n0.567\n0.533\n0.169\n8.395\n3.126\n0.0000\n23.1236\n39.0054\n26.9423\n\n\nS8S\nSouth\nSouth3S\nSGS\n0\n4260\n36745\n985\n5470\n2265\n3.639\n0.255\n0.658\n0.665\n0.247\n8.991\n3.843\n0.0132\n23.3147\n38.9885\n26.8713\n\n\n\n\n\n\n\n\n\nsouth_samples <- row.names(south_context)"
  },
  {
    "objectID": "courses/phyloseq.html#which-asvs-are-cyanobacteria",
    "href": "courses/phyloseq.html#which-asvs-are-cyanobacteria",
    "title": "Introduction to phyloseq",
    "section": "Which ASVs are Cyanobacteria?",
    "text": "Which ASVs are Cyanobacteria?\n\ncyano_taxo <- subset(taxonomy, Phylum == \"Cyanobacteria\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKingdom\nPhylum\nClass\nOrder\nFamily\nGenus\nSpecies\n\n\n\n\n8e57b5813bc7e9f8e856bee05e4dfc9461d3ab0d\nBacteria\nCyanobacteria\nCyanobacteriia\nSynechococcales\nCyanobiaceae\nSynechococcus CC9902\nNA\n\n\n22aadd43e88795bdc601040af311182e3440157c\nBacteria\nCyanobacteria\nCyanobacteriia\nSynechococcales\nCyanobiaceae\nProchlorococcus MIT9313\nmarinus\n\n\n467820280624aa1dc05cdc6a5d76fb93e22fa701\nBacteria\nCyanobacteria\nCyanobacteriia\nChloroplast\nNA\nNA\nNA\n\n\n956525620eb1842a14f209b36cb295ff74043ece\nBacteria\nCyanobacteria\nCyanobacteriia\nSynechococcales\nCyanobiaceae\nProchlorococcus MIT9313\nmarinus\n\n\n\n\n\n\n\n\ncyano_asvs <- row.names(cyano_taxo)"
  },
  {
    "objectID": "courses/phyloseq.html#subset-asv-table",
    "href": "courses/phyloseq.html#subset-asv-table",
    "title": "Introduction to phyloseq",
    "section": "Subset asv table",
    "text": "Subset asv table\n\nasv_table_cyano <- asv_table[cyano_asvs,south_samples]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nS6B\nS6S\nS7B\nS7S\nS8B\nS8S\nS9B\nS9S\nS11B\n\n\n\n\n8e57b5813bc7e9f8e856bee05e4dfc9461d3ab0d\n138\n62\n41\n70\n47\n59\n60\n78\n101\n\n\n22aadd43e88795bdc601040af311182e3440157c\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n467820280624aa1dc05cdc6a5d76fb93e22fa701\n12\n9\n16\n11\n19\n12\n16\n9\n5\n\n\n956525620eb1842a14f209b36cb295ff74043ece\n0\n0\n0\n0\n0\n0\n0\n15\n0\n\n\n74d14f8459fa61d310b66472aa76f53bcd539d46\n0\n0\n0\n9\n0\n12\n0\n0\n0\n\n\n64649f74679ddd46d97f558a6faeace607cca08e\n0\n0\n0\n0\n0\n0\n0\n12\n0\n\n\n5fff88e383763b45c12cc486762817c327be6e16\n0\n0\n0\n0\n0\n0\n0\n10\n0\n\n\na0ca1c2ce9c7508d31a16a2de62e2898715b7c56\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\nf5fb70404afd3526d1893acbcac6c38fe4e09dda\n0\n0\n0\n0\n0\n0\n0\n8\n0"
  },
  {
    "objectID": "courses/phyloseq.html#cyanobacteria-present-in-south-samples",
    "href": "courses/phyloseq.html#cyanobacteria-present-in-south-samples",
    "title": "Introduction to phyloseq",
    "section": "Cyanobacteria present in south samples",
    "text": "Cyanobacteria present in south samples\n\ncyano_total <- apply(asv_table_cyano, 1, sum)\n\n\n\n\n                                         total\n8e57b5813bc7e9f8e856bee05e4dfc9461d3ab0d   656\n22aadd43e88795bdc601040af311182e3440157c     0\n467820280624aa1dc05cdc6a5d76fb93e22fa701   109\n956525620eb1842a14f209b36cb295ff74043ece    15\n74d14f8459fa61d310b66472aa76f53bcd539d46    21\n64649f74679ddd46d97f558a6faeace607cca08e    12\n5fff88e383763b45c12cc486762817c327be6e16    10\na0ca1c2ce9c7508d31a16a2de62e2898715b7c56     0\nf5fb70404afd3526d1893acbcac6c38fe4e09dda     8\n\n\n\n\ncyano_subset <- names(cyano_total)[cyano_total > 0]"
  },
  {
    "objectID": "courses/phyloseq.html#exract-sequences",
    "href": "courses/phyloseq.html#exract-sequences",
    "title": "Introduction to phyloseq",
    "section": "Exract sequences",
    "text": "Exract sequences\n\nasv_seq_cyano <- asv_seq[cyano_subset]\n\n\n\n\n>8e57b5813bc7e9f8e856bee05e4dfc9461d3ab0d\nTGGGGAATTTTCCGCAATGGGCGAAAGCCTGACGGAGCAACGCCGCGTGAGGGATGAAGGCCTCTGGGCTGTAAACCTCTTTTATCAAGGAAGAAGATCTGACGGTACTTGATGAATAAGCCACGGCTAATTCCGTGCCAGCAGCCGCGGTAATACGGGAGTGGCAAGCGTTATCCGGAATTATTGGGCGTAAAGCGTCCGCAGGCGGCCCTTCAAGTCTGCTGTTAAAAAGTGGAGCTTAACTCCATCATGGCAGTGGAAACTGTTGGGCTTGAGTGTGGTAGGGGCAGAGGGAATTCCCGGTGTAGCGGTGAAATGCGTAGATATCGGGAAGAACACCAGTGGCGAAGGCGCTCTGCTGGGCCATCACTGACGCTCATGGACGAAAGCCAGGGGAGCGAAAGGG\n>467820280624aa1dc05cdc6a5d76fb93e22fa701\nTGAGGAATTTTCCGCAATGGGCGCAAGCCTGACGGAGCAATACCGCGTGAGGGATGACGGCCTTTGGGTTGTAAACCTCTTTTTTCAAGGAGGAAGTTCTGACGTGTACTTGAAGAATAAGCATCGGCTAACTCCGTGCCAGCAGCCGCGGTAAGACGGAGGATGCAAGTGTTATCCGGAATTATTGGGCGTAAAGCGTCTGTAGGTTGCCTAACAAGTCTGTTGTTAAAGGTTAAAGCTTAACTTTAAAACTGCAGCAGAAACTGCTAGGCTTGAGTACAGTCGAAGTAGAGGGAATTTCCAGTGAAGCGGTGAAATGCGTAGATATTGGAAGGAACACCAATGGCGAAAGCACTCTACTAGACTTTTACTGACACTCAGAGACGAAAGCTAGGGTAGCAAATGGG\n>956525620eb1842a14f209b36cb295ff74043ece\nTGGGGAATTTTCCGCAATGGGCGAAAGCCTGACGGAGCAACGCCGCGTGAGGGACGAAGGCCTCTGGGCTGTAAACCTCTTTTCTCAAGGAAGAAGATATGACGGTACTTGAGGAATAAGCCACGGCTAATTCCGTGCCAGCAGCCGCGGTAATACGGGAGTGGCAAGCGTTATCCGGAATTATTGGGCGTAAAGCGTCCGCAGGCGGCTTTTCAAGTCTGCTGTTAAAGCGTGGAGCTTAACTCCATCATGGCAGTGGAAACTGAAAGGCTTGAGTATGGTAGGGGCAGAGGGAATTCCCGGTGTAGCGGTGAAATGCGTAGATATCGGGAAGAACACCAGTGGCGAAGGCGCTCTGCTGGGCCATTACTGACGCTCATGGACGAAAGCCAGGGGAGCGAAAGGG\n>74d14f8459fa61d310b66472aa76f53bcd539d46\nTGGGGAATTTTCCGCAATGGACGAAAGTCTGACGGAGCGACGCTGCGTGAAGGATGACGGCCTGCGGGTTGTAAACTTCTTTTCTCGAAGAAGAAGCTCTGACGGTATTCGAGGAATAAGCATCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGAGGATGCAAGTGTTATTCGGAATGATTGGGCGTAAAGCGTCTGTAGGCTGTATAGAAAGTCTTTTGTTAAATGCCTCGGCTCAACCGAGATCCAGCAAAGGAAACTTCTATACTTGAGGGAAGTAGAGGTACAGGGAATTCCCGGTGGAGCGGTGAAATGCGTAGATATCGGGAGGAACACCAATATGGCGAAGGCACTGTACTGGGCTTTACCTGACGCTCAGAGACGAAAGCTAAAGGAGTGATTAGG\n>64649f74679ddd46d97f558a6faeace607cca08e\nTGAGGAATTTTCCGCAATGGGCGAAAGCCTGACGGAGCAATACCGCGTGAGGGATGAAGGATTTTGGTCTGTAAACCTCTTTTCTCAAGAAAGAAGTTCTGACGGTACTTGAGGAATAAGCATCGGCTAACTCCGTGCCAGCAGCCGCGGTAATACGGGGGATGCAAGCGTTATCCGGAATCATTGGGCGTAAAGCGCCTGTAGGTTGTTTAATAAGTCTGTTGTTAAAGACTGGGGCTTAACCCCAGGAAAGCAATGGAAACTACTAGACTAGAGTATGGTAGGGGTAAAGGGAATTTCTAGTGTAGCGGTGAAATGCGTAGATATTAGAAAGAACACCGGTGGCGAAAGCGCTTTACTGGACCATTACTGACACTCAGAGGCGAAAGCTAGGGTAGCCAAAGGG\n>5fff88e383763b45c12cc486762817c327be6e16\nTGGGGAATTTTCCGCAATGGGCGAAAGCCTGACGGAGCGACGCTGCGTGAAGGATGACGGCCTGAGGGTTGTAAACTTCTTTTCTCGAAGAAGAATCAATGACGGTATTCGAGGAATAAGCATCGGCTAACTCTGTGCCAGCAGCCGCGGTAAGACAGAGGATGCAAGTGTTATTCGGATTGATTGGGCGTAAAGCGTCTGTAGGCGGTTTAGAAAGTCTTTTGTGAAATACTTCAGCTCAACTGGGGCTCCGCAAAAGAAACTTCTAGACTTGAGGGAAGTAGAGGTACAGGGAATTTCCGGTGGAGCGGTGAAATGCGTAGATATCGGAAGGAACACCAATATGGCGAAGGCACTGTACTGGGCTTTACCTGACGCTAAGAGACGAAAGCTAAAGGAGTGATTAGG\n>f5fb70404afd3526d1893acbcac6c38fe4e09dda\nTGGGGAATTTTCCGCAATGGGCGAAAGCCTGACGGAGCAACGCCGCGTGAGGGATGAAGGCCTCTGGGCTGTAAACCTCTTTTATCAAGGAAGAAGATCTGACGGTACTTGATGAATAAGCCACGGCTAATTCCGTGCCAGCAGCCGCGGTAATACGGGAGTGGCAAGCGTTATCCGGAATTATTGGGCGTAAAGCGTCCGCAGGCGGCCTGACAAGTCTGCTGTTAAAGCGTGGAGCTTAACTCCATTTCAGCAGTGGAAACTGTCAGGCTTGAGTGTGGTAGGGGCAGAGGGAATTCCCGGTGTAGCGGTGAAATGCGTAGATATCGGGAAGAACACCAGTGGCGAAAGCGCTCTGCTGGGCCATCACTGACGCTCATGGACGAAAGCCAGGGGAGCGAAAGGG"
  },
  {
    "objectID": "courses/phyloseq.html#go-fancy-with-a-phylogenetic-tree",
    "href": "courses/phyloseq.html#go-fancy-with-a-phylogenetic-tree",
    "title": "Introduction to phyloseq",
    "section": "Go fancy with a phylogenetic tree",
    "text": "Go fancy with a phylogenetic tree"
  },
  {
    "objectID": "courses/phyloseq.html#a-complex-data-structure",
    "href": "courses/phyloseq.html#a-complex-data-structure",
    "title": "Introduction to phyloseq",
    "section": "A complex data structure",
    "text": "A complex data structure\n\n\n\n\n\n\n\nG\n\n  \n\nASV table(abundance information)\n\n ASV table (abundance information)   \n\nSamplesdata\n\n Samples contextual data   \n\nASV table(abundance information)–Samplesdata\n\n   \n\nSequences\n\n Sequences   \n\nASV table(abundance information)–Sequences\n\n   \n\nTaxonomy\n\n Taxonomy   \n\nSequences–Taxonomy\n\n   \n\nPhylogenetic tree\n\n Phylogenetic tree   \n\nSequences–Phylogenetic tree"
  },
  {
    "objectID": "courses/phyloseq.html#the-phyloseq-package",
    "href": "courses/phyloseq.html#the-phyloseq-package",
    "title": "Introduction to phyloseq",
    "section": "The phyloseq package",
    "text": "The phyloseq package\n\n\n\n\n\n\n\nhttps://doi.org/10.1371/journal.pone.0061217.g001"
  },
  {
    "objectID": "courses/phyloseq.html#phyloseq-workflow",
    "href": "courses/phyloseq.html#phyloseq-workflow",
    "title": "Introduction to phyloseq",
    "section": "phyloseq workflow",
    "text": "phyloseq workflow\n\n\n\n\n\n\n\nhttps://doi.org/10.1371/journal.pone.0061217.g002"
  },
  {
    "objectID": "courses/phyloseq.html#phyloseq-object",
    "href": "courses/phyloseq.html#phyloseq-object",
    "title": "Introduction to phyloseq",
    "section": "phyloseq object",
    "text": "phyloseq object\n\n\n\n\n\n\n\nhttps://doi.org/10.1371/journal.pone.0061217.g003"
  },
  {
    "objectID": "courses/phyloseq.html#create-our-phyloseq-object",
    "href": "courses/phyloseq.html#create-our-phyloseq-object",
    "title": "Introduction to phyloseq",
    "section": "Create our phyloseq object",
    "text": "Create our phyloseq object\n\nlibrary(phyloseq)\n\nphyseq <- phyloseq(\n  otu_table(asv_table,taxa_are_rows = TRUE),\n  tax_table(as.matrix(taxonomy)),\n  sample_data(context),\n  refseq(asv_seq),\n  phy_tree(asv_tree)\n)\n\n\n\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 155 taxa and 18 samples ]\nsample_data() Sample Data:       [ 18 samples by 20 sample variables ]\ntax_table()   Taxonomy Table:    [ 155 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 155 tips and 153 internal nodes ]\nrefseq()      DNAStringSet:      [ 155 reference sequences ]"
  },
  {
    "objectID": "courses/phyloseq.html#redo-our-selection",
    "href": "courses/phyloseq.html#redo-our-selection",
    "title": "Introduction to phyloseq",
    "section": "Redo our selection",
    "text": "Redo our selection\n\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 155 taxa and 18 samples ]\nsample_data() Sample Data:       [ 18 samples by 20 sample variables ]\ntax_table()   Taxonomy Table:    [ 155 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 155 tips and 153 internal nodes ]\nrefseq()      DNAStringSet:      [ 155 reference sequences ]\n\n\n\n\nsubset_taxa(physeq,Phylum == \"Cyanobacteria\")\n\n\n\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 9 taxa and 18 samples ]\nsample_data() Sample Data:       [ 18 samples by 20 sample variables ]\ntax_table()   Taxonomy Table:    [ 9 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 9 tips and 8 internal nodes ]\nrefseq()      DNAStringSet:      [ 9 reference sequences ]"
  },
  {
    "objectID": "courses/phyloseq.html#redo-our-selection-1",
    "href": "courses/phyloseq.html#redo-our-selection-1",
    "title": "Introduction to phyloseq",
    "section": "Redo our selection",
    "text": "Redo our selection\n\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 155 taxa and 18 samples ]\nsample_data() Sample Data:       [ 18 samples by 20 sample variables ]\ntax_table()   Taxonomy Table:    [ 155 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 155 tips and 153 internal nodes ]\nrefseq()      DNAStringSet:      [ 155 reference sequences ]\n\n\n\n\nsubset_taxa(physeq,Phylum == \"Cyanobacteria\") |>\n  subset_samples(Geo == \"South\") \n\n\n\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 9 taxa and 9 samples ]\nsample_data() Sample Data:       [ 9 samples by 20 sample variables ]\ntax_table()   Taxonomy Table:    [ 9 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 9 tips and 8 internal nodes ]\nrefseq()      DNAStringSet:      [ 9 reference sequences ]"
  },
  {
    "objectID": "courses/phyloseq.html#redo-our-selection-2",
    "href": "courses/phyloseq.html#redo-our-selection-2",
    "title": "Introduction to phyloseq",
    "section": "Redo our selection",
    "text": "Redo our selection\n\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 155 taxa and 18 samples ]\nsample_data() Sample Data:       [ 18 samples by 20 sample variables ]\ntax_table()   Taxonomy Table:    [ 155 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 155 tips and 153 internal nodes ]\nrefseq()      DNAStringSet:      [ 155 reference sequences ]\n\n\n\n\nsubset_taxa(physeq,Phylum == \"Cyanobacteria\") |>\n  subset_samples(Geo == \"South\") |>\n  filter_taxa(function(x) sum(x) > 0, prune = TRUE)\n\n\n\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 7 taxa and 9 samples ]\nsample_data() Sample Data:       [ 9 samples by 20 sample variables ]\ntax_table()   Taxonomy Table:    [ 7 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 7 tips and 6 internal nodes ]\nrefseq()      DNAStringSet:      [ 7 reference sequences ]"
  },
  {
    "objectID": "courses/phyloseq.html#redo-our-selection-3",
    "href": "courses/phyloseq.html#redo-our-selection-3",
    "title": "Introduction to phyloseq",
    "section": "Redo our selection",
    "text": "Redo our selection\n\nsubset_taxa(physeq,Phylum == \"Cyanobacteria\") |>\n  subset_samples(Geo == \"South\") |>\n  filter_taxa(function(x) sum(x) > 0, prune = TRUE) |>\n  plot_bar(fill=\"Genus\")"
  },
  {
    "objectID": "courses/phyloseq.html#phyloseq-in-this-course",
    "href": "courses/phyloseq.html#phyloseq-in-this-course",
    "title": "Introduction to phyloseq",
    "section": "phyloseq in this course",
    "text": "phyloseq in this course\n\nCreate a phyloseq object from your data\nExplore the taxonomic composition of your communities\nCompare communities composition with ordinations"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html",
    "href": "practicals/preprocessing_phyloseq.html",
    "title": "Preprocessing : phyloseq",
    "section": "",
    "text": "Load phyloseq\n\nlibrary(phyloseq)\n\nWe import the ASV table, the taxonomic assignment results and the sequences from the text files we exported in the dada2 practical.\nDefine where the previous practical outputs are located:\n\ninput_dir <- here::here(\"outputs\", \"dada2\", \"asv_table\")\n\nImport the ASV table:\n\nasv_table <- read.table(file = file.path(input_dir, \"asv_table.tsv\"),\n                        header = TRUE,\n                        sep = \"\\t\",\n                        row.names = 1)\n\nthe results of the taxonomic assignment:\n\ntaxonomy <- read.table(file = file.path(input_dir, \"taxonomy.tsv\"),\n                        header = TRUE,\n                        sep = \"\\t\",\n                        row.names = 1)\n\nand the ASV sequences:\n\nasv_seq <- Biostrings::readDNAStringSet(\n  filepath = file.path(input_dir, \"asv.fasta\"),\n  format = \"fasta\"\n)\n\nWe will also need some information about the samples, the file is located is another folder.\n\ncontext <- read.table(here::here(\"data\",\n                                 \"context\",\n                                 \"mapfileFA.txt\"),\n                      header = TRUE,\n                      row.names = 1)"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#check-sample-file",
    "href": "practicals/preprocessing_phyloseq.html#check-sample-file",
    "title": "Preprocessing : phyloseq",
    "section": "2.1 Check sample file",
    "text": "2.1 Check sample file\nMake sure sample names in the ASV table…\n\ncolnames(asv_table) |> sort()\n\n [1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\"  \"S4B\"  \"S4S\"  \"S5B\"  \"S5S\" \n[11] \"S6B\"  \"S6S\"  \"S7B\"  \"S7S\"  \"S8B\"  \"S8S\"  \"S9B\"  \"S9S\" \n\n\nmatch sample table ids.\n\nrow.names(context) |> sort()\n\n [1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\"  \"S4B\"  \"S4S\"  \"S5B\"  \"S5S\" \n[11] \"S6B\"  \"S6S\"  \"S7B\"  \"S7S\"  \"S8B\"  \"S8S\"  \"S9B\"  \"S9S\" \n\n\nYou can do it in a more formal way using the function setdiff(). This function returns the elements of x not present in y.\n\nsetdiff(x = colnames(asv_table),\n        y = row.names(context))\n\ncharacter(0)\n\n\nPerfect! The ASV table sample names match with the contextual data table."
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#assemble-asv-table-taxonomy-and-contextual-data",
    "href": "practicals/preprocessing_phyloseq.html#assemble-asv-table-taxonomy-and-contextual-data",
    "title": "Preprocessing : phyloseq",
    "section": "2.2 Assemble ASV table, taxonomy and contextual data",
    "text": "2.2 Assemble ASV table, taxonomy and contextual data\nUse the phyloseq::phyloseq() function to create a phyloseq object. A phyloseq object is usualy composed by an ASV table, a taxonomy table and a table describing the samples. You can also add ASV sequences and a phylogenetic tree\n\nphyseq <- phyloseq::phyloseq(\n  phyloseq::otu_table(asv_table, taxa_are_rows = TRUE),\n  phyloseq::tax_table(as.matrix(taxonomy)),\n  phyloseq::sample_data(context),\n  phyloseq::refseq(asv_seq)\n)"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#why",
    "href": "practicals/preprocessing_phyloseq.html#why",
    "title": "Preprocessing : phyloseq",
    "section": "3.1 Why?",
    "text": "3.1 Why?\nKnowing the ASVs phylogenetic relatedness will help you to have a better understanding of the communities your studying.\nTo quote the evolutionary biologist Theodosius Dobzhansky:\n\nNothing in Biology Makes Sense Except in the Light of Evolution.\n\nA phylogenetic tree reconstructed from the ASV sequences will be used to measure their relatedness."
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#alignment-using-decipher",
    "href": "practicals/preprocessing_phyloseq.html#alignment-using-decipher",
    "title": "Preprocessing : phyloseq",
    "section": "3.2 Alignment using DECIPHER",
    "text": "3.2 Alignment using DECIPHER\nBefore reconstructing a phylogenetic tree we need to align the ASVs sequences.\n\naln <- refseq(physeq) |>\n  DECIPHER::AlignSeqs(anchor = NA)\n\nOnce it is done, you can visualise the alignment using the function DECIPHER::BrowseSeqs()\n\nDECIPHER::BrowseSeqs(aln, highlight = 0)"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#infering-the-phylogenetic-tree",
    "href": "practicals/preprocessing_phyloseq.html#infering-the-phylogenetic-tree",
    "title": "Preprocessing : phyloseq",
    "section": "3.3 Infering the phylogenetic tree",
    "text": "3.3 Infering the phylogenetic tree\nWe will infer a phylogenetic from our alignement using the library phangorn.\nFirst, let’s convert our DNAStringSet alignment to the phangorn phyDat format.\n\nphang_align <- as.matrix(aln) |> phangorn::phyDat(type = \"DNA\")\n\nThen, we compute pairwise distances of our aligned sequences using equal base frequencies (JC69 model used by default).\n\ndm <- phangorn::dist.ml(phang_align, model = \"JC69\")\n\nFinally, we reconstruct a neighbour joining tree.\n\ntreeNJ <- phangorn::NJ(dm)\n\nOther approaches to reconstruct a phylogenetic tree exist. If you want to try them with phangorn, have a look here\nWe need the tree to be rooted for future analysis. We can do that using the function phangorn::midpoint()\n\ntreeNJ <- phangorn::midpoint(tree = treeNJ)\n\nOnce we have a rooted tree, we can add it to the phyloseq object.\n\nphyseq <- phyloseq::merge_phyloseq(physeq,treeNJ)"
  },
  {
    "objectID": "practicals/preprocessing_phyloseq.html#if-i-do-not-have-a-tree",
    "href": "practicals/preprocessing_phyloseq.html#if-i-do-not-have-a-tree",
    "title": "Preprocessing : phyloseq",
    "section": "3.4 If I do not have a tree",
    "text": "3.4 If I do not have a tree\nFor some reasons, it is sometimes not relevant or not possible to infer a tree from our data.\nFor example, the metabarcode you are using is not carrying enough phylogenetic information to reconstruct a tree.\nOr you have so many ASVs that infering a tree would require more computational ressource that what you can afford.\nIn that case, it is fine. You will still be able to perform most of the analyses introduced in the alpha and beta diversity practicals."
  },
  {
    "objectID": "practicals/alpha_diversity.html",
    "href": "practicals/alpha_diversity.html",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "",
    "text": "Load libraries\n\nlibrary(phyloseq)\nlibrary(ggplot2)\nlibrary(patchwork)\n\nLoad custom functions:\n\ndevtools::load_all()\n\nDefine output folder:\n\noutput_alpha <- here::here(\"outputs\", \"alpha_diversity\")\nif (!dir.exists(output_alpha)) dir.create(output_alpha)\n\nLoad the data and inspect the phyloseq object:\n\nphyseq <- readRDS(here::here(\"data\",\n                             \"asv_table\",\n                             \"phyloseq_object_alpha_beta_div.rds\"))"
  },
  {
    "objectID": "practicals/alpha_diversity.html#our-phyloseq-object-physeq-is-composed-of",
    "href": "practicals/alpha_diversity.html#our-phyloseq-object-physeq-is-composed-of",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "2.1 Our phyloseq object physeq is composed of:",
    "text": "2.1 Our phyloseq object physeq is composed of:\n\n2.1.1 An ASV table with the absolute counts\nBe careful: Rows are samples, columns are ASVs\n\nphyseq@otu_table[1:10,1:10]\n\nOTU Table:          [10 taxa and 10 samples]\n                     taxa are columns\n     ASV1 ASV2 ASV3 ASV4 ASV5 ASV6 ASV7 ASV8 ASV9 ASV10\nS11B  117   25   85   70   87   40   57   34   41     0\nS1B    67    0   23    0   51   48    0    0   27    58\nS2B    43    0   35   15   42   52    0    0    0    43\nS2S   103   87   76   12   99   43   36   72   46     0\nS3B    59    0   32    0   49   73    0    0    0    57\nS3S    81   10    0   20   36    0    0    0    0    50\nS4B    11    6   38   33   43   46    0    8    0    37\nS4S    68    6   38    0   62    0    0   11   30    46\nS5B   176   18   62  109    0   35   56   13   33    82\nS5S   182    0   36  101   51    0   33    0   29    42\n\n\n\n\n2.1.2 A metadata table with information (e.g. physicochemical, categorical variables) about samples\n\nphyseq@sam_data\n\n     SampName   Geo Description groupe Pres PicoEuk Synec Prochloro NanoEuk\nS11B     S11B South     South5B    SGF   35    5370 46830       580    6010\nS1B       S1B North     North1B    NBF   52     660 32195     10675     955\nS2B       S2B North     North2B    NBF   59     890 25480     16595     670\nS2S       S2S North     North2S    NBS    0     890 25480     16595     670\nS3B       S3B North     North3B    NBF   74     835 13340     25115    1115\nS3S       S3S North     North3S    NBS    0     715 26725     16860     890\nS4B       S4B North     North4B    NBF   78    2220  3130     29835    2120\nS4S       S4S North     North4S    NBS   78    2220  3130     29835    2120\nS5B       S5B North     North5B    NBF   42    1620 55780     23795    2555\nS5S       S5S North     North5S    NBS    0    1620 56555     22835    2560\nS6B       S6B South     South1B    SGF   13    2520 39050       705    3630\nS6S       S6S South     South1S    SGS    0    2435 35890       915    3735\nS7B       S7B South     South2B    SGF   26       0     0         0    4005\nS7S       S7S South     South2S    SGS    0    4535 26545      1340    6585\nS8B       S8B South     South3B    SGF   33       0     0         0    5910\nS8S       S8S South     South3S    SGS    0    4260 36745       985    5470\nS9B       S9B South     South4B    SGF   25    4000 31730       485    4395\nS9S       S9S South     South4S    SGS    0    5465 32860       820    5045\n     Crypto SiOH4   NO2   NO3   NH4   PO4    NT    PT   Chla       T       S\nS11B   1690 3.324 0.083 0.756 0.467 0.115 9.539 4.138 0.0182 23.0308 38.9967\nS1B     115 1.813 0.256 0.889 0.324 0.132 9.946 3.565 0.0000 22.7338 37.6204\nS2B     395 2.592 0.105 1.125 0.328 0.067 9.378 3.391 0.0000 22.6824 37.6627\nS2S     395 3.381 0.231 0.706 0.450 0.109 8.817 3.345 0.0000 22.6854 37.6176\nS3B     165 1.438 0.057 1.159 0.369 0.174 8.989 2.568 0.0000 21.5296 37.5549\nS3S     200 1.656 0.098 0.794 0.367 0.095 7.847 2.520 0.0000 22.5610 37.5960\nS4B     235 2.457 0.099 1.087 0.349 0.137 8.689 3.129 0.0000 18.8515 37.4542\nS4S     235 2.457 0.099 1.087 0.349 0.137 8.689 3.129 0.0000 18.8515 37.4542\nS5B    1355 2.028 0.103 1.135 0.216 0.128 8.623 3.137 0.0102 24.1905 38.3192\nS5S     945 2.669 0.136 0.785 0.267 0.114 9.146 3.062 0.0000 24.1789 38.3213\nS6B    1295 2.206 0.249 0.768 0.629 0.236 9.013 3.455 0.0000 22.0197 39.0877\nS6S    1300 3.004 0.251 0.927 0.653 0.266 8.776 3.230 0.0134 22.0515 39.0884\nS7B    1600 3.016 0.157 0.895 0.491 0.176 8.968 4.116 0.0000 23.6669 38.9699\nS7S    1355 1.198 0.165 1.099 0.432 0.180 8.256 3.182 0.0000 23.6814 38.9708\nS8B    1590 3.868 0.253 0.567 0.533 0.169 8.395 3.126 0.0000 23.1236 39.0054\nS8S    2265 3.639 0.255 0.658 0.665 0.247 8.991 3.843 0.0132 23.3147 38.9885\nS9B    1180 3.910 0.107 0.672 0.490 0.134 8.954 4.042 0.0172 22.6306 38.9094\nS9S    1545 3.607 0.139 0.644 0.373 0.167 9.817 3.689 0.0062 22.9545 38.7777\n     Sigma_t\nS11B 26.9631\nS1B  26.0046\nS2B  26.0521\nS2S  26.0137\nS3B  26.2987\nS3S  26.0332\nS4B  26.9415\nS4S  26.9415\nS5B  26.1037\nS5S  26.1065\nS6B  27.3241\nS6S  27.3151\nS7B  26.7536\nS7S  26.7488\nS8B  26.9423\nS8S  26.8713\nS9B  27.0131\nS9S  26.8172\n\n\n\n\n2.1.3 A table of Taxonomic classification of each ASV\n\nphyseq@tax_table[1:10,]\n\nTaxonomy Table:     [10 taxa by 7 taxonomic ranks]:\n      Kingdom    Phylum             Class                 Order             \nASV1  \"Bacteria\" \"Cyanobacteria\"    \"Cyanobacteriia\"      \"Synechococcales\" \nASV2  \"Bacteria\" \"Proteobacteria\"   \"Gammaproteobacteria\" \"Enterobacterales\"\nASV3  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \nASV4  \"Archaea\"  \"Thermoplasmatota\" \"Thermoplasmata\"      \"Marine Group II\" \nASV5  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \nASV6  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \nASV7  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"Rhodospirillales\"\nASV8  \"Bacteria\" \"Proteobacteria\"   \"Gammaproteobacteria\" \"Enterobacterales\"\nASV9  \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \nASV10 \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\" \"SAR11 clade\"     \n      Family                    Genus                  Species\nASV1  \"Cyanobiaceae\"            \"Synechococcus CC9902\" NA     \nASV2  \"Pseudoalteromonadaceae\"  \"Pseudoalteromonas\"    NA     \nASV3  \"Clade I\"                 \"Clade Ia\"             NA     \nASV4  NA                        NA                     NA     \nASV5  \"Clade I\"                 \"Clade Ia\"             NA     \nASV6  \"Clade II\"                NA                     NA     \nASV7  \"AEGEAN-169 marine group\" NA                     NA     \nASV8  \"Pseudoalteromonadaceae\"  \"Pseudoalteromonas\"    NA     \nASV9  \"Clade I\"                 \"Clade Ia\"             NA     \nASV10 \"Clade I\"                 \"Clade Ia\"             NA     \n\n\n\n\n2.1.4 A Phylogenetic Tree\n\nphyseq@phy_tree\n\n\nPhylogenetic tree with 213 tips and 212 internal nodes.\n\nTip labels:\n  ASV1, ASV2, ASV3, ASV4, ASV5, ASV6, ...\n\nRooted; includes branch lengths.\n\n\n\n\n2.1.5 A table with the ASV Sequences\n\nphyseq@refseq\n\nDNAStringSet object of length 213:\n      width seq                                             names               \n  [1]   402 GGAATTTTCCGCAATGGGCGAA...CGAAAGCCAGGGGAGCGAAAGG ASV1\n  [2]   425 GGAATATTGCACAATGGGCGCA...CGAAAGCGTGGGGAGCAAACAG ASV2\n  [3]   400 GGAATCTTGCACAATGGAGGAA...CGAAAGCATGGGTAGCGAAGAG ASV3\n  [4]   383 CGAAAACTTGACAATGCGAGCA...CGAAGCCTAGGGGCACGAACCG ASV4\n  [5]   400 GGAATCTTGCACAATGGAGGAA...CGAAAGCATGGGTAGCGAAGAG ASV5\n  ...   ... ...\n[209]   426 GGAATTTTGCGCAATGGACGAA...CGAAAGCGTGGGGAGCGAACAG ASV209\n[210]   403 GGAATATTGCACAATGGGCGCA...GGTCAACACTGACGCTCATGTA ASV210\n[211]   360 CGAAAACTTCACACTGCAGGAA...GAACGGATCCGACGGTCAGGGA ASV211\n[212]   400 GGAATATTGGACAATGGGCGAA...CGAAAGCGTGGGTAGCAAACAG ASV212\n[213]   404 GGAATATTGCACAATGGGCGCA...GTCAACACTGACGCTCATGTAC ASV213"
  },
  {
    "objectID": "practicals/alpha_diversity.html#rarefaction-curves",
    "href": "practicals/alpha_diversity.html#rarefaction-curves",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "3.1 Rarefaction Curves",
    "text": "3.1 Rarefaction Curves\nBefore normalization by sub-sampling, let’s have a look at rarefaction curves, evaluate your sequencing effort and make decisions\n\n3.1.1 Identify your minimum sample size\n\nphyloseq::sample_sums(physeq)\n\nS11B  S1B  S2B  S2S  S3B  S3S  S4B  S4S  S5B  S5S  S6B  S6S  S7B  S7S  S8B  S8S \n 975  837  893  983  878  889  917 1077 1018 1006 1076  937  878  936  846  958 \n S9B  S9S \n 888  991 \n\n\n\n\n3.1.2 What is the minimum sample size?\nRun rarefaction curves using our custom function ggrare() (defined in R/alpha_diversity.R)\n\n#Make rarefaction curves & Add min sample size line\nggrare(physeq, step = 10, color = \"Description\", se = FALSE) +\n  geom_vline(xintercept = min(sample_sums(physeq)), color = \"gray60\")\n\n\n\n\n\n\n\nDo you think is a good idea to normalize your data using this minimal sample size?"
  },
  {
    "objectID": "practicals/alpha_diversity.html#normalization-process-for-alpha-diversity-sub-sampling",
    "href": "practicals/alpha_diversity.html#normalization-process-for-alpha-diversity-sub-sampling",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "3.2 Normalization process for alpha diversity: sub-sampling",
    "text": "3.2 Normalization process for alpha diversity: sub-sampling\n\nphyseq_rar <- phyloseq::rarefy_even_depth(physeq, rngseed = TRUE)\n\nCheck the number of sequences for each sample using sample_sums function\nDid you lost a lot of ASVs?"
  },
  {
    "objectID": "practicals/alpha_diversity.html#run-rarefaction-curves-on-normalized-data",
    "href": "practicals/alpha_diversity.html#run-rarefaction-curves-on-normalized-data",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "3.3 Run rarefaction curves on normalized data",
    "text": "3.3 Run rarefaction curves on normalized data\n\np0 <- ggrare(physeq_rar, step = 10, color = \"Description\", se = TRUE)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#group-separation",
    "href": "practicals/alpha_diversity.html#group-separation",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "3.4 Group separation",
    "text": "3.4 Group separation\n\np0 + facet_wrap(~Geo, ncol = 2)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#indices",
    "href": "practicals/alpha_diversity.html#indices",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "4.1 Indices",
    "text": "4.1 Indices\n\n4.1.1 Get taxonomy-based diversity indices\n\n#Get indices with alpha function (NB: index=\"all\" if you want all the indices)\nalpha_indices <- microbiome::alpha(\n  physeq_rar,\n  index = c(\"observed\", \"diversity_gini_simpson\",\n          \"diversity_shannon\", \"evenness_pielou\",\n          \"dominance_relative\")\n)\n\n#save\nwrite.table(alpha_indices,\n            file = file.path(output_alpha, \"indices_alpha_resultat.txt\"),\n            sep = \"\\t\")\n\n#which type?\nclass(alpha_indices)\n\n[1] \"data.frame\"\n\n\n\n#see\nalpha_indices\n\n     observed diversity_gini_simpson diversity_shannon evenness_pielou\nS11B       36              0.9447863          3.146480       0.8780420\nS1B        35              0.9477924          3.177766       0.8937989\nS2B        43              0.9577758          3.408022       0.9060997\nS2S        36              0.9414576          3.112066       0.8684385\nS3B        41              0.9503989          3.275906       0.8821441\nS3S        38              0.9491313          3.246802       0.8925706\nS4B        40              0.9570249          3.350694       0.9083230\nS4S        40              0.9363446          3.097474       0.8396788\nS5B        32              0.9271578          2.978541       0.8594252\nS5S        33              0.9253250          2.993341       0.8560944\nS6B        41              0.9439556          3.213508       0.8653415\nS6S        28              0.8247810          2.440971       0.7325395\nS7B        36              0.9435901          3.157702       0.8811735\nS7S        44              0.9488744          3.278296       0.8663140\nS8B        33              0.9452117          3.108474       0.8890226\nS8S        39              0.9517578          3.307644       0.9028494\nS9B        36              0.9443038          3.105908       0.8667202\nS9S        33              0.9487545          3.180393       0.9095912\n     dominance_relative\nS11B         0.10274791\nS1B          0.10274791\nS2B          0.09677419\nS2S          0.10991637\nS3B          0.10991637\nS3S          0.10991637\nS4B          0.08721625\nS4S          0.14336918\nS5B          0.16606930\nS5S          0.18876941\nS6B          0.13620072\nS6S          0.38351254\nS7B          0.13022700\nS7S          0.10633214\nS8B          0.09438471\nS8S          0.09677419\nS9B          0.09438471\nS9S          0.10394265\n\n\nWhat can you say about S6S?\n\n\n4.1.2 Add the alpha indices result to your metadata (sample_data) phyloseq object\nImportant because many times you will probably want to add new variables in the phyloseq class object!!!\n\n#Turn into sample_data object : sample_data function\nalpha_indices <- phyloseq::sample_data(alpha_indices)\n#See\nclass(alpha_indices)\n\n[1] \"sample_data\"\nattr(,\"package\")\n[1] \"phyloseq\"\n\n\n\n#Add alpha_indices to phyloseq sample_data object: merge_phyloseq function!\nphyseq_rar <- phyloseq::merge_phyloseq(physeq_rar, alpha_indices)\n#See the result\nsample_data(physeq_rar)\n\n\n\n4.1.3 Get phylogeny based diversity indices: get_NRI_NTI function\n\n#CalculateNRI,NTI,PD...: get_NRI_NTI function\nind_comp <- MicrobiotaProcess::get_NRI_NTI(physeq_rar,\n                                           abundance.weighted = FALSE,\n                                           metric = \"all\",\n                                           seed = 123)\n\n#Retrieve only those of interest :select function, results are in ind_comp@alpha\nindi_comp <- as.data.frame(ind_comp@alpha)\nNRI_NTI_PB <- dplyr::select(indi_comp, NRI:PD)\n#see\nNRI_NTI_PB\n\n             NRI           NTI       PD\nS11B -1.70064052 -1.7348808000 3.532377\nS1B   1.17623968 -0.7634036100 3.315546\nS2B  -0.26125740 -0.6647458642 3.697007\nS2S  -2.45515064 -0.7418024886 3.422223\nS3B   0.62045110 -1.2987453680 3.683481\nS3S  -0.14108530 -0.7345369499 3.440318\nS4B  -0.48556229  0.0045554178 3.317148\nS4S   1.77346210 -0.9136191708 3.436577\nS5B   0.15698400  0.1315279847 2.959208\nS5S  -0.13425169  1.8924504384 2.473861\nS6B   0.21850759  1.0880702249 3.122788\nS6S   2.63122819  0.0003761727 2.422982\nS7B  -1.47035872 -0.6371365496 3.169274\nS7S  -2.51835742  0.7082829258 3.453089\nS8B  -0.09163059  0.7447376259 2.935800\nS8S  -1.20596938  0.4464282161 3.301764\nS9B  -0.07394926  0.3100746390 2.880719\nS9S   0.44303515  2.4561469676 2.437359\n\n\n\n\n4.1.4 Again!!! Add the phylogenetic indices to your metadata (sample_data) phyloseq object\n\n#Turn into sample_data object : sample_data function\nNRI_NTI_PB <- phyloseq::sample_data(NRI_NTI_PB)\n#Add alpha_indices to phyloseq sample_data object: merge_phyloseq function!\nphyseq_rar <- phyloseq::merge_phyloseq(physeq_rar, NRI_NTI_PB)\n#See the result with all the indices included\nsample_data(physeq_rar)\n\n\n\n4.1.5 Importance of metadata table/file\nMetadata groups all the meta information (category/numerical) such as sample names, geographic group, treatment groups (disease/normal), measures of environmental factors, alpha diversity indices etc. This table is central for further analyses and graphic representations You saw how to add alpha indices from calculation with alpha function Now, how to add a customized variable in metadata?\n\n\n4.1.6 Add my own variable to metadata\n\n#create a dataframe with a vector with  values of your new variable\nmydataframe <- data.frame(MYNEWVAR = c(\"sediment\", \"mer\", \"sediment\",\n                                       \"trap\", \"mer\", \"mer\",\n                                       \"trap\", \"trap\", \"trap\",\n                                       \"sediment\", \"mer\", \"mer\",\n                                       \"mer\", \"trap\", \"trap\",\n                                       \"mer\", \"mer\", \"sediment\"))\n\n#Add rownames=samples names\nrow.names(mydataframe) <- c(\"S2S\", \"S1B\", \"S2B\",\n                            \"S3S\", \"S3B\", \"S4S\",\n                            \"S4B\", \"S5S\", \"S5B\",\n                            \"S6S\", \"S6B\", \"S7S\",\n                            \"S7B\", \"S8S\", \"S8B\",\n                            \"S9S\", \"S9B\", \"S11B\")\n\n# See & notice that order of sample names is not the same as in physeq_rar@sam_data\nmydataframe\n\n     MYNEWVAR\nS2S  sediment\nS1B       mer\nS2B  sediment\nS3S      trap\nS3B       mer\nS4S       mer\nS4B      trap\nS5S      trap\nS5B      trap\nS6S  sediment\nS6B       mer\nS7S       mer\nS7B       mer\nS8S      trap\nS8B      trap\nS9S       mer\nS9B       mer\nS11B sediment\n\n\n\nmydataframe <- phyloseq::sample_data(mydataframe)\n# Add your own variable\nphyseq_rar <- phyloseq::merge_phyloseq(physeq_rar, mydataframe)\n# See the result with your MYNEWVAR with ordenring Ok as merge_phyloseq manages it for you\nsample_data(physeq_rar)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#alpha-diversity-representations",
    "href": "practicals/alpha_diversity.html#alpha-diversity-representations",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "4.2 Alpha diversity representations",
    "text": "4.2 Alpha diversity representations\nThis section will show you how to plot by different ways the alpha diversity and its customization. Understand how it works!\n\n4.2.1 Alpha representations using phyloseq::plot_richness()\nYou are limited to the indices calculated by the phyloseq::estimate_richness function (i.e.”Observed”, “Chao1”, “ACE”, “Shannon”, “Simpson”, “InvSimpson”, “Fisher”).\n\n4.2.1.1 Selected indices + SampName\nx allow you to choose the column from sample_data(physeq_rar) for applying the label\n\nphyloseq::plot_richness(physeq_rar, x = \"SampName\",\n                        measures = c(\"Observed\", \"Shannon\", \"Simpson\"))\n\n\n\n\n\n\n4.2.1.2 Color by group: color = Geo & change sample name\nFor color option pass the column of sample_data(physeq_rar) that you want. Here different colors is applied depending on Geo (which is North and South, so 2 different colors)\n\nphyloseq::plot_richness(physeq_rar,\n                        x = \"Description\",\n                        color=\"Geo\",\n                        measures=c(\"Observed\", \"Shannon\", \"Simpson\"))\n\n\n\n\n\n\n4.2.1.3 Make box_plot by adding geom_boxplot function\n\nphyloseq::plot_richness(physeq_rar,\n                        x=\"Geo\",\n                        color=\"Geo\",\n                        measures=c(\"Observed\", \"Shannon\", \"Simpson\")) +\n  ggplot2::geom_boxplot()\n\n\n\n\n\n\n4.2.1.4 Make box_plot : geom_boxplot + fill color of boxplot (fill) + transparency (with alpha)\n\nphyloseq::plot_richness(physeq_rar,\n                        x=\"Geo\",\n                        measures=c(\"Observed\", \"Shannon\", \"Simpson\")) +\n  ggplot2::geom_boxplot(aes(fill = Geo), alpha = 0.4) \n\n\n\n\n\n\n\n4.2.2 Alpha representations using Microbiome::boxplot_alpha\nAgain, you are limited to the indices calculated by the Microbiome::alpha function\n\nmicrobiome::boxplot_alpha(physeq_rar,\n                          index = \"observed\",\n                          violin = TRUE,\n                          x_var = \"Geo\",\n                          fill.colors = c(North=\"#00AFBB\", South=\"#E7B800\"))\n\nWarning: The `.data` argument of `add_column()` must have unique names as of tibble 3.0.0.\nUse `.name_repair = \"minimal\"`.\nThis warning is displayed once every 8 hours.\nCall `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n\n\n\n\n\n\n\n4.2.3 Alpha representations using ggplot2\nInterest: Freedom!! you can use ANY indices that you have calculated from different packages & included in sample_data\n\n#Before : Change your phyloseq class oject sample_data as a dataframe\nmetadata <- data.frame(sample_data(physeq_rar))\n\n\n4.2.3.1 basic: points & color\n\n#You use the columns of the metadata (Geo, observed, groupe etc)\nggplot(metadata, aes(x = Geo, y = observed)) +\n  geom_point(aes(color = groupe, fill = groupe))\n\n\n\n\n\n\n4.2.3.2 Deals with superposed points: geom_dotplot()\n\nggplot(metadata, aes(x = Geo, y = observed)) +\n  geom_dotplot(binaxis = \"y\", stackdir = \"center\", stackgroups = TRUE,\n               binwidth = 0.5, aes(color = groupe, fill = groupe)) +\n  xlab(\"Geographic position\") +\n  ylab(\"Number of Observed ASVs\") \n\n\n\n\n\n\n4.2.3.3 Boxplot & color control : scale_fill & scale_color\n\nggplot(metadata, aes(x = Geo, y = observed)) +\n  geom_boxplot(alpha = 0.7, aes(color = Geo, fill = Geo)) +\n  scale_fill_manual(values = c(\"#00AFBB\", \"#E7B800\"))\n\n\n\n\n\nggplot(metadata, aes(x = Geo, y = observed)) + \n  geom_boxplot(alpha = 0.7, aes(color = Geo, fill = Geo)) +\n  scale_fill_manual(values = c(\"#00AFBB\", \"#E7B800\")) +\n  scale_color_manual(values = c(\"#00AFBB\", \"#E7B800\"))\n\n\n\n\n\n\n4.2.3.4 Boxplot, color control & points: geom_jitter()\n\nggplot(metadata, aes(x = Geo, y = observed)) +\n  geom_boxplot(alpha = 0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color = c(\"#00AFBB\", \"#E7B800\"))+\n  geom_jitter(aes(colour = groupe), position = position_jitter(0.07), cex = 2.2)\n\n\n\n\n\n\n4.2.3.5 Boxplot, color control, points and Mean SD: stat_summary()\n\nggplot(metadata, aes(x = Geo, y = observed)) +\n  geom_boxplot(alpha = 0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color=c(\"#00AFBB\", \"#E7B800\")) +\n  geom_jitter(aes(colour = groupe), position = position_jitter(0.07), cex = 2.2) +\n  stat_summary(fun = mean, geom = \"point\", shape = 17, size = 3, color = \"white\") +\n  stat_summary(fun.data = \"mean_se\", geom = \"errorbar\", width = .1, color = \"white\")\n\n\n\n\n\n\n4.2.3.6 Combine graphs on same figure: patchwork\n\n#Put your  graphs in different variables P1,P2,P3\np1 <- ggplot(metadata, aes(x = Geo, y = observed)) +\n  geom_boxplot(alpha = 0.6,\n               fill = c(\"#00AFBB\",\"#E7B800\"),\n               color=c(\"#00AFBB\",\"#E7B800\")) +\n  geom_jitter(aes(colour = groupe), position = position_jitter(0.07), cex = 2.2) +\n  theme(axis.title.x = element_blank())\n\np2 <- ggplot(metadata, aes(x = Geo, y = evenness_pielou)) +\n  geom_boxplot(alpha = 0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color = c(\"#00AFBB\", \"#E7B800\")) +\n  geom_jitter(aes(colour = groupe), position = position_jitter(0.07), cex = 2.2) +\n  theme(axis.title.x = element_blank())\n\np3 <- ggplot(metadata, aes(x = Geo, y = diversity_gini_simpson)) +\n  geom_boxplot(alpha = 0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color = c(\"#00AFBB\", \"#E7B800\")) +\n  geom_jitter(aes(colour = groupe), position = position_jitter(0.07), cex = 2.2) +\n  theme(axis.title.x = element_blank())\n\n\n#Put the grpah of p1, p2 and p3 on same Figure\np1 + p2 + p3 + \n  patchwork::plot_annotation(tag_levels = \"A\") +\n  patchwork::plot_layout(guides = \"collect\")\n\n\n\n# ggpubr::ggarrange(p1, p2, p3, ncol = 3, nrow = 1,common.legend = TRUE, legend = \"right\",labels=c(\"A\",\"B\",\"C\"))"
  },
  {
    "objectID": "practicals/alpha_diversity.html#univariate-statistics-for-alpha-diversity",
    "href": "practicals/alpha_diversity.html#univariate-statistics-for-alpha-diversity",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "4.3 Univariate Statistics for alpha diversity",
    "text": "4.3 Univariate Statistics for alpha diversity\n\n4.3.1 Normality test: Check the Normal or not normal distribution of your data to choose the right test!\n\n4.3.1.1 Shapiro test: H0 Null Hypothesis: follows Normal distribution!\nMeans if p<0.05 -> reject the H0 (so does not follow a normal distribution)\n\n\n4.3.1.2 Q-Qplots: Compare your distribution with a theoretical normal distribution\nIf your data follow a normal distribution, you’re expecting a linear relationship theoritical vs. experimental\nOur custom function indices_normality() (defined in R/alpha_diversity.R) plots the results of Shapiro test as well as Q-Qplots.\n\n\n\n4.3.2 Select indices to test & run normality check\n\nmetadata |>\n  dplyr::select(observed,\n                diversity_gini_simpson,\n                diversity_shannon,\n                evenness_pielou,\n                PD) |>\n  indices_normality(nrow = 3, ncol = 2)\n\n\n\n\nWhat are your conclusions?\n\n\n4.3.3 ANOVA: parametric (follows normal distribution) AND at least 3 groups\n\n4.3.3.1 Anova for Observed ASV and 4 groups\n\n# How many groups used? See the column \"groupe\" of metadata:\nfactor(metadata$groupe)\n\n [1] SGF NBF NBF NBS NBF NBS NBF NBS NBF NBS SGF SGS SGF SGS SGF SGS SGF SGS\nLevels: NBF NBS SGF SGS\n\n\n\n# Check homogeneity of variance between groups\n# (avoid bias in ANOVA result & keep the power of the test)\n# H0= equality of variances in the different populations\nstats::bartlett.test(observed ~ groupe, metadata)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  observed by groupe\nBartlett's K-squared = 3.1798, df = 3, p-value = 0.3647\n\n\nConclusion?\n\n\n\n4.3.4 Alternative to Bartlett : Levene test (package car), less sensitive to normality deviation\nGlobal Test: Anova tell you if that some of the group means are different, but you don’t know which pairs of groups are different!\n\naov_observed <- stats::aov(observed ~ groupe, metadata)\nsummary(aov_observed)\n\n            Df Sum Sq Mean Sq F value Pr(>F)\ngroupe       3  13.03   4.343   0.211  0.887\nResiduals   14 288.75  20.625               \n\n\nWhich pairs of groups are different? -> Post-hoc test: Tukey multiple pairwise-comparisons\n\nsignif_pairgroups <- stats::TukeyHSD(aov_observed, method = \"bh\")\nsignif_pairgroups\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: stats::aov(formula = observed ~ groupe, data = metadata)\n\n$groupe\n         diff        lwr      upr     p adj\nNBS-NBF -1.45 -10.304898 7.404898 0.9631679\nSGF-NBF -1.80 -10.148478 6.548478 0.9217657\nSGS-NBF -2.20 -11.054898 6.654898 0.8866424\nSGF-NBS -0.35  -9.204898 8.504898 0.9994302\nSGS-NBS -0.75 -10.083882 8.583882 0.9953019\nSGS-SGF -0.40  -9.254898 8.454898 0.9991510\n\n\n\n\n4.3.5 Kruskal-Wallis: non-parametric & at least three groups\n\n4.3.5.1 Kruskal for diversity_shannon and 4 groups\nGlobal test\n\nstats::kruskal.test(diversity_shannon ~ groupe, data = metadata)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  diversity_shannon by groupe\nKruskal-Wallis chi-squared = 2.9544, df = 3, p-value = 0.3987\n\n\nPost hoc test: Dunn test (pairwise group test)\n\nsignifgroup <- FSA::dunnTest(diversity_shannon ~ groupe,\n                           data = metadata,\n                           method = \"bh\")\n\nWarning: groupe was coerced to a factor.\n\n#See\nsignifgroup\n\n  Comparison          Z   P.unadj     P.adj\n1  NBF - NBS  1.5218359 0.1280502 0.7683013\n2  NBF - SGF  1.2439326 0.2135244 0.6405731\n3  NBS - SGF -0.3490449 0.7270556 0.7270556\n4  NBF - SGS  0.4048921 0.6855568 0.8226682\n5  NBS - SGS -1.0596259 0.2893148 0.5786297\n6  SGF - SGS -0.7678988 0.4425473 0.6638209\n\n\n\n\n\n4.3.6 T-test: parametric, 2 groups (i.e North Vs. Sud)\n\nstats::bartlett.test(observed ~ Geo, metadata)\n\n\n    Bartlett test of homogeneity of variances\n\ndata:  observed by Geo\nBartlett's K-squared = 0.38191, df = 1, p-value = 0.5366\n\n\n\nobserved_ttest <- stats::t.test(observed ~ Geo, data = metadata)\n#see\nobserved_ttest\n\n\n    Welch Two Sample t-test\n\ndata:  observed by Geo\nt = 0.66008, df = 15.246, p-value = 0.5191\nalternative hypothesis: true difference in means between group North and group South is not equal to 0\n95 percent confidence interval:\n -2.966072  5.632739\nsample estimates:\nmean in group North mean in group South \n           37.55556            36.22222 \n\n\n\n\n4.3.7 Wilcoxon rank sum: non-parametric & 2 Groups\n\npairwise_test <- ggpubr::compare_means(diversity_shannon ~ Geo,\n                                       metadata,\n                                       method = \"wilcox.test\")\n#See\npairwise_test\n\n# A tibble: 1 × 8\n  .y.               group1 group2     p p.adj p.format p.signif method  \n  <chr>             <chr>  <chr>  <dbl> <dbl> <chr>    <chr>    <chr>   \n1 diversity_shannon South  North  0.863  0.86 0.86     ns       Wilcoxon\n\n\n\n\n4.3.8 Boxplot representation with p-value information\n\n#Boxplot as previously seen\ngraph_shan <- ggplot(metadata, aes(x = Geo, y = diversity_shannon)) + \n  geom_boxplot(alpha=0.6,\n               fill = c(\"#00AFBB\", \"#E7B800\"),\n               color = c(\"#00AFBB\", \"#E7B800\")) +\n  geom_jitter(aes(colour = groupe),\n              position = position_jitter(0.02) ,\n              cex=2.2)+\n  stat_summary(fun = mean, geom = \"point\",\n               shape = 17, size = 3,\n               color = \"white\")\n\n#Add p-value on graph\ngraph_shan + ggpubr::stat_pvalue_manual(\n  pairwise_test,\n  y.position = 3.5,\n  label = \"p.adj = {p.adj}\",\n  color = \"blue\",\n  linetype = 1,\n  tip.length = 0.01\n)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#correlation-analysis",
    "href": "practicals/alpha_diversity.html#correlation-analysis",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "5.1 Correlation analysis",
    "text": "5.1 Correlation analysis\nMethods available are spearman, kendall and pearson. Correlation coefficient r is independent of change of origin and scale (So no data transformation!!). Correlation analysis describes the nature (strength (0->1) and direction +/-) of the relationship between two variables (r), whatever the range and the measurement units of them.\nConsiderations for statistical tests (test of the value being zero): * Pearson’s test is parametric (normal distribution required) * Spearman’s and Kendall’s tests are non-parametric\n\n5.1.1 Select variables\n\n#Select variables for bivariate correlation\nmyvariables <- dplyr::select(metadata, SiOH4:PO4, observed,\n                             diversity_shannon, PD)\n#see\nmyvariables\n\n     SiOH4   NO2   NO3   NH4   PO4 observed diversity_shannon       PD\nS11B 3.324 0.083 0.756 0.467 0.115       36          3.146480 3.532377\nS1B  1.813 0.256 0.889 0.324 0.132       35          3.177766 3.315546\nS2B  2.592 0.105 1.125 0.328 0.067       43          3.408022 3.697007\nS2S  3.381 0.231 0.706 0.450 0.109       36          3.112066 3.422223\nS3B  1.438 0.057 1.159 0.369 0.174       41          3.275906 3.683481\nS3S  1.656 0.098 0.794 0.367 0.095       38          3.246802 3.440318\nS4B  2.457 0.099 1.087 0.349 0.137       40          3.350694 3.317148\nS4S  2.457 0.099 1.087 0.349 0.137       40          3.097474 3.436577\nS5B  2.028 0.103 1.135 0.216 0.128       32          2.978541 2.959208\nS5S  2.669 0.136 0.785 0.267 0.114       33          2.993341 2.473861\nS6B  2.206 0.249 0.768 0.629 0.236       41          3.213508 3.122788\nS6S  3.004 0.251 0.927 0.653 0.266       28          2.440971 2.422982\nS7B  3.016 0.157 0.895 0.491 0.176       36          3.157702 3.169274\nS7S  1.198 0.165 1.099 0.432 0.180       44          3.278296 3.453089\nS8B  3.868 0.253 0.567 0.533 0.169       33          3.108474 2.935800\nS8S  3.639 0.255 0.658 0.665 0.247       39          3.307644 3.301764\nS9B  3.910 0.107 0.672 0.490 0.134       36          3.105908 2.880719\nS9S  3.607 0.139 0.644 0.373 0.167       33          3.180393 2.437359\n\n\n\n\n5.1.2 Apply the method\n\n#Apply method pearson\nmatrixCor <- stats::cor(myvariables, method = \"pearson\")\n#see\nmatrixCor\n\n                       SiOH4        NO2         NO3         NH4        PO4\nSiOH4              1.0000000  0.2680225 -0.72770308  0.44354653  0.1194938\nNO2                0.2680225  1.0000000 -0.48440242  0.62864562  0.5775735\nNO3               -0.7277031 -0.4844024  1.00000000 -0.49147592 -0.1691272\nNH4                0.4435465  0.6286456 -0.49147592  1.00000000  0.7744357\nPO4                0.1194938  0.5775735 -0.16912716  0.77443570  1.0000000\nobserved          -0.4539279 -0.2844272  0.40577219 -0.06052592 -0.1598867\ndiversity_shannon -0.2072882 -0.2931624  0.09476396 -0.24014733 -0.3779158\nPD                -0.4216740 -0.2872557  0.41958058 -0.13328333 -0.3522890\n                     observed diversity_shannon         PD\nSiOH4             -0.45392787       -0.20728823 -0.4216740\nNO2               -0.28442718       -0.29316236 -0.2872557\nNO3                0.40577219        0.09476396  0.4195806\nNH4               -0.06052592       -0.24014733 -0.1332833\nPO4               -0.15988665       -0.37791579 -0.3522890\nobserved           1.00000000        0.80004197  0.7792103\ndiversity_shannon  0.80004197        1.00000000  0.6703605\nPD                 0.77921035        0.67036049  1.0000000\n\n# we use a function defined in R/utils.R\n# to move the row names content to a new column\n\ndf_export(matrixCor, new_rn = \"variable\")\n\n           variable      SiOH4        NO2         NO3         NH4        PO4\n1             SiOH4  1.0000000  0.2680225 -0.72770308  0.44354653  0.1194938\n2               NO2  0.2680225  1.0000000 -0.48440242  0.62864562  0.5775735\n3               NO3 -0.7277031 -0.4844024  1.00000000 -0.49147592 -0.1691272\n4               NH4  0.4435465  0.6286456 -0.49147592  1.00000000  0.7744357\n5               PO4  0.1194938  0.5775735 -0.16912716  0.77443570  1.0000000\n6          observed -0.4539279 -0.2844272  0.40577219 -0.06052592 -0.1598867\n7 diversity_shannon -0.2072882 -0.2931624  0.09476396 -0.24014733 -0.3779158\n8                PD -0.4216740 -0.2872557  0.41958058 -0.13328333 -0.3522890\n     observed diversity_shannon         PD\n1 -0.45392787       -0.20728823 -0.4216740\n2 -0.28442718       -0.29316236 -0.2872557\n3  0.40577219        0.09476396  0.4195806\n4 -0.06052592       -0.24014733 -0.1332833\n5 -0.15988665       -0.37791579 -0.3522890\n6  1.00000000        0.80004197  0.7792103\n7  0.80004197        1.00000000  0.6703605\n8  0.77921035        0.67036049  1.0000000\n\n# we can now export\n\nwrite.table(df_export(matrixCor, new_rn = \"variable\"),\n            file.path(output_alpha, \"correlation_matrix.tsv\"),\n            row.names = FALSE,\n            sep = \"\\t\",\n            quote = FALSE)\n\n\n\n5.1.3 Plot results: corrplot function\n\ncorrplot::corrplot(\n  matrixCor,\n  method=\"circle\",\n  type=\"lower\",\n  order='hclust',\n  tl.col = \"black\",\n  tl.srt = 45,\n  tl.cex=0.9,\n  diag = FALSE\n)\n\n\n\n\n\n\n5.1.4 Is the correlation is due to chance? Significance test!\nThe idea: Test the correlation at the population scale (=Rho) and compare to r (your samples). HO is : there is not a significant linear correlation between x and y in the population. For instance t-test allows to use sample data to generalize an assumption to an entire population.\n\n#Test stats\nptest <- corrplot::cor.mtest(matrixCor, conf.level = .95)\n#The p-value are stored in ptest$p\n#see\nptest$p \n\n                         SiOH4         NO2          NO3         NH4         PO4\nSiOH4             0.0000000000 0.049489497 0.0002332876 0.027766508 0.163621297\nNO2               0.0494894971 0.000000000 0.0131598941 0.001291248 0.004356718\nNO3               0.0002332876 0.013159894 0.0000000000 0.009159687 0.106919410\nNH4               0.0277665081 0.001291248 0.0091596871 0.000000000 0.001585739\nPO4               0.1636212970 0.004356718 0.1069194104 0.001585739 0.000000000\nobserved          0.0127916768 0.014498926 0.0315030294 0.030686706 0.031731622\ndiversity_shannon 0.1017556942 0.021558528 0.1531313980 0.032086176 0.007967349\nPD                0.0156006175 0.010570716 0.0277011182 0.018036573 0.011994662\n                      observed diversity_shannon           PD\nSiOH4             1.279168e-02      0.1017556942 1.560062e-02\nNO2               1.449893e-02      0.0215585277 1.057072e-02\nNO3               3.150303e-02      0.1531313980 2.770112e-02\nNH4               3.068671e-02      0.0320861758 1.803657e-02\nPO4               3.173162e-02      0.0079673485 1.199466e-02\nobserved          0.000000e+00      0.0006687658 7.658065e-05\ndiversity_shannon 6.687658e-04      0.0000000000 1.385245e-03\nPD                7.658065e-05      0.0013852451 0.000000e+00\n\n\n\n\n5.1.5 Show only correlations with significant p-values\n\ncorrplot::corrplot(\n  matrixCor,\n  p.mat = ptest$p,\n  sig.level = .05,\n  method = \"circle\",\n  type = \"lower\",\n  order = 'hclust',\n  tl.col = \"black\",\n  tl.srt = 45,\n  tl.cex = 0.7,\n  diag = FALSE\n)\n\n\n\n\n\n\n5.1.6 Linear regression\nDetermination coefficient R2 provides percentage variation in y which is explained by all the x together. Its value is (usually) between 0 and 1 and it indicates strength of Linear Regression model. Higher the R2 value, data points are less scattered so it is a good model. Lesser the R2 value is more scattered the data points.\n\n5.1.6.1 Shannon ~ Observed\n\nggplot(metadata, aes(x = observed, y = diversity_shannon)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\") +\n  ggpmisc::stat_poly_eq(aes(label = paste(after_stat(rr.label),\n                                          after_stat(p.value.label),\n                                          sep = \"*\\\", \\\"*\")))\n\n\n\n\n\n\n5.1.6.2 PD ~ Observed\n\nggplot2::ggplot(metadata, aes(x = observed, y = PD)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", col = \"red\") +\n  ggpmisc::stat_poly_eq(aes(label = paste(after_stat(rr.label),\n                                          after_stat(p.value.label),\n                                          sep = \"*\\\", \\\"*\")))\n\n\n\n\nUsing these two examples, what should be your conclusions…be careful…\nWhat are √R2 of these exemple? See matrixCor. Do you see the relation beetween R2 and r?"
  },
  {
    "objectID": "practicals/alpha_diversity.html#abundance-transformation",
    "href": "practicals/alpha_diversity.html#abundance-transformation",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "6.1 Abundance Transformation",
    "text": "6.1 Abundance Transformation\n\n6.1.1 Counts in percentage using phyloseq::transform_sample_counts()\n\npourcentS <- phyloseq::transform_sample_counts(physeq_rar, function(x) x/sum(x) * 100)\n\nSee plot:\n\nphyloseq::plot_bar(pourcentS)\n\n\n\n\nWhat are the separation lines?\n\n\n6.1.2 Summarise at a given taxonomic level with phyloseq::tax_glom()\nRemember ranks can be obtained with phyloseq::rank_names()\n\nphyloseq::rank_names(pourcentS)\n\n[1] \"Kingdom\" \"Phylum\"  \"Class\"   \"Order\"   \"Family\"  \"Genus\"   \"Species\"\n\n\n\nPhylum_glom <- phyloseq::tax_glom(pourcentS,\n                                  taxrank = \"Phylum\",\n                                  NArm = FALSE)\n\n#Plot at Phylum taxonomic rank, with color\nphyloseq::plot_bar(Phylum_glom, fill = \"Phylum\") \n\n\n\n\nNArm?\n\n\n6.1.3 Filter phylum (mean of the line): phyloseq::filter_taxa()\nLet’s filter out the phylums with a mean relative abundance inferior to 1%\n\nPhylum_1 <- phyloseq::filter_taxa(Phylum_glom,\n                                  flist = function(x) mean(x) >= 1,\n                                  prune = TRUE)\n\n#Plot at Phylum taxonomic rank, with color\nphyloseq::plot_bar(Phylum_1, fill = \"Phylum\") \n\n\n\n\n\n\n6.1.4 How to save a table into a file: exemple of phylum taxonomic table\n\nwrite.table(df_export(otu_table(Phylum_glom)),\n            row.names = FALSE,\n            file = file.path(output_alpha, \"Phylum_pourcent.tsv\"),\n            sep = \"\\t\")\n\n\n\n6.1.5 Remove black lines\n\nphyloseq::plot_bar(Phylum_glom, \"Description\", fill = \"Phylum\") +\n  geom_bar(aes(colour = Phylum), stat = \"identity\")\n\n\n\n\n\n6.1.5.1 Microbiome package\n\n6.1.5.1.1 microbiome::aggregate_taxa()\n\n# Order Rank\nOrder_microb <- microbiome::aggregate_taxa(pourcentS, \"Order\")\n\n#Filter at 1%\nOrder1 <- phyloseq::filter_taxa(Order_microb, function(x) mean(x) >= 1, prune = TRUE) \n\n\n\n6.1.5.1.2 microbiome::plot_composition()\n\np_order <- microbiome::plot_composition(Order1,\n                                        otu.sort = \"abundance\",\n                                        sample.sort = \"Description\",\n                                        x.label = \"Description\",\n                                        plot.type = \"barplot\",\n                                        verbose = FALSE) +\n  ggplot2::labs(x = \"\", y = \"Relative abundance (%)\")\n#see\np_order\n\n\n\n\n\n#Average by group :average_by option\np_order_groupe <- microbiome::plot_composition(Order1,\n                                               otu.sort = \"abundance\",\n                                               sample.sort = \"Description\",\n                                               x.label = \"Description\",\n                                               plot.type = \"barplot\",\n                                               verbose = FALSE,\n                                               average_by = \"Geo\") +\n  ggplot2::labs(x = \"\", y = \"Relative abundance (%)\")\n\n#see\np_order_groupe\n\n\n\n\n\n\n\n6.1.5.2 Interactive barplot with plotly::ggplotly()\n\nplotly::ggplotly(p_order)"
  },
  {
    "objectID": "practicals/alpha_diversity.html#how-to-manage-colors-in-barplots",
    "href": "practicals/alpha_diversity.html#how-to-manage-colors-in-barplots",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "6.2 How to manage colors in barplots",
    "text": "6.2 How to manage colors in barplots\nWith the number of Phyla, Order etc a barplot can become very confusing… Need to have distinct color for each taxonomic groups.\nUse the library RColorBrewer et scale_fill_manual() See here to understand the possibilities\nYou can visualise RColorBrewer’s palettes with the following command:\n\nRColorBrewer::display.brewer.all()\n\n\n\n\n\n6.2.1 Build your own palette\nLet’s assemble from two RColorBrewer’s palettes a single 13 colors palette\n\n#See Set2 colors\n(col1 <- RColorBrewer::brewer.pal(name = \"Set2\", n = 8))\n\n[1] \"#66C2A5\" \"#FC8D62\" \"#8DA0CB\" \"#E78AC3\" \"#A6D854\" \"#FFD92F\" \"#E5C494\"\n[8] \"#B3B3B3\"\n\n#See  Paired colors \n(col2 <- RColorBrewer::brewer.pal(name = \"Paired\", n = 5))\n\n[1] \"#A6CEE3\" \"#1F78B4\" \"#B2DF8A\" \"#33A02C\" \"#FB9A99\"\n\n#Build your set of colors using brewer.pal or your own colors\nmycolors <- c(col1, col2)\n\n\n\n6.2.2 Use your palette in the p_order barplot\n\n#Use scale_fill_manual\np_order +\n  ggplot2::scale_fill_manual(\"Order\", values = mycolors) +\n  theme(legend.position = \"right\",\n        legend.text = element_text(size=8))"
  },
  {
    "objectID": "practicals/alpha_diversity.html#other-data-manipulation-select-specific-taxa-merge-samples",
    "href": "practicals/alpha_diversity.html#other-data-manipulation-select-specific-taxa-merge-samples",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "6.3 Other data Manipulation : select specific taxa, merge samples",
    "text": "6.3 Other data Manipulation : select specific taxa, merge samples\n\n6.3.1 Select Actinobacteria AND Bacteroidetes: phyloseq::subset_taxa()\n\nmyselection1 <- phyloseq::subset_taxa(Phylum_glom, Phylum == \"Actinobacteriota\" | Phylum == \"Bacteroidota\")\n\nphyloseq::plot_bar(myselection1, x = \"Description\", fill = \"Phylum\")\n\n\n\n\n\nphyloseq::plot_bar(myselection1, x = \"Description\",\n                   fill=\"Phylum\", facet_grid = ~Phylum) \n\n\n\n\n\n\n6.3.2 Keep all with the exception of a class, a genus etc (e.g. contamination)\n\nmyselection2 <- phyloseq::subset_taxa(physeq, Class != \"Thermoplasmata\" | is.na(Class))\n\n\n\n6.3.3 Understand:\n! = means IS NOT\n| = AND\nIs.na  = do not remove the NA (Not Assigned at the Class rank), by default it will be removed. be careful!\n\n\n6.3.4 Merge samples (groups, duplicates etc)\nUse a column from metadata to group/merge samples (North & South)\n\n(NordSud <- phyloseq::merge_samples(physeq_rar, \"Geo\"))\n\nWarning in asMethod(object): NAs introduits lors de la conversion automatique\n\nWarning in asMethod(object): NAs introduits lors de la conversion automatique\n\nWarning in asMethod(object): NAs introduits lors de la conversion automatique\n\nWarning in asMethod(object): NAs introduits lors de la conversion automatique\n\nWarning in asMethod(object): NAs introduits lors de la conversion automatique\n\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 209 taxa and 2 samples ]\nsample_data() Sample Data:       [ 2 samples by 30 sample variables ]\ntax_table()   Taxonomy Table:    [ 209 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 209 tips and 208 internal nodes ]\n\n\n\n\n6.3.5 Sample selection: phyloseq::subset_samples()\n\n(sub_North <- phyloseq::subset_samples(pourcentS, Geo == \"North\"))\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 209 taxa and 9 samples ]\nsample_data() Sample Data:       [ 9 samples by 30 sample variables ]\ntax_table()   Taxonomy Table:    [ 209 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 209 tips and 208 internal nodes ]\nrefseq()      DNAStringSet:      [ 209 reference sequences ]\n\n\n\n\n6.3.6 Alternative way: phyloseq::prune_samples\nDefine what you want to keep\n\nkeep <- c(\"S1B\", \"S2S\")\n\nThen extract these samples from pourcentS phyloseq object\n\nkeep2samples <- phyloseq::prune_samples(keep, pourcentS)\nsample_names(keep2samples)\n\n[1] \"S1B\" \"S2S\""
  },
  {
    "objectID": "practicals/alpha_diversity.html#retrieve-fasta-sequences-from-a-phyloseq-object",
    "href": "practicals/alpha_diversity.html#retrieve-fasta-sequences-from-a-phyloseq-object",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "6.4 Retrieve fasta sequences from a phyloseq object",
    "text": "6.4 Retrieve fasta sequences from a phyloseq object\n\n6.4.1 Create a fasta file from your sequences\nOne sequence:\n\nBiostrings::writeXStringSet(physeq_rar@refseq[\"ASV1\"],\n                            filepath = file.path(output_alpha,\"ASV1.fasta\"),\n                            format = \"fasta\")\n\n\n\n6.4.2 Retrieve a subset of sequences\n\n6.4.2.1 By name\n\nlistASV <- c(\"ASV2\", \"ASV8\", \"ASV32\", \"ASV58\")\n\n\nBiostrings::writeXStringSet(physeq_rar@refseq[listASV],\n                            filepath = file.path(output_alpha,\"several_asvs.fasta\"),\n                            format = \"fasta\")\n\n\n\n6.4.2.2 From a selection\nLet’s export a fasta files of all ASVs with a maximum relative abundance superior to 10% in North samples:\n\nphyloseq::subset_samples(pourcentS, Geo == \"North\") |>\n  phyloseq::filter_taxa(flist = function(x) max(x) >= 10, prune = TRUE) |>\n  phyloseq::refseq() |>\n  Biostrings::writeXStringSet(\n    filepath = file.path(output_alpha, \"fancy_selection_asvs.fasta\"),\n    format = \"fasta\"\n  )\n\n\n\n6.4.2.3 Retrieve all sequences\n\nBiostrings::writeXStringSet(physeq_rar@refseq,\n                            filepath = file.path(output_alpha,\"all_asvs.fasta\"),\n                            format = \"fasta\")"
  },
  {
    "objectID": "practicals/alpha_diversity.html#identify-the-taxa-names-of-the-core-microbiota",
    "href": "practicals/alpha_diversity.html#identify-the-taxa-names-of-the-core-microbiota",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "7.1 Identify the taxa names of the core microbiota",
    "text": "7.1 Identify the taxa names of the core microbiota\n\n7.1.1 Which core? Compare North & South core microbiota\n\n#Create 2 phyloseq objects for North and South sample groups\nsub_North <- phyloseq::subset_samples(pourcentS, Geo == \"North\")\nsub_South <- phyloseq::subset_samples(pourcentS, Geo == \"South\")\n\n\n#Check groups ok\nsub_South@sam_data\n\n     SampName   Geo Description groupe Pres PicoEuk Synec Prochloro NanoEuk\nS11B     S11B South     South5B    SGF   35    5370 46830       580    6010\nS6B       S6B South     South1B    SGF   13    2520 39050       705    3630\nS6S       S6S South     South1S    SGS    0    2435 35890       915    3735\nS7B       S7B South     South2B    SGF   26       0     0         0    4005\nS7S       S7S South     South2S    SGS    0    4535 26545      1340    6585\nS8B       S8B South     South3B    SGF   33       0     0         0    5910\nS8S       S8S South     South3S    SGS    0    4260 36745       985    5470\nS9B       S9B South     South4B    SGF   25    4000 31730       485    4395\nS9S       S9S South     South4S    SGS    0    5465 32860       820    5045\n     Crypto SiOH4   NO2   NO3   NH4   PO4    NT    PT   Chla       T       S\nS11B   1690 3.324 0.083 0.756 0.467 0.115 9.539 4.138 0.0182 23.0308 38.9967\nS6B    1295 2.206 0.249 0.768 0.629 0.236 9.013 3.455 0.0000 22.0197 39.0877\nS6S    1300 3.004 0.251 0.927 0.653 0.266 8.776 3.230 0.0134 22.0515 39.0884\nS7B    1600 3.016 0.157 0.895 0.491 0.176 8.968 4.116 0.0000 23.6669 38.9699\nS7S    1355 1.198 0.165 1.099 0.432 0.180 8.256 3.182 0.0000 23.6814 38.9708\nS8B    1590 3.868 0.253 0.567 0.533 0.169 8.395 3.126 0.0000 23.1236 39.0054\nS8S    2265 3.639 0.255 0.658 0.665 0.247 8.991 3.843 0.0132 23.3147 38.9885\nS9B    1180 3.910 0.107 0.672 0.490 0.134 8.954 4.042 0.0172 22.6306 38.9094\nS9S    1545 3.607 0.139 0.644 0.373 0.167 9.817 3.689 0.0062 22.9545 38.7777\n     Sigma_t observed diversity_gini_simpson diversity_shannon evenness_pielou\nS11B 26.9631       36              0.9447863          3.146480       0.8780420\nS6B  27.3241       41              0.9439556          3.213508       0.8653415\nS6S  27.3151       28              0.8247810          2.440971       0.7325395\nS7B  26.7536       36              0.9435901          3.157702       0.8811735\nS7S  26.7488       44              0.9488744          3.278296       0.8663140\nS8B  26.9423       33              0.9452117          3.108474       0.8890226\nS8S  26.8713       39              0.9517578          3.307644       0.9028494\nS9B  27.0131       36              0.9443038          3.105908       0.8667202\nS9S  26.8172       33              0.9487545          3.180393       0.9095912\n     dominance_relative         NRI           NTI       PD MYNEWVAR\nS11B         0.10274791 -1.70064052 -1.7348808000 3.532377 sediment\nS6B          0.13620072  0.21850759  1.0880702249 3.122788      mer\nS6S          0.38351254  2.63122819  0.0003761727 2.422982 sediment\nS7B          0.13022700 -1.47035872 -0.6371365496 3.169274      mer\nS7S          0.10633214 -2.51835742  0.7082829258 3.453089      mer\nS8B          0.09438471 -0.09163059  0.7447376259 2.935800     trap\nS8S          0.09677419 -1.20596938  0.4464282161 3.301764     trap\nS9B          0.09438471 -0.07394926  0.3100746390 2.880719      mer\nS9S          0.10394265  0.44303515  2.4561469676 2.437359      mer\n\nsub_North@sam_data\n\n    SampName   Geo Description groupe Pres PicoEuk Synec Prochloro NanoEuk\nS1B      S1B North     North1B    NBF   52     660 32195     10675     955\nS2B      S2B North     North2B    NBF   59     890 25480     16595     670\nS2S      S2S North     North2S    NBS    0     890 25480     16595     670\nS3B      S3B North     North3B    NBF   74     835 13340     25115    1115\nS3S      S3S North     North3S    NBS    0     715 26725     16860     890\nS4B      S4B North     North4B    NBF   78    2220  3130     29835    2120\nS4S      S4S North     North4S    NBS   78    2220  3130     29835    2120\nS5B      S5B North     North5B    NBF   42    1620 55780     23795    2555\nS5S      S5S North     North5S    NBS    0    1620 56555     22835    2560\n    Crypto SiOH4   NO2   NO3   NH4   PO4    NT    PT   Chla       T       S\nS1B    115 1.813 0.256 0.889 0.324 0.132 9.946 3.565 0.0000 22.7338 37.6204\nS2B    395 2.592 0.105 1.125 0.328 0.067 9.378 3.391 0.0000 22.6824 37.6627\nS2S    395 3.381 0.231 0.706 0.450 0.109 8.817 3.345 0.0000 22.6854 37.6176\nS3B    165 1.438 0.057 1.159 0.369 0.174 8.989 2.568 0.0000 21.5296 37.5549\nS3S    200 1.656 0.098 0.794 0.367 0.095 7.847 2.520 0.0000 22.5610 37.5960\nS4B    235 2.457 0.099 1.087 0.349 0.137 8.689 3.129 0.0000 18.8515 37.4542\nS4S    235 2.457 0.099 1.087 0.349 0.137 8.689 3.129 0.0000 18.8515 37.4542\nS5B   1355 2.028 0.103 1.135 0.216 0.128 8.623 3.137 0.0102 24.1905 38.3192\nS5S    945 2.669 0.136 0.785 0.267 0.114 9.146 3.062 0.0000 24.1789 38.3213\n    Sigma_t observed diversity_gini_simpson diversity_shannon evenness_pielou\nS1B 26.0046       35              0.9477924          3.177766       0.8937989\nS2B 26.0521       43              0.9577758          3.408022       0.9060997\nS2S 26.0137       36              0.9414576          3.112066       0.8684385\nS3B 26.2987       41              0.9503989          3.275906       0.8821441\nS3S 26.0332       38              0.9491313          3.246802       0.8925706\nS4B 26.9415       40              0.9570249          3.350694       0.9083230\nS4S 26.9415       40              0.9363446          3.097474       0.8396788\nS5B 26.1037       32              0.9271578          2.978541       0.8594252\nS5S 26.1065       33              0.9253250          2.993341       0.8560944\n    dominance_relative        NRI          NTI       PD MYNEWVAR\nS1B         0.10274791  1.1762397 -0.763403610 3.315546      mer\nS2B         0.09677419 -0.2612574 -0.664745864 3.697007 sediment\nS2S         0.10991637 -2.4551506 -0.741802489 3.422223 sediment\nS3B         0.10991637  0.6204511 -1.298745368 3.683481      mer\nS3S         0.10991637 -0.1410853 -0.734536950 3.440318     trap\nS4B         0.08721625 -0.4855623  0.004555418 3.317148     trap\nS4S         0.14336918  1.7734621 -0.913619171 3.436577      mer\nS5B         0.16606930  0.1569840  0.131527985 2.959208     trap\nS5S         0.18876941 -0.1342517  1.892450438 2.473861     trap\n\n\n\n\n7.1.2 Change first column name of taxonomy rank\nReplace “Kingdom” by “Domain”, needed for the use of add_best function\n\n#Before\ncolnames(sub_North@tax_table)[1]\n\n[1] \"Kingdom\"\n\n#Apply change for North\ncolnames(sub_North@tax_table)[1] <- \"Domain\"\n#See \ncolnames(sub_North@tax_table)[1]\n\n[1] \"Domain\"\n\n#Apply change for South\ncolnames(sub_South@tax_table)[1] <- \"Domain\"\n\n\n\n7.1.3 Add the lowest taxonomy classification\nhttps://rdrr.io/github/microbiome/microbiome/man/add_besthit.html\n\nsub_North <- microbiome::add_besthit(sub_North, sep = \":\")\nsub_South <- microbiome::add_besthit(sub_South, sep = \":\")\n\n\n\n7.1.4 See the transformation of tax_table\n\nhead(sub_North@tax_table)\n\nTaxonomy Table:     [6 taxa by 7 taxonomic ranks]:\n                          Domain     Phylum             Class                \nASV1:Synechococcus CC9902 \"Bacteria\" \"Cyanobacteria\"    \"Cyanobacteriia\"     \nASV2:Pseudoalteromonas    \"Bacteria\" \"Proteobacteria\"   \"Gammaproteobacteria\"\nASV3:Clade Ia             \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\"\nASV4:Marine Group II      \"Archaea\"  \"Thermoplasmatota\" \"Thermoplasmata\"     \nASV5:Clade Ia             \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\"\nASV6:Clade II             \"Bacteria\" \"Proteobacteria\"   \"Alphaproteobacteria\"\n                          Order              Family                  \nASV1:Synechococcus CC9902 \"Synechococcales\"  \"Cyanobiaceae\"          \nASV2:Pseudoalteromonas    \"Enterobacterales\" \"Pseudoalteromonadaceae\"\nASV3:Clade Ia             \"SAR11 clade\"      \"Clade I\"               \nASV4:Marine Group II      \"Marine Group II\"  NA                      \nASV5:Clade Ia             \"SAR11 clade\"      \"Clade I\"               \nASV6:Clade II             \"SAR11 clade\"      \"Clade II\"              \n                          Genus                  Species\nASV1:Synechococcus CC9902 \"Synechococcus CC9902\" NA     \nASV2:Pseudoalteromonas    \"Pseudoalteromonas\"    NA     \nASV3:Clade Ia             \"Clade Ia\"             NA     \nASV4:Marine Group II      NA                     NA     \nASV5:Clade Ia             \"Clade Ia\"             NA     \nASV6:Clade II             NA                     NA     \n\n\n\n\n7.1.5 Identify Core microbiota\nhttps://rdrr.io/github/microbiome/microbiome/man/core_members.html\n\n#North\n(core_taxa_north <- microbiome::core_members(sub_North,\n                                            detection = 0.0001,\n                                            prevalence = 50/100))\n\n [1] \"ASV1:Synechococcus CC9902\"            \n [2] \"ASV2:Pseudoalteromonas\"               \n [3] \"ASV3:Clade Ia\"                        \n [4] \"ASV4:Marine Group II\"                 \n [5] \"ASV5:Clade Ia\"                        \n [6] \"ASV6:Clade II\"                        \n [7] \"ASV9:Clade Ia\"                        \n [8] \"ASV10:Clade Ia\"                       \n [9] \"ASV11:AEGEAN-169 marine group\"        \n[10] \"ASV12:Prochlorococcus MIT9313.marinus\"\n[11] \"ASV16:AEGEAN-169 marine group\"        \n[12] \"ASV18:Clade Ib\"                       \n[13] \"ASV22:Clade Ia\"                       \n[14] \"ASV23:Clade Ia\"                       \n[15] \"ASV26:Chloroplast\"                    \n[16] \"ASV30:Marine Group II\"                \n[17] \"ASV32:Dadabacteriales\"                \n[18] \"ASV33:SAR324 clade(Marine group B)\"   \n[19] \"ASV35:Clade IV\"                       \n[20] \"ASV37:Marine Group III\"               \n[21] \"ASV49:SAR202 clade\"                   \n[22] \"ASV53:AEGEAN-169 marine group\"        \n\n#South\n(core.taxa.South <- microbiome::core_members(sub_South,\n                                            detection = 0.0001,\n                                            prevalence = 50/100))\n\n [1] \"ASV1:Synechococcus CC9902\"          \"ASV2:Pseudoalteromonas\"            \n [3] \"ASV3:Clade Ia\"                      \"ASV4:Marine Group II\"              \n [5] \"ASV5:Clade Ia\"                      \"ASV6:Clade II\"                     \n [7] \"ASV7:AEGEAN-169 marine group\"       \"ASV8:Pseudoalteromonas\"            \n [9] \"ASV9:Clade Ia\"                      \"ASV13:Alteromonas\"                 \n[11] \"ASV19:AEGEAN-169 marine group\"      \"ASV20:Marine Group II\"             \n[13] \"ASV21:SAR86 clade\"                  \"ASV24:NS4 marine group\"            \n[15] \"ASV26:Chloroplast\"                  \"ASV27:Marine Group II\"             \n[17] \"ASV29:Clade Ib\"                     \"ASV33:SAR324 clade(Marine group B)\"\n[19] \"ASV41:Marine Group II\"              \"ASV43:Marine Group II\"             \n[21] \"ASV51:SAR324 clade(Marine group B)\" \"ASV54:SAR202 clade\"                \n[23] \"ASV62:Pseudoalteromonas\"            \"ASV90:Pseudoalteromonas\"           \n\n\n\n\n7.1.6 Get core microbiota phyloseq object\nGet the phyloseq object with also sequences, phylo tree etc.\n\n(phyloseq_core_north <- microbiome::core(sub_North,\n                                        detection = 0.0001,\n                                        prevalence = .5))\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 22 taxa and 9 samples ]\nsample_data() Sample Data:       [ 9 samples by 30 sample variables ]\ntax_table()   Taxonomy Table:    [ 22 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 22 tips and 21 internal nodes ]\nrefseq()      DNAStringSet:      [ 22 reference sequences ]\n\n\nSee full taxanomy of core members\n\n(tax_mat <- as.data.frame(phyloseq::tax_table(phyloseq_core_north)))\n\n                                        Domain                       Phylum\nASV1:Synechococcus CC9902             Bacteria                Cyanobacteria\nASV2:Pseudoalteromonas                Bacteria               Proteobacteria\nASV3:Clade Ia                         Bacteria               Proteobacteria\nASV4:Marine Group II                   Archaea             Thermoplasmatota\nASV5:Clade Ia                         Bacteria               Proteobacteria\nASV6:Clade II                         Bacteria               Proteobacteria\nASV9:Clade Ia                         Bacteria               Proteobacteria\nASV10:Clade Ia                        Bacteria               Proteobacteria\nASV11:AEGEAN-169 marine group         Bacteria               Proteobacteria\nASV12:Prochlorococcus MIT9313.marinus Bacteria                Cyanobacteria\nASV16:AEGEAN-169 marine group         Bacteria               Proteobacteria\nASV18:Clade Ib                        Bacteria               Proteobacteria\nASV22:Clade Ia                        Bacteria               Proteobacteria\nASV23:Clade Ia                        Bacteria               Proteobacteria\nASV26:Chloroplast                     Bacteria                Cyanobacteria\nASV30:Marine Group II                  Archaea             Thermoplasmatota\nASV32:Dadabacteriales                 Bacteria                 Dadabacteria\nASV33:SAR324 clade(Marine group B)    Bacteria SAR324 clade(Marine group B)\nASV35:Clade IV                        Bacteria               Proteobacteria\nASV37:Marine Group III                 Archaea             Thermoplasmatota\nASV49:SAR202 clade                    Bacteria                  Chloroflexi\nASV53:AEGEAN-169 marine group         Bacteria               Proteobacteria\n                                                    Class            Order\nASV1:Synechococcus CC9902                  Cyanobacteriia  Synechococcales\nASV2:Pseudoalteromonas                Gammaproteobacteria Enterobacterales\nASV3:Clade Ia                         Alphaproteobacteria      SAR11 clade\nASV4:Marine Group II                       Thermoplasmata  Marine Group II\nASV5:Clade Ia                         Alphaproteobacteria      SAR11 clade\nASV6:Clade II                         Alphaproteobacteria      SAR11 clade\nASV9:Clade Ia                         Alphaproteobacteria      SAR11 clade\nASV10:Clade Ia                        Alphaproteobacteria      SAR11 clade\nASV11:AEGEAN-169 marine group         Alphaproteobacteria Rhodospirillales\nASV12:Prochlorococcus MIT9313.marinus      Cyanobacteriia  Synechococcales\nASV16:AEGEAN-169 marine group         Alphaproteobacteria Rhodospirillales\nASV18:Clade Ib                        Alphaproteobacteria      SAR11 clade\nASV22:Clade Ia                        Alphaproteobacteria      SAR11 clade\nASV23:Clade Ia                        Alphaproteobacteria      SAR11 clade\nASV26:Chloroplast                          Cyanobacteriia      Chloroplast\nASV30:Marine Group II                      Thermoplasmata  Marine Group II\nASV32:Dadabacteriales                       Dadabacteriia  Dadabacteriales\nASV33:SAR324 clade(Marine group B)                   <NA>             <NA>\nASV35:Clade IV                        Alphaproteobacteria      SAR11 clade\nASV37:Marine Group III                     Thermoplasmata Marine Group III\nASV49:SAR202 clade                        Dehalococcoidia     SAR202 clade\nASV53:AEGEAN-169 marine group         Alphaproteobacteria Rhodospirillales\n                                                       Family\nASV1:Synechococcus CC9902                        Cyanobiaceae\nASV2:Pseudoalteromonas                 Pseudoalteromonadaceae\nASV3:Clade Ia                                         Clade I\nASV4:Marine Group II                                     <NA>\nASV5:Clade Ia                                         Clade I\nASV6:Clade II                                        Clade II\nASV9:Clade Ia                                         Clade I\nASV10:Clade Ia                                        Clade I\nASV11:AEGEAN-169 marine group         AEGEAN-169 marine group\nASV12:Prochlorococcus MIT9313.marinus            Cyanobiaceae\nASV16:AEGEAN-169 marine group         AEGEAN-169 marine group\nASV18:Clade Ib                                        Clade I\nASV22:Clade Ia                                        Clade I\nASV23:Clade Ia                                        Clade I\nASV26:Chloroplast                                        <NA>\nASV30:Marine Group II                                    <NA>\nASV32:Dadabacteriales                                    <NA>\nASV33:SAR324 clade(Marine group B)                       <NA>\nASV35:Clade IV                                       Clade IV\nASV37:Marine Group III                                   <NA>\nASV49:SAR202 clade                                       <NA>\nASV53:AEGEAN-169 marine group         AEGEAN-169 marine group\n                                                        Genus Species\nASV1:Synechococcus CC9902                Synechococcus CC9902    <NA>\nASV2:Pseudoalteromonas                      Pseudoalteromonas    <NA>\nASV3:Clade Ia                                        Clade Ia    <NA>\nASV4:Marine Group II                                     <NA>    <NA>\nASV5:Clade Ia                                        Clade Ia    <NA>\nASV6:Clade II                                            <NA>    <NA>\nASV9:Clade Ia                                        Clade Ia    <NA>\nASV10:Clade Ia                                       Clade Ia    <NA>\nASV11:AEGEAN-169 marine group                            <NA>    <NA>\nASV12:Prochlorococcus MIT9313.marinus Prochlorococcus MIT9313 marinus\nASV16:AEGEAN-169 marine group                            <NA>    <NA>\nASV18:Clade Ib                                       Clade Ib    <NA>\nASV22:Clade Ia                                       Clade Ia    <NA>\nASV23:Clade Ia                                       Clade Ia    <NA>\nASV26:Chloroplast                                        <NA>    <NA>\nASV30:Marine Group II                                    <NA>    <NA>\nASV32:Dadabacteriales                                    <NA>    <NA>\nASV33:SAR324 clade(Marine group B)                       <NA>    <NA>\nASV35:Clade IV                                           <NA>    <NA>\nASV37:Marine Group III                                   <NA>    <NA>\nASV49:SAR202 clade                                       <NA>    <NA>\nASV53:AEGEAN-169 marine group                            <NA>    <NA>"
  },
  {
    "objectID": "practicals/alpha_diversity.html#visualise-core-microbiome-with-microbiomeplot_core",
    "href": "practicals/alpha_diversity.html#visualise-core-microbiome-with-microbiomeplot_core",
    "title": "PARTII_alpha_Diversity_ANF",
    "section": "7.2 Visualise core microbiome with microbiome::plot_core()",
    "text": "7.2 Visualise core microbiome with microbiome::plot_core()\nVisualise the core microbiome of North samples\n\nmicrobiome::plot_core(phyloseq_core_north,\n                      plot.type = \"heatmap\",\n                      colours = rev(RColorBrewer::brewer.pal(8, \"RdBu\")),\n                      prevalences = seq(from = 0, to = 1, by = .1),\n                      detections = seq(from = 0.1, to = 5, by = 0.2)) +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2))+\n  xlab(\"Detection Threshold (Relative Abundance (%))\") +\n  ylab(\"ASVs\")\n\nWarning in microbiome::plot_core(phyloseq_core_north, plot.type = \"heatmap\", : The plot_core function is typically used with compositional \n                data. The data is not compositional. Make sure that you\n                intend to operate on non-compositional data.\n\n\n\n\n\nDo the same for the South samples .. please!\nWhat are your conclusions about the comparison between North & South core micobiota at the ASV level?"
  },
  {
    "objectID": "practicals/beta_diversity.html",
    "href": "practicals/beta_diversity.html",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "",
    "text": "library(phyloseq)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\noutput_beta <- here::here(\"outputs\", \"beta_diversity\")\nif (!dir.exists(output_beta)) dir.create(output_beta)\n\n\n\n\nLoad the data and inspect the phyloseq object\n\nphyseq <- readRDS(here::here(\"data\",\n                             \"asv_table\",\n                             \"phyloseq_object_alpha_beta_div.rds\"))"
  },
  {
    "objectID": "practicals/beta_diversity.html#normalisation",
    "href": "practicals/beta_diversity.html#normalisation",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "2.1 Normalisation",
    "text": "2.1 Normalisation\nHere we will consider two approaches for library size normalization. The first will involve simply subsampling the data without replacement; however, this approach comes with limitations that are well described here.\nThe second will employ a compositional data analysis approach and involves working with log-ratios.\n\n2.1.1 Rarefaction\nWe will subsample reads from each sample without replacement to a constant depth. Let see first how many reads we have per sample:\n\nrowSums(physeq@otu_table@.Data)\n\nS11B  S1B  S2B  S2S  S3B  S3S  S4B  S4S  S5B  S5S  S6B  S6S  S7B  S7S  S8B  S8S \n 975  837  893  983  878  889  917 1077 1018 1006 1076  937  878  936  846  958 \n S9B  S9S \n 888  991 \n\n\nWe will plot these results and look at the rank abudance of the reads\n\nreadsumsdf <- data.frame(nreads = sort(taxa_sums(physeq), decreasing = TRUE),\n                        sorted = 1:ntaxa(physeq),\n                        type = \"OTUs\")\n\ntmp <- data.frame(nreads = sort(sample_sums(physeq), decreasing = TRUE), \n                  sorted = 1:nsamples(physeq),\n                  type = \"Samples\")\n\nreadsumsdf <- rbind(readsumsdf, tmp)\n\nhead(readsumsdf)\n\n     nreads sorted type\nASV1   1558      1 OTUs\nASV2    973      2 OTUs\nASV3    899      3 OTUs\nASV4    833      4 OTUs\nASV5    767      5 OTUs\nASV6    654      6 OTUs\n\n\n\nggplot(readsumsdf, aes(x = sorted, y = nreads)) +\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"Total number of reads\") +\n  scale_y_log10() +\n  facet_wrap(~type, nrow = 1, scales = \"free\")\n\n\n\n\nWe will now transform to equal sample sum (Only if the number of reads is not the same between samples) in order to be sure that the sampling effort is the same between samples.\n\n# set the seed for random sampling\n# it allows reproductibility\nset.seed(10000)\n\n# minimum reads in a sample\nmin(rowSums(physeq@otu_table@.Data))\n\n[1] 837\n\n\nThe minimun number of reads in a sample is 837. Lets do the randomization at 800 reads per sample in order to apply the process also in the sample having this minimum of reads.\n\nphyseq_rar <- rarefy_even_depth(physeq, sample.size = 800)\nrowSums(physeq_rar@otu_table@.Data) #how many reads per sample\n\nS11B  S1B  S2B  S2S  S3B  S3S  S4B  S4S  S5B  S5S  S6B  S6S  S7B  S7S  S8B  S8S \n 800  800  800  800  800  800  800  800  800  800  800  800  800  800  800  800 \n S9B  S9S \n 800  800 \n\n\n\nphyseq\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 213 taxa and 18 samples ]\nsample_data() Sample Data:       [ 18 samples by 21 sample variables ]\ntax_table()   Taxonomy Table:    [ 213 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 213 tips and 212 internal nodes ]\nrefseq()      DNAStringSet:      [ 213 reference sequences ]\n\n\n\nphyseq_rar\n\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 208 taxa and 18 samples ]\nsample_data() Sample Data:       [ 18 samples by 21 sample variables ]\ntax_table()   Taxonomy Table:    [ 208 taxa by 7 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 208 tips and 207 internal nodes ]\nrefseq()      DNAStringSet:      [ 208 reference sequences ]\n\n\n\n\n2.1.2 Centered log-ratio (CLR) transformation\nA detailed discussion of compositional data analysis (CoDA) is beyond the scope of this session but just know that microbiome data is compositional since reads total is constrained by the sequencing depth. Relative abundances (proportions) are obviously constraint by a sum equal to one. This total constraint induces strong dependencies among the observed abundances of the different taxa. In fact, nor the absolute abundance (read counts) nor the relative abundance (proportion) of one taxon alone are informative of the real abundance of the taxon in the environment. Instead, they provide information on the relative measure of abundance when compared to the abundance of other taxa in the same sample. For this reason, these data fail to meet many of the assumptions of our favorite statistical methods developed for unconstrained random variables. Working with ratios of compositional elements lets us transform these data to the Euclidian space and apply our favorite methods. There are different types of log-ratio “transformations” including the additive log-ratio, centered log-ratio, and isometric log-ratio transforms. Find more information here, here and here\nLet’s perform the CLR transformation\ntmp\n\n # we first replace the zeros using\n # the Count Zero Multiplicative approach\ntmp <- zCompositions::cmultRepl(physeq@otu_table,\n                                method = \"CZM\",\n                                label = 0)\n\n# generate the centered log-ratio transformed. ASVs are in rows!!!!!\nphyseq_clr_asv <- apply(tmp, 1, function(x) log(x) - mean(log(x)))\n\n\n#create a new phyloseq object with CLR tranformed counts\nphyseq_clr <- physeq\notu_table(physeq_clr) <- otu_table(t(physeq_clr_asv),\n                                   taxa_are_rows = FALSE)\ndata.frame(physeq_clr@otu_table@.Data[1:5,1:10])\n\n         ASV1       ASV2     ASV3       ASV4     ASV5     ASV6       ASV7\nS11B 5.172800  3.6295018 4.853277  4.6591212 4.876534 4.099505  4.4536772\nS1B  4.630559 -0.6264429 3.561361 -0.6264429 4.357692 4.297068 -0.6264429\nS2B  4.065517 -0.7557464 3.859665  3.0123670 4.041986 4.255561 -0.7557464\nS2S  5.042825  4.8740037 4.738829  2.8930022 5.003215 4.169296  3.9916145\nS3B  4.440233 -0.6954498 3.828432 -0.6954498 4.254516 4.653155 -0.6954498\n           ASV8       ASV9      ASV10\nS11B  3.9369865  4.1241980 -0.6524920\nS1B  -0.6264429  3.7217036  4.4863097\nS2B  -0.7557464 -0.7557464  4.0655169\nS2S   4.6847617  4.2367369 -0.6558837\nS3B  -0.6954498 -0.6954498  4.4057470\n\n\nWe can see that the values are now no longer counts, but rather the dominance (or lack thereof) for each taxa relative to the geometric mean of all taxa on the logarithmic scale. This centered log-ratio (CLR) transformed table can be used directly in a PCA or RDA to generate a beta diveristy ordination using the Aitchison distance.\nTips: This chunk can be coded in one line using the microbiome package: physeq_clr <- microbiome::transform(physeq, “clr”)"
  },
  {
    "objectID": "practicals/beta_diversity.html#treemaps",
    "href": "practicals/beta_diversity.html#treemaps",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "3.1 Treemaps",
    "text": "3.1 Treemaps\n\n3.1.1 What for?\nLooking at the composition of the meta community with a treemap allow roughly to detect if some taxa should not be present (contaminants) and observe if the dominanting taxa correspond to the habitat studied.\n\n\n3.1.2 Using the package treemap\n\n#pdf(file=\"treemap.pdf\", wi = 7, he = 7)\ntreemap::treemap(physeq_phylum, index=c(\"Class\", \"Family\"), vSize=\"Abundance\", type=\"index\",\n        fontsize.labels=c(15,12),                # size of labels. Give the size per level of aggregation: size for group, size for subgroup, sub-subgroups...\n        fontcolor.labels=c(\"white\",\"black\"),    # Color of labels\n        fontface.labels=c(2,1),                  # Font of labels: 1,2,3,4 for normal, bold, italic, bold-italic...\n        align.labels=list(\n          c(\"center\", \"center\"), \n          c(\"left\", \"bottom\")),                 # Where to place labels in the rectangle?\n        overlap.labels=0.5,                      # number between 0 and 1 that determines the tolerance of the overlap between labels. 0 means that labels of lower levels are not printed if higher level labels overlap, 1  means that labels are always printed. In-between values, for instance the default value .5, means that lower level labels are printed if other labels do not overlap with more than .5  times their area size.\n        inflate.labels=F, # If true, labels are bigger when rectangle is bigger.\n        border.col=c(\"black\",\"white\"),          #Color of the boders separating the taxonomic levels\n        border.lwds=c(4,2),\n        #palette = \"Set3\",                        # Select your color palette from the RColorBrewer presets or make your own.\n        fontsize.title=12\n)\n\n\n\n#dev.off()\n\n\n\n3.1.3 Using the package treemapify\n\ntmp <- transform_sample_counts(physeq,function(x) {x/sum(x)} ) %>%\n  psmelt() %>%\n  group_by(Family, Class) %>%\n  summarise(abundance = sum(Abundance)) %>%\n  na.omit()\n\nggplot(tmp,aes(area=abundance,label=Family,fill=Class,subgroup=Class))+\n  treemapify::geom_treemap()+\n  treemapify::geom_treemap_subgroup_border() +\n  treemapify::geom_treemap_subgroup_text(place = \"centre\",\n                                         grow = T,\n                                         alpha = 0.5,\n                                         colour = \"black\",\n                                         fontface = \"italic\",\n                                         min.size = 0) +\n  treemapify::geom_treemap_text(colour = \"white\",\n                                place = \"topleft\",\n                                reflow = TRUE)+\n  theme(legend.position=\"none\")\n\n\n\nggsave(here::here(output_beta,\"treemap_treemapify.pdf\"))\n\n\n\n3.1.4 Observations\nHere we can observe that the meta-community is dominated by typical marine clades such as the AEGEAN marine group in Alphaproteobacteria or the SAR86 clade in Gammaproteobacteria. So everything is good so far."
  },
  {
    "objectID": "practicals/beta_diversity.html#stacked-barplots",
    "href": "practicals/beta_diversity.html#stacked-barplots",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "3.2 Stacked barplots",
    "text": "3.2 Stacked barplots\n\nggplot(physeq_phylum, aes(x = Sample, y = Abundance, fill = Family)) + \n  geom_bar(stat = \"identity\") +\n  # facet_wrap(~Treatment, nrow=1, scales = \"free_x\") +\n  ylab(\"Relative Abundance (Family > 2%)\") +\n  scale_y_continuous(expand = c(0,0)) + #remove the space below the 0 of the y axis in the graph\n  ggtitle(\"Community composition\") +\n  theme_bw() +\n  theme(axis.title.x = element_blank(),\n        axis.text.x = element_text(angle = 45, size = 10,\n                                   hjust = 0.5, vjust = 0.8),\n        axis.ticks.x = element_blank(),\n        panel.background = element_blank(), \n        panel.grid.major = element_blank(),  #remove major-grid labels\n        panel.grid.minor = element_blank())  #remove minor-grid labels\n\n\n\nggsave(here::here(output_beta, \"asv_composition.pdf\"))\n\nHere we can already see some differences in the composition at the Family level with an enrichment in Pseudoalteromonadaceae in some samples and Cyanobiaceae. Note that we are limited by our ability to discernate between than more than 9-12 colors in this kind of graphic."
  },
  {
    "objectID": "practicals/beta_diversity.html#calculation",
    "href": "practicals/beta_diversity.html#calculation",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "4.1 Calculation",
    "text": "4.1 Calculation\nOver the years, ecologists have invented numerous ways of quantifying dissimilarity between pairs of ecosystems.Four components of species community beta-diveristy can be assessed using different distances or dissimilarities. Compostional distances or dissimilarities do not consider the relative abundance of taxa, only their presence (detection) or absence, which can make it (overly) sensitive to rare taxa, sequencing artefacts, and abundance filtering choices. Conversely, structural distances or dissimilarities do put (perhaps too much) more importance on highly abundant taxa, when determining dissimilarities. Phylogentic distances or dissimilarities take into account the phylogenetic relatedness of the taxa / sequences in your samples when calculating dissimilarity while taxnomic distances or dissimilarities do not.\n\n4.1.1 Compositional taxonomic\n\nphyseq_rar_jaccard <- phyloseq::distance(physeq_rar,\n                                         method = \"jaccard\",\n                                         binary = TRUE)\n\n# trick to avoid negative egein values in PCoA\n# it recreates what ade4::dist.binary() does\nphyseq_rar_jaccard <- sqrt(physeq_rar_jaccard)\n\n\n\n4.1.2 Compositional phylogenetic (Unweighted unifrac)\nThe GUniFrac package requires a rooted tree as input data. We can use the function midpoint() from the phangorn package to obtain the rooted tree.\nTo check if your tree is rooted, you may use this function:\n\nape::is.rooted(physeq_rar@phy_tree)\n\n[1] TRUE\n\n\nIf not, you can use the function midpoint() from the package phangorn\n\nphy_tree(physeq_rar) <- phangorn::midpoint(physeq_rar@phy_tree)\n\nNow, Unifrac distances can be calculated\n\nunifracs <- GUniFrac::GUniFrac(physeq_rar@otu_table@.Data, physeq_rar@phy_tree, alpha=c(0, 0.5, 1))$unifracs\n\nThe unifracs object is a list containing 5 distance matrices correspoonding to the weighted UniFrac (d_1), the unweighted UniFrac (d_UW), Variance adjusted UniFrac (d_VAW), GUniFrac with alpha = 0, GUniFrac with alpha = 0.5\n\nphyseq_rar_du <- unifracs[, , \"d_UW\"]   # Unweighted UniFrac\n\n\n\n4.1.3 Structural taxonomic (Bray-Curtis)\n\n# physeq_rar_bray <- vegan::vegdist(physeq_rar@otu_table@.Data, method = \"bray\")\n\ntmp <- transform_sample_counts(physeq,function(x) {x/sum(x)} )\nphyseq_rar_bray <- phyloseq::distance(tmp, method = \"bray\")\n\n\n\n4.1.4 Structural phylogenetic (Weighted UniFrac)\n\nphyseq_rar_dw <- unifracs[, , \"d_1\"]   # Weighted UniFrac"
  },
  {
    "objectID": "practicals/beta_diversity.html#visualisation",
    "href": "practicals/beta_diversity.html#visualisation",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "4.2 Visualisation",
    "text": "4.2 Visualisation\nYou can actually calculate all these distances directly in phyloseq using dist.calc(). There are currently 44 explicitly supported method options in the phyloseq package, see https://joey711.github.io/phyloseq/distance.html for more informations. Here, we will loop through each distance method, save each plot to a list and then plot these results in a combined graphic using ggplot2.\n\ndist_methods <- unlist(distanceMethodList)\ndata.frame(position = seq_along(dist_methods),\n           dist_methods)\n\n            position dist_methods\nUniFrac1           1      unifrac\nUniFrac2           2     wunifrac\nDPCoA              3        dpcoa\nJSD                4          jsd\nvegdist1           5    manhattan\nvegdist2           6    euclidean\nvegdist3           7     canberra\nvegdist4           8         bray\nvegdist5           9   kulczynski\nvegdist6          10      jaccard\nvegdist7          11        gower\nvegdist8          12     altGower\nvegdist9          13     morisita\nvegdist10         14         horn\nvegdist11         15    mountford\nvegdist12         16         raup\nvegdist13         17     binomial\nvegdist14         18         chao\nvegdist15         19          cao\nbetadiver1        20            w\nbetadiver2        21           -1\nbetadiver3        22            c\nbetadiver4        23           wb\nbetadiver5        24            r\nbetadiver6        25            I\nbetadiver7        26            e\nbetadiver8        27            t\nbetadiver9        28           me\nbetadiver10       29            j\nbetadiver11       30          sor\nbetadiver12       31            m\nbetadiver13       32           -2\nbetadiver14       33           co\nbetadiver15       34           cc\nbetadiver16       35            g\nbetadiver17       36           -3\nbetadiver18       37            l\nbetadiver19       38           19\nbetadiver20       39           hk\nbetadiver21       40          rlb\nbetadiver22       41          sim\nbetadiver23       42           gl\nbetadiver24       43            z\ndist1             44      maximum\ndist2             45       binary\ndist3             46    minkowski\ndesigndist        47          ANY\n\n#Select the distances of interest\ndist_methods <- dist_methods[c(1, 2, 10, 8)]\ndist_methods\n\n  UniFrac1   UniFrac2   vegdist6   vegdist4 \n \"unifrac\" \"wunifrac\"  \"jaccard\"     \"bray\" \n\n#Loop through each distance method, save each plot to a list, called plist.\nplist <- vector(\"list\")\n\nfor(i in dist_methods){\n  # Calculate distance matrix\n  iDist <- phyloseq::distance(physeq_rar, method = i)\n  # Calculate PCoA ordination\n  iMDS <- ordinate(physeq_rar, \"MDS\", distance = iDist)\n  ## Make plot. Don't carry over previous plot (if error, p will be blank)\n  p <- NULL\n  # Create plot, store as temp variable, p\n  p <- plot_ordination(physeq_rar, iMDS, color= \"Geo\")\n  # Add title to each plot\n  p <- p + ggtitle(paste(\"MDS using distance method \", i, sep=\"\"))\n  # Save the graphic to list\n  plist[[i]] = p \n}\n\nCombine results\n\ndf <- plyr::ldply(plist, function(x) x$data)\nhead(df)\n\n      .id      Axis.1      Axis.2 SampName   Geo Description groupe Pres\n1 unifrac  0.09023445  0.06150644     S11B South     South5B    SGF   35\n2 unifrac -0.21048836 -0.19946687      S1B North     North1B    NBF   52\n3 unifrac -0.21001002 -0.08655455      S2B North     North2B    NBF   59\n4 unifrac  0.12583068  0.07022248      S2S North     North2S    NBS    0\n5 unifrac -0.31465014 -0.06077941      S3B North     North3B    NBF   74\n6 unifrac -0.16616937  0.01827175      S3S North     North3S    NBS    0\n  PicoEuk Synec Prochloro NanoEuk Crypto SiOH4   NO2   NO3   NH4   PO4    NT\n1    5370 46830       580    6010   1690 3.324 0.083 0.756 0.467 0.115 9.539\n2     660 32195     10675     955    115 1.813 0.256 0.889 0.324 0.132 9.946\n3     890 25480     16595     670    395 2.592 0.105 1.125 0.328 0.067 9.378\n4     890 25480     16595     670    395 3.381 0.231 0.706 0.450 0.109 8.817\n5     835 13340     25115    1115    165 1.438 0.057 1.159 0.369 0.174 8.989\n6     715 26725     16860     890    200 1.656 0.098 0.794 0.367 0.095 7.847\n     PT   Chla       T       S Sigma_t\n1 4.138 0.0182 23.0308 38.9967 26.9631\n2 3.565 0.0000 22.7338 37.6204 26.0046\n3 3.391 0.0000 22.6824 37.6627 26.0521\n4 3.345 0.0000 22.6854 37.6176 26.0137\n5 2.568 0.0000 21.5296 37.5549 26.2987\n6 2.520 0.0000 22.5610 37.5960 26.0332\n\nnames(df)[1] <- \"distance\"\n\nggplot(df, aes(Axis.1, Axis.2, color = Geo)) +\n  geom_point(size=3, alpha=0.5) +\n  theme_bw() +\n  facet_wrap(~distance, scales=\"free\") +\n  ggtitle(\"PCoA (MDS) on various distance metrics\")\n\n\n\n\nWe can observe that there is a fairly good separation between North and South samples except for the Weighted UniFrac distance which tends to give too much weight to the most abundant ASVs that are also the most frequent."
  },
  {
    "objectID": "practicals/beta_diversity.html#hierarchical-ascendant-classification-hac",
    "href": "practicals/beta_diversity.html#hierarchical-ascendant-classification-hac",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "5.1 Hierarchical ascendant classification (HAC)",
    "text": "5.1 Hierarchical ascendant classification (HAC)\nA first step in many microbiome projects is to examine how samples cluster on some measure of (dis)similarity. There are many ways to do perform such clustering, see here. Since microbiome data is compositional, we will perform here a hierarchical ascendant classification (HAC) of samples based on Aitchison distance.\n\n#distance matrix calculation\nphyseq_clr_dist <- phyloseq::distance(physeq_clr, method = \"euclidean\")\n\nLet’s see the different clustering obtained with the four aggregation criterion\n\n#Simple aggregation criterion\nspe_single <- hclust(physeq_clr_dist, method = \"single\")\n\n#Complete aggregation criterion\nspe_complete <- hclust(physeq_clr_dist, method = \"complete\")\n\n#Unweighted pair group method with arithmetic mean\nspe_upgma <- hclust(physeq_clr_dist, method = \"average\")\n\n#Ward criterion\nspe_ward <- hclust(physeq_clr_dist, method = \"ward.D\")\n\npar(mfrow = c(2, 2))\nplot(spe_single, main = \"single\")\nplot(spe_complete, main = \"complete\")\nplot(spe_upgma, main = \"UPGMA\")\nplot(spe_ward, main = \"ward\")\n\n\n\n\nRemember that clustering is a heuristic procedure, not a statistical test. The choices of an association coefficient and a clustering method influence the result. This stresses the importance of choosing a method that is consistent with the aims of the analysis."
  },
  {
    "objectID": "practicals/beta_diversity.html#cophenetic-correlation",
    "href": "practicals/beta_diversity.html#cophenetic-correlation",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "5.2 Cophenetic Correlation",
    "text": "5.2 Cophenetic Correlation\nA cophenetic matrix is a matrix representing the cophenetic distances among all pairs of objects. A Pearson’s r correlation, called the cophenetic correlation in this context, can be computed between the original dissimilarity matrix and the cophenetic matrix. The method with the highest cophenetic correlation may be seen as the one that produced the best clustering model for the distance matrix.\nLet us compute the cophenetic matrix and correlation of four clustering results presented above, by means of the function cophenetic() of package stats.\n\n#Cophenetic corrélation\nspe_single_coph <- cophenetic(spe_single)\ncor(physeq_clr_dist, spe_single_coph)\nspe_complete_coph <- cophenetic(spe_complete)\ncor(physeq_clr_dist, spe_complete_coph)\nspe_upgma_coph <- cophenetic(spe_upgma)\ncor(physeq_clr_dist, spe_upgma_coph)\nspe_ward_coph <- cophenetic(spe_ward)\ncor(physeq_clr_dist, spe_ward_coph)\n\nWhich dendrogram retains the closest relationship to the Aitchinson distance matrix?\nTo illustrate the relationship between a distance matrix and a set of cophenetic matrices obtained from various methods, one can draw Shepard-like diagrams (Legendre and Legendre 1998, p. 377) by plotting the original distances against the cophenetic distances.\n\nplot_coph_cor <- function(cophenetic_distance, hclust_type){\n\n  # first calculate the correlation between\n  # the cophenetic distance and the observed distance\n  cor_res <- round(cor(physeq_clr_dist, cophenetic_distance),3)\n\n  # generate a scatter plot to visualise\n  # the relationship\n  plot(x = physeq_clr_dist,\n     y = cophenetic_distance,\n     xlab = \"Aitchison distance\",\n     ylab = \"Cophenetic distance\",\n     xlim = c(10, 35), ylim = c(10, 35),\n     main = c(hclust_type, paste(\"Cophenetic correlation \", cor_res)))\n  abline(0, 1)\n}\n\npar(mfrow=c(2,2))\n\nplot_coph_cor(cophenetic_distance = spe_complete_coph,\n              hclust_type = \"Single linkage\")\n\nplot_coph_cor(cophenetic_distance = spe_complete_coph,\n              hclust_type = \"Complete linkage\")\n\nplot_coph_cor(cophenetic_distance = spe_upgma_coph,\n              hclust_type = \"Average linkage\")\n\nplot_coph_cor(cophenetic_distance = spe_ward_coph,\n              hclust_type = \"Ward linkage\")\n\n\n\n\nIt seems clear that the UPGMA method give the most faithful representation of original distances."
  },
  {
    "objectID": "practicals/beta_diversity.html#looking-for-interpretable-clusters",
    "href": "practicals/beta_diversity.html#looking-for-interpretable-clusters",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "5.3 Looking for Interpretable Clusters",
    "text": "5.3 Looking for Interpretable Clusters\nTo interpret and compare clustering results, users generally look for interpretable clusters. This means that a decision must be made: at what level should the dendrogram be cut? Many indices (more than 30) has been published in the literature for finding the right number of clusters in a dataset. The process has been covered here. The fusion level values of a dendrogram are the dissimilarity values where a fusion between two branches of a dendrogram occurs. Plotting the fusion level values may help define cutting levels. Let us plot the fusion level values for for the UPGMA dendrogram.\n\n#Fusion level plot\npar(mfrow = c(1, 1))\n\nplot(x = spe_upgma$height,\n     y = phyloseq::nsamples(physeq_clr):2,\n     type = \"S\",\n     main = \"Fusion levels - Aitchison - Average\",\n     ylab = \"k (number of cluster)\",\n     xlab = \"h (node height)\")\n\ntext(x = spe_upgma$height,\n     y = phyloseq::nsamples(physeq_clr):2,\n     labels = phyloseq::nsamples(physeq_clr):2,\n     col = \"red\",\n     cex = 0.8)\n\n\n\n\nFrom right to left, this first graph shows clear jumps after each fusion between 2 groups.\n\n#Cut the dendrogram in order to obtain K groups and compare their compositionC\nk <- 2 # Number of groups given by the fusion level plot\n\n#Cut the dendrogram\nspe_upgma_clust <- cutree(tree = spe_upgma, k = k)\ntable(spe_upgma_clust)\n\nspe_upgma_clust\n 1  2 \n12  6 \n\nspe_upgma_clust2 <- data.frame(UPGMA_clusters = spe_upgma_clust)\n\n\n# Plot dendrogram with group labels\nplot(spe_upgma,\n     hang = -1,\n     ylab = \"Height\",\n     main=\"Aitchison distance - UPGMA\")\n\nrect.hclust(spe_upgma,\n            k = k,\n            border = 2:6,\n            cluster = spe_upgma_clust)\n\nlegend(\"topright\",\n       paste(\"Cluster\", 1:k),\n       pch = 22,\n       col = 2:(k + 1),\n       bty = \"n\")\n\n\n\n\nDo the groups obtained make sense? Do you obtain enough groups containing a substantial number of sites?\nThere are several ways to measure the robustness of a clustering algorithm. Three commonly used metrics are the Dunn index, Davis-Bouldin index and Silhoutte index. The Dunn index is calculated as a ratio of the smallest inter-cluster distance to the largest intra-cluster distance. A high DI means better clustering since observations in each cluster are closer together, while clusters themselves are further away from each other. We’ll use the function cluster.stats() in fpc package for computing the Dunn index which can be used for cluster validation,\n\ncs <- fpc::cluster.stats(d = physeq_clr_dist,\n                         clustering = spe_upgma_clust)\n\ncs$dunn\n\n[1] 0.9231545\n\n\nThe Dunn index is high indicating a good clustering of samples. Now that we identified two groups of samples based on their microbial community composition, we may want to look at which microbial clades or ASVs are enriched in each of the groups."
  },
  {
    "objectID": "practicals/beta_diversity.html#combining-clustering-and-z-score-heatmap",
    "href": "practicals/beta_diversity.html#combining-clustering-and-z-score-heatmap",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "5.4 Combining clustering and Z-score Heatmap",
    "text": "5.4 Combining clustering and Z-score Heatmap\nZ-score heatmap are normalized (centered around the mean (by line!!) & reduced (Standard deviation= SD). It’s the comparison on an observed value of a sample to the mean of the population. So, it answers to the question, how far from the population mean is a score for a given sample. The scores are given in SD to the population mean.\n\n5.4.1 Select the top 30 ASV\nHere we used ASV but of course you can do it on Family or genus taxonomic level!\n\n#Transform Row/normalized counts in percentage: transform_sample_counts\npourcentS <- phyloseq::transform_sample_counts(physeq_rar, function(x) x/sum(x) * 100)\n#Selection of top 30 taxa \nmytop30 <- names(sort(phyloseq::taxa_sums(pourcentS), TRUE)[1:30])\n#Extraction of taxa from the object pourcentS\nselection30 <- phyloseq::prune_taxa(mytop30, pourcentS)\n#See new object with only the top 30 ASV\nselection30\n\n\n\n5.4.2 Get the otu_table & Z-score transformation\n\n#Retrieve abundance of ASV (otu_table) as table & put in data.prop variable\nselection30_asv <- phyloseq::otu_table(selection30)\nselection30_sample <- phyloseq::sample_data(selection30)\n\n#Change the rownames\n#See\nrownames(selection30_asv)\n\n [1] \"S11B\" \"S1B\"  \"S2B\"  \"S2S\"  \"S3B\"  \"S3S\"  \"S4B\"  \"S4S\"  \"S5B\"  \"S5S\" \n[11] \"S6B\"  \"S6S\"  \"S7B\"  \"S7S\"  \"S8B\"  \"S8S\"  \"S9B\"  \"S9S\" \n\n#Change... Why?\n\n# rownames(data.prop)<-c(\"S11B_South5B\",\"S1B_North1B\",\"S2B_North2B\",\"S2S_North2S\",\"S3B_North3B\",\"S3S_North3S\",\"S4B_North4B\",\"S4S_North4S\",\"S5B_North5B\",\"S5S_North5S\",\"S6B_South1B\",\"S6S_South1S\",\"S7B_South2B\",\"S7S_South2S\",\"S8B_South3B\",\"S8S_South3S\",\"S9B_South4B\",\"S9S_South4S\")\n\nsample_new_names <- paste(selection30_sample$SampName,\n                          selection30_sample$Description,\n                          sep = \"_\")\n\n#Z-score transformation (with scale)\nheat <- t(base::scale(selection30_asv))\n#See\nhead(data.frame(heat))\n\n           S11B         S1B        S2B        S2S        S3B         S3S\nASV1  1.0670101 -0.36085474 -0.8368097  0.5070631 -0.6688256  0.08710287\nASV2 -0.3822681 -0.72549212 -0.7254921  0.5166521 -0.7254921 -0.59474010\nASV3  1.4657223 -1.12279860 -0.5254476  0.6692543 -0.3761099 -2.16816282\nASV4  0.2776466 -1.18129127 -0.9019202 -0.8087965 -1.1812913 -0.77775527\nASV5  1.1642633  0.31674810  0.2397013  1.3954038  0.3552715  0.20117785\nASV6  0.4514863 -0.01289961  0.7417276  0.3934381  1.4963548 -1.81239520\n            S4B        S4S         S5B        S5S         S6B         S6S\nASV1 -1.7327249 -0.3608547  1.48697039  2.2149015  1.48697039 -0.47284414\nASV2 -0.6110841 -0.6764601 -0.49667608 -0.7254921  0.38590007  3.34416457\nASV3 -0.6747854 -0.7245646  1.06748833 -1.0232401 -0.02765514  0.02212411\nASV4 -0.3121368 -1.1812913  1.67450193  1.1778422 -0.68463158 -0.56046666\nASV5 -0.3766734  0.5864120 -1.30123544  0.2782247  1.43392721 -1.30123544\nASV6  0.7997758 -1.8123952  0.04514863 -1.8123952 -0.59338206 -0.59338206\n            S7B         S7S        S8B        S8S        S9B          S9S\nASV1 -0.8928044  0.03110817 -0.6128309 -0.3888521 -0.5568362  0.003110817\nASV2  0.9742842 -0.18614003  0.4349321 -0.5293641  0.4022441  0.320524054\nASV3  0.6194751 -0.22677213  0.5696958  1.8639563 -0.1769929  0.768812836\nASV4  0.8363887  1.02263609  1.2088835  1.1778422  0.8053475 -0.591507891\nASV5 -1.3012354 -1.30123544 -1.3012354  0.3552715  1.2798335 -0.723384173\nASV6 -0.1870443  0.10319688  0.7417276  0.2192934  0.5095346  1.322210022\n\n\n\n\n5.4.3 Heat map Z-score\n\nComplexHeatmap::Heatmap(\n  heat,\n  row_names_gp = grid::gpar(fontsize = 6),\n  cluster_columns = FALSE,\n  heatmap_legend_param = list(direction = \"vertical\",\n                              title = \"Z-scores\", \n                              grid_width = unit(0.5, \"cm\"),\n                              legend_height = unit(3, \"cm\"))\n)\n\n\n\n\n\n\n5.4.4 Add the Taxonomy for ASV names\n\n#get taxnomic table\ntaxon <- phyloseq::tax_table(selection30) |>\n  as.data.frame()\n\n#concatene ASV with Phylum & Family names\nmyname <- paste(rownames(taxon), taxon$Phylum, taxon$Family, sep=\"_\")\n#apply\ncolnames(selection30_asv) <- myname\n\n\n\n5.4.5 Apply to the Heatmap\n\n#re-run Z-score to take into account the colnames change\nheat <- t(scale(selection30_asv))\n\nmy_top_annotation <- ComplexHeatmap::anno_block(gp = grid::gpar(fill =c(3,4)),\n                                               labels = c(1, 2),\n                                               labels_gp = grid::gpar(col = \"white\",\n                                                                      fontsize = 10))\n\nComplexHeatmap::Heatmap(\n  heat,\n  row_names_gp = grid::gpar(fontsize = 6),\n  cluster_columns =TRUE,\n  heatmap_legend_param = list(direction = \"vertical\",\n   title =\"Z-scores\",\n   grid_width = unit(0.5, \"cm\"),\n   legend_height = unit(4, \"cm\")),\n  top_annotation = ComplexHeatmap::HeatmapAnnotation(foo = my_top_annotation),\n  column_km = 2,\n  column_names_gp= grid::gpar(fontsize = 6)\n  )\n\n\n\n\n\n\n5.4.6 Add a boxplot of ASV Abundance distribution within sample\n\nboxplot <- ComplexHeatmap::anno_boxplot(t(selection30_asv), \n                                        which = \"row\",\n                                        gp = grid::gpar(fill = \"turquoise3\"))\n\nmy_boxplot_left_anno <- ComplexHeatmap::HeatmapAnnotation(Abund = boxplot,\n                                                          which = \"row\",\n                                                          width = unit(3, \"cm\"))\n\nmy_top_anno <- ComplexHeatmap::anno_block(gp = grid::gpar(fill = c(3, 6)),\n                                          labels = c(\"South\", \"North\"),\n                                          labels_gp = grid::gpar(col = \"white\",\n                                                                fontsize = 10))\n\nmy_top_anno <- ComplexHeatmap::HeatmapAnnotation(foo = my_top_anno)\n\nComplexHeatmap::Heatmap(\n  heat,\n  row_names_gp = grid::gpar(fontsize = 7),\n  left_annotation = my_boxplot_left_anno, \n  heatmap_legend_param = list(direction = \"vertical\",\n                              title =\"Z-scores\",\n                              grid_width = unit(0.5, \"cm\"),\n                              legend_height = unit(3, \"cm\")),\n  top_annotation = my_top_anno,\n  column_km = 2,\n  cluster_columns = TRUE,\n  column_dend_side = \"bottom\",\n  column_names_gp = grid::gpar(fontsize = 7)\n  )\n\n\n\n\nWe can now observe that microbial communities in samples from the south differ in their microbial composition from sample from the north. The significant effect of treatment (North/south) remains to be tested statistically, we’ll see how it is done in the hypothese testing section. This difference in community composition is due to the apparent differential abundance of many top ASV of the dataset. The identification of significant biomarkers in North and South samples will be covered in the differential abundance testing section."
  },
  {
    "objectID": "practicals/beta_diversity.html#principal-component-analysis-pca",
    "href": "practicals/beta_diversity.html#principal-component-analysis-pca",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "6.1 Principal component analysis (PCA)",
    "text": "6.1 Principal component analysis (PCA)\nPrincipal components analysis (PCA) is a method to summarise, in a low-dimensional space, the variance in a multivariate scatter of points. In doing so, it provides an overview of linear relationships between your objects and variables. This can often act as a good starting point in multivariate data analysis by allowing you to note trends, groupings, key variables, and potential outliers. Again, because of the compositional nature of microbiome data, we will use the Aitchinson distance here. Be aware that this is the CLR transformed ASV table which is used directly not the Aitchinson distance matrix. The function will calculate a euclidean distance on this CLR transformed table to get the Aitchison matrix. There are many packages allowing PCA analysis. We will use the recent PCAtools package wich provides functions for data exploration via PCA, and allows the user to generate publication-ready figures.\n\n6.1.1 Number of PCs to retain\nFirst, we will use a scree plot to examine the proportion of total variation explained by each PC.\n\n#prepare the ASV table to add taxonomy\ntax_CLR <-  as.data.frame(tax_table(physeq_clr)) #get taxnomic table\n#concatene ASV with Family & Genus names\nASVname <- paste(rownames(tax_CLR), tax_CLR$Family, tax_CLR$Genus,sep=\"_\")\n#apply \nrownames(physeq_clr_asv) <- ASVname\np <- PCAtools::pca(physeq_clr_asv,\n                   metadata = data.frame(sample_data(physeq_clr)))\nPCAtools::screeplot(p, axisLabSize = 18, titleLabSize = 22)\n\n\n\n#variance explained by each PC\np$variance\n\n         PC1          PC2          PC3          PC4          PC5          PC6 \n3.075855e+01 1.031496e+01 7.599351e+00 6.503439e+00 5.730059e+00 5.408493e+00 \n         PC7          PC8          PC9         PC10         PC11         PC12 \n5.190984e+00 4.610939e+00 3.688116e+00 3.619816e+00 3.196232e+00 2.988529e+00 \n        PC13         PC14         PC15         PC16         PC17         PC18 \n2.558172e+00 2.373339e+00 2.088026e+00 1.905741e+00 1.465248e+00 5.780019e-31 \n\n\nHere we see that the first PC really stands out with 31% of the variance explained and then we have a gradual decline for the remaining components. A scree plot on its own just shows the accumulative proportion of explained variation, but we want to determine the optimum number of PCs to retain.\n\n#Horn’s parallel analysis (Horn 1965) (Buja and Eyuboglu 1992)\nhorn <- PCAtools::parallelPCA(physeq_clr_asv)\nhorn$n\n\n[1] 2\n\n#elbow method\nelbow <- PCAtools::findElbowPoint(p$variance)\nelbow\n\nPC3 \n  3 \n\n\nThe two methods indicate that we should retain the first 2 or 3 PCs. The reason for this discrepancy is because finding the correct number of PCs is a difficult task and is akin to finding the ‘correct’ number of clusters in a dataset - there is no correct answer. Most studies take into account only the two first PCs.\n\n\n6.1.2 Plotting the ordination\n\n#Plotting the PCA\nPCAtools::biplot(\n  p,\n  lab = p$metadata$SampName,\n  colby = \"Geo\",\n  pointSize = 5,\n  hline = 0, vline = 0,\n  legendPosition = \"right\"\n)\n\n\n\n\nEach point is a sample, and samples that appear closer together are typically more similar to each other than samples which are further apart. So by colouring the points by treatment you can see that the microbiota from the North are often, but not always, highly distinct from sample from the south.\n\n\n6.1.3 Determine the variables that drive variation among each PC\nOne benefit of not using a distance matrix, is that you can plot taxa “loadings” onto your PCA axes, using the showLoadings = TRUE argument. PCAtools allow you to plots the number of taxa loading vectors you want beginning by those having the more weight on each PCs. The relative length of each loading vector indicates its contribution to each PCA axis shown, and allows you to roughly estimate which samples will contain more of that taxon.\n\nPCAtools::biplot(\n  p, \n  # loadings parameters\n  showLoadings = TRUE,\n  lengthLoadingsArrowsFactor = 1.5,\n  sizeLoadingsNames = 3,\n  colLoadingsNames = 'red4',\n  ntopLoadings = 3,\n  # other parameters\n  lab = p$metadata$X.SampleID,\n  colby = \"Geo\",\n  hline = 0, vline = 0,\n  legendPosition = \"right\"\n)\n\n\n\n\nASVs 7, 11 and 12 have a high contribution to PC1 while ASVs 38, 40, and 47 have a high contribution on the second PC. These ASVs belong to only two families. Samples from the South seems to be enriched in ASV7 while North samples contain higher abundances of ASV11 and 12. The two Noth sample outliers at the top of the plot are caracterized by a higher abundance of ASVs 38, 40, and 47.\n\n\n6.1.4 Correlate the principal components back to environmental data\nFurther exploration of the PCs can come through correlations with environmental data. Here, we will correlate the two first PCs with environmental data.\n\nPCAtools::eigencorplot(\n  p,\n  components = PCAtools::getComponents(p, 1:horn$n),\n  metavars = c('SiOH4','NO2','NO3','NH4','PO4',\n              'NT','PT','Chla',\"T\", \"S\", \"Sigma_t\"),\n  col = c('white', 'cornsilk1', 'gold',\n          'forestgreen', 'darkgreen'),\n  cexCorval = 1.2,\n  fontCorval = 2,\n  posLab = \"all\",\n  rotLabX = 45,\n  scale = TRUE,\n  main = bquote(PC ~ Spearman ~ r^2 ~ environmental ~ correlates),\n  plotRsquared = TRUE,\n  corFUN = \"spearman\",\n  corUSE = \"pairwise.complete.obs\",\n  corMultipleTestCorrection = 'BH',\n  signifSymbols = c(\"****\", \"***\", \"**\", \"*\", \"\"),\n  signifCutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 1)\n)\n\n\n\n\nThe only signficant correlation found is between the first PC1 explaining the separation between South and North samples and salinity. This is unteresting but correlation between variables does not automatically means that the change in one variable is the cause of the change in the values of the other variable. We’ll check later if there is a causal relationship between the salinity gradient and the difference observed in southern and northern bacterial communities."
  },
  {
    "objectID": "practicals/beta_diversity.html#principal-component-analysis-pcoa",
    "href": "practicals/beta_diversity.html#principal-component-analysis-pcoa",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "6.2 Principal component analysis (PCoA)",
    "text": "6.2 Principal component analysis (PCoA)\nPrincipal coordinates analysis (PCoA, also known as metric multidimensional scaling, MDS) attempts to represent the distances between samples in a low-dimensional, Euclidean space. In particular, it maximizes the linear correlation between the distances in the distance matrix, and the distances in a space of low dimension (typically, 2 or 3 axes are selected). As always, the choice of (dis)similarity measure is critical and must be suitable to the data in question. Here we will use the Bray-Curtis distance. When the distance metric is Euclidean, PCoA is equivalent to Principal Components Analysis. The interpretation of the results is the same as with PCA.\n\n#BPCoA on Bray-Curtis dissimilarity\npcoa_asv <- ape::pcoa(physeq_rar_bray)\npcoa_coord <- pcoa_asv$vectors[, 1:2]\n\n#Data frame for hull\nhull <- data.frame(\"Axis.1\" = pcoa_coord[, 1],\n                   \"Axis.2\" = pcoa_coord[, 2],\n                   \"sample\" = as.data.frame(sample_data(physeq_rar@sam_data)))\n\n\n# North <- hull[hull$sample.Geo  == \"North\", ][chull(hull[hull$sample.Geo ==  \"North\", c(\"Axis.1\", \"Axis.2\")]), ]  # hull values for North\n# South <- hull[hull$sample.Geo == \"South\", ][chull(hull[hull$sample.Geo == \n#                                                          \"South\", c(\"Axis.1\", \"Axis.2\")]), ]  # hull values for Jellyfishes  \n\n# hull_data <- rbind(North, South)\n\n#Vector of color for hulls\n# color <- rep(\"#a65628\", length(hull_data$sample.Geo))\n# color[hull_data$sample.Geo == \"North\"] <- \"#1919ff\"\n# hull_data <- cbind(hull_data, color)\n\nhull_col <- c(\"#a65628\",\"#1919ff\")\nnames(hull_col) <- c(\"North\",\"South\")\n\nhull_data <- hull %>%\n  dplyr::group_by(sample.Geo) %>%\n  dplyr::slice(chull(Axis.1,Axis.2)) %>%\n  dplyr::mutate(color = hull_col[sample.Geo])\n\nhead(hull_data)\n\n# A tibble: 6 × 24\n# Groups:   sample.Geo [1]\n    Axis.1  Axis.2 sample.Samp…¹ sampl…² sampl…³ sampl…⁴ sampl…⁵ sampl…⁶ sampl…⁷\n     <dbl>   <dbl> <chr>         <chr>   <chr>   <chr>     <int>   <int>   <int>\n1  0.242   -0.0992 S2S           North   North2S NBS           0     890   25480\n2 -0.403   -0.130  S2B           North   North2B NBF          59     890   25480\n3 -0.455   -0.0922 S3B           North   North3B NBF          74     835   13340\n4 -0.471    0.0176 S3S           North   North3S NBS           0     715   26725\n5  0.00454  0.407  S5S           North   North5S NBS           0    1620   56555\n6  0.102    0.327  S5B           North   North5B NBF          42    1620   55780\n# … with 15 more variables: sample.Prochloro <int>, sample.NanoEuk <int>,\n#   sample.Crypto <int>, sample.SiOH4 <dbl>, sample.NO2 <dbl>,\n#   sample.NO3 <dbl>, sample.NH4 <dbl>, sample.PO4 <dbl>, sample.NT <dbl>,\n#   sample.PT <dbl>, sample.Chla <dbl>, sample.T <dbl>, sample.S <dbl>,\n#   sample.Sigma_t <dbl>, color <chr>, and abbreviated variable names\n#   ¹​sample.SampName, ²​sample.Geo, ³​sample.Description, ⁴​sample.groupe,\n#   ⁵​sample.Pres, ⁶​sample.PicoEuk, ⁷​sample.Synec\n# ℹ Use `colnames()` to see all variable names\n\n\nNow that we prepared the data, lets plot the PCoA.\n\nggplot(data = hull, aes(x = Axis.1, y = Axis.2)) +\n  geom_hline(yintercept = 0, colour = \"lightgrey\", linetype = 2) +\n  geom_vline(xintercept = 0, colour = \"lightgrey\", linetype = 2) +\n  geom_polygon(data = hull_data,\n               aes(group = sample.Geo,\n                   fill = sample.Geo),\n               alpha = 0.3) + # add the convex hulls)\n  scale_fill_manual(values = c(\"Darkgrey\", \"#1919ff\")) +\n  geom_point(data = hull,\n             aes(color = sample.Geo,\n                 size = sample.S),\n             alpha = 0.7) +\n  scale_color_manual(values = c(\"Darkgrey\", \"#1919ff\")) +\n  xlab(paste(\"PCo1 (\", round(pcoa_asv$values$Relative_eig[1]*100, 1), \"%)\")) +\n  ylab(paste(\"PCo2 (\", round(pcoa_asv$values$Relative_eig[2]*100, 1), \"%)\")) +\n  theme_bw() +\n  coord_equal() +\n  theme(axis.title.x = element_text(size = 14), # remove x-axis labels\n        axis.title.y = element_text(size = 14), # remove y-axis labels\n        panel.background = element_blank(), \n        panel.grid.major = element_blank(),  #remove major-grid labels\n        panel.grid.minor = element_blank(),  #remove minor-grid labels\n        plot.background = element_blank())\n\n\n\n\nThe ordination of the samples in the PCoA is very similar to the one observed in the PCA with a clear segregation of North and South bacterial communities. This segregation may result from the increasing salinity gradient from North to South but it relaims to be tested.\nDo you see what is missing?\nIndeed, there are no species plotted on this ordination. That’s because we used a dissimilarity matrix (sites x sites) as input for the PCoA function. Hence, no species scores could be calculated. However, we could work around this problem with the function biplot.pcoa() from the ape package.\nPCoA suffers from a number of flaws, in particular the arch effect (see PCA for more information). These flaws stem, in part, from the fact that PCoA maximizes a linear correlation. Non-metric Multidimensional Scaling (NMDS) rectifies this by maximizing the rank order correlation."
  },
  {
    "objectID": "practicals/beta_diversity.html#non-metric-multidimensional-scaling-nmds",
    "href": "practicals/beta_diversity.html#non-metric-multidimensional-scaling-nmds",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "6.3 Non Metric Multidimensional Scaling (NMDS)",
    "text": "6.3 Non Metric Multidimensional Scaling (NMDS)\nNMDS attempts to represent the pairwise dissimilarity between objects in a low-dimensional space. Any dissimilarity coefficient or distance measure may be used to build the distance matrix used as input. NMDS is a rank-based approach. This means that the original distance data is substituted with ranks. While information about the magnitude of distances is lost, rank-based methods are generally more robust to data which do not have an identifiable distribution.\nNMDS is an iterative algorithm. NMDS routines often begin by random placement of data objects in ordination space. The algorithm then begins to refine this placement by an iterative process, attempting to find an ordination in which ordinated object distances closely match the order of object dissimilarities in the original distance matrix. The stress value reflects how well the ordination summarizes the observed distances among the samples.\nNMDS is not an eigenanalysis. This has three important consequences:\n\nThere is no unique ordination result\nThe axes of the ordination are not ordered according to the variance they explain\nThe number of dimensions of the low-dimensional space must be specified before running the analysis\n\nAxes are not ordered in NMDS. vegan::metaMDS() automatically rotates the final result of the NMDS using PCA to make axis 1 correspond to the greatest variance among the NMDS sample points.\n\n#NMDS plot on Aitchison distance\nphyseq_clr_nmds <- vegan::metaMDS(physeq_clr_dist, k=2, trymax=100) #Aitchison distance\n\nA useful way to assess the appropriateness of an NMDS result is to compare, in a Shepard diagram, the distances among objects in the ordination plot with the original distances.\n\nvegan::stressplot(physeq_clr_nmds)\n\n\n\n\nThere is a good non-metric fit between observed dissimilarities (in our distance matrix) and the distances in ordination space. Also the stress of our final result was good.\ndo you know how much the stress is?\nThe stress value can be used as an indicator of the goodness-of-fit. Stress values >0.2 are generally poor and potentially not interpretable, whereas values <0.1 are good and <0.05 are excellent, leaving little danger of misinterpretation.\nSo we can go further and plot the results:\n\nnmds_coord <- data.frame(physeq_clr_nmds$points)\n\n#Data frame for hull\nhull <- data.frame(\"Axis.1\" = nmds_coord[,1],\n                   \"Axis.2\" = nmds_coord[,2],\n                   \"sample\" = as.data.frame(sample_data(physeq_clr@sam_data)))\n\n# North <- hull[hull$sample.Geo  == \"North\", ][chull(hull[hull$sample.Geo == \n#                                                                 \"North\", c(\"Axis.1\", \"Axis.2\")]), ]  # hull values for North\n# South <- hull[hull$sample.Geo == \"South\", ][chull(hull[hull$sample.Geo == \n#                                                                \"South\", c(\"Axis.1\", \"Axis.2\")]), ]  # hull values for Jellyfishes  \n\n# hull_data <- rbind(North, South)\n\n# #Vector of color for hulls\n# color <- rep(\"#a65628\", length(hull_data$sample.Geo))\n# color[hull_data$sample.Geo == \"North\"] <- \"#1919ff\"\n# hull_data <- cbind(hull_data, color)\n\nhull_col <- c(\"#a65628\",\"#1919ff\")\nnames(hull_col) <- c(\"North\",\"South\")\n\nhull_data <- hull %>%\n  dplyr::group_by(sample.Geo) %>%\n  dplyr::slice(chull(Axis.1,Axis.2)) %>%\n  dplyr::mutate(color = hull_col[sample.Geo])\n\n#pdf(file=\"NMDS_Aitchison.pdf\", wi = 7, he = 7)\nggplot(hull,aes(x = Axis.1, y = Axis.2)) +\n  geom_hline(yintercept = 0, colour = \"lightgrey\", linetype = 2) + \n  geom_vline(xintercept = 0, colour = \"lightgrey\", linetype = 2) +\n  geom_polygon(data = hull_data,\n               aes(group = sample.Geo,\n                   fill = sample.Geo),\n               alpha = 0.3) + # add the convex hulls)\n  scale_fill_manual(values = c(\"Darkgrey\", \"#1919ff\")) +\n  geom_point(data = hull,\n             aes(color = sample.Geo,\n                 size = sample.S),\n             alpha = 0.7) +\n  scale_color_manual(values = c(\"Darkgrey\", \"#1919ff\")) +\n  geom_text(data = hull_data,\n            x = -0, y = -9,\n            label = paste(\"Stress =\", round(physeq_clr_nmds$stress, 2)),\n            colour = \"Black\",\n            size = 5)  +\n  xlab(paste(\"MDS1\")) +\n  ylab(paste(\"MDS2\")) +\n  theme_bw() +\n  coord_equal() +\n  theme(axis.title.x = element_text(size=14), # remove x-axis labels\n        axis.title.y = element_text(size=14), # remove y-axis labels\n        panel.background = element_blank(), \n        panel.grid.major = element_blank(),  #remove major-grid labels\n        panel.grid.minor = element_blank(),  #remove minor-grid labels\n        plot.background = element_blank())\n\n\n\n#dev.off()\n\nWe observe the same ordiantion pattern of the samples as in the PCA and PCoA. There are no species scores (same problem as we encountered with PCoA). We can work around this problem, by using the wascores function giving metaMDS the original community matrix as input and specifying the distance measure.\nThe next question is: Which environmental variable is driving the observed differences in species composition? Similarly to what we have done with PCA, we can correlate environmental variables with our ordination axes.\n\n# Correlation with environmental data\ndata.frame(names(hull))\n\n          names.hull.\n1              Axis.1\n2              Axis.2\n3     sample.SampName\n4          sample.Geo\n5  sample.Description\n6       sample.groupe\n7         sample.Pres\n8      sample.PicoEuk\n9        sample.Synec\n10   sample.Prochloro\n11     sample.NanoEuk\n12      sample.Crypto\n13       sample.SiOH4\n14         sample.NO2\n15         sample.NO3\n16         sample.NH4\n17         sample.PO4\n18          sample.NT\n19          sample.PT\n20        sample.Chla\n21           sample.T\n22           sample.S\n23     sample.Sigma_t\n\nenv <- hull[, 13:23]\n\n# The function envfit will add the environmental variables as vectors to the ordination plot\nef <- vegan::envfit(physeq_clr_nmds, env, permu = 1000)\nef\n\n\n***VECTORS\n\n                  NMDS1    NMDS2     r2   Pr(>r)    \nsample.SiOH4   -0.95409 -0.29952 0.2717 0.108891    \nsample.NO2     -0.44259 -0.89672 0.3271 0.050949 .  \nsample.NO3      0.94086  0.33880 0.2986 0.072927 .  \nsample.NH4     -0.48808 -0.87280 0.4484 0.007992 ** \nsample.PO4     -0.67399 -0.73874 0.2498 0.107892    \nsample.NT       0.02371 -0.99972 0.0526 0.678322    \nsample.PT      -0.61901 -0.78539 0.3745 0.046953 *  \nsample.Chla    -0.96843 -0.24930 0.2016 0.212787    \nsample.T       -0.87263 -0.48838 0.3250 0.050949 .  \nsample.S       -0.93218 -0.36198 0.7607 0.000999 ***\nsample.Sigma_t -0.96163 -0.27436 0.2116 0.176823    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nPermutation: free\nNumber of permutations: 1000\n\n# The two last columns are of interest: the squared correlation coefficient and the associated p-value\n# Plot the vectors of the significant correlations and interpret the plot\nplot(physeq_clr_nmds, type = \"t\", display = \"sites\")\nplot(ef, p.max = 0.05)\n\n\n\n\nHere again, we can see that the salinity is strongly correlated with the first axis separating samples from the South and the North. To a lesser extent, new environmental variables related with the trophic conditions of the habitat (NH4 and PT) were correlated with the second axis of the NMDS. The detection of these new relations between microbial communities and the environment may be related to the fact that NMDS is best suited to detect the non linear response of microbes to environmental gradients.\nMany different types of indirect gradient analysis are available outthere. In the following graph, we offer suggestions of some of the appropriate choices based on data input structure and expected relationships among variables."
  },
  {
    "objectID": "practicals/beta_diversity.html#permutational-multiple-analysis-of-variance-permanova",
    "href": "practicals/beta_diversity.html#permutational-multiple-analysis-of-variance-permanova",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "7.1 PERmutational Multiple ANalysis Of VAriance (PERMANOVA)",
    "text": "7.1 PERmutational Multiple ANalysis Of VAriance (PERMANOVA)\nPERMANOVA was proposed by Anderson and McArdle to apply the powerful ANOVA to multivariate ecological datasets. PERMANOVA is one of most widely used nonparametric methods to fit multivariate models to microbiome data. It is a multivariate analysis of variance based on distance matrices and permutation. It does this by partitioning the sums of squares for the within- and between-cluster components using the concept of centroids. Many permutations of the data (i.e. random shuffling) are used to generate the null distribution. Find more informations on PERMANOVA here and on the adonis2() function here Now let us evaluate whether the group (North vs. South) has a significant effect on overall bacterial community composition.\n\n#PERMANOVA\nmetadata <- data.frame(sample_data(physeq_clr))\nresults_permanova <- vegan::adonis2(physeq_clr_dist ~ Geo,\n                                    data = metadata,\n                                    perm = 1000)\nresults_permanova\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ Geo, data = metadata, permutations = 1000)\n         Df SumOfSqs      R2      F   Pr(>F)   \nGeo       1   1135.5 0.20329 4.0825 0.001998 **\nResidual 16   4450.1 0.79671                   \nTotal    17   5585.6 1.00000                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere we can see that the North/South grouping explain significantly (p < 0.001) 20% of the variance in the ASV Aitchison matrix. In other words Nothern and Southern bacterial differ significatively in their bacterial composition. The test from ADONIS can be confounded by differences in dispersion (or spread) so we want to check this as well..\n\n# Testing the assumption of similar multivariate spread among the groups (ie. analogous to variance homogeneity)\nanova(vegan::betadisper(physeq_clr_dist, metadata$Geo))\n\nAnalysis of Variance Table\n\nResponse: Distances\n          Df Sum Sq Mean Sq F value   Pr(>F)   \nGroups     1 49.657  49.657  13.915 0.001822 **\nResiduals 16 57.096   3.569                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere the groups have significant different spreads and permanova result may be impacted by that although PERMANOVA is very robust to difference in group dispersion. We can also check which taxa contribute most to the community differences using the ancient adonis() function and the ASV table of CLR transformed counts.\n\n#Show coefficients for the top taxa separating the groups\n\npermanova <- vegan::adonis(t(physeq_clr_asv) ~ Geo,\n                            data = metadata,\n                            permutations = 1000,\n                            method = \"euclidean\")\n\ncoef <- coefficients(permanova)[\"Geo1\",]\n\ntop.coef <- coef[rev(order(abs(coef)))[1:10]]\n\npar(mar = c(3, 14, 2, 1))\n\nbarplot(sort(top.coef),\n        horiz = TRUE,\n        las = 1,\n        main = \"Top taxa\",\n        cex.names = 0.7)\n\n\n\n\nAre these ASVs the same or different compared to ASV contributing the most to PC axes?\nadonis() and adonis2() allow us to explore the effect of categorical or continuous variables.\nNB: An important difference between adonis et adonis2: in adonis terms are tested sequentially and this is the only option. This means that the order you enter your variables is important (if design is unbalanced). This is because the first explanatory variable is added to the model. Then the next one is added to see if it explains significantly more variation not explained by the previous variables. This is equivalent to using by=“terms” in adonis2. If you don’t want the order to matter you can use adonis2 with by=“margin”, or if you want to check if the model as a whole is significant you can use by=NULL. Order does not matter when by=“margin” because the significance is tested against a model that includes all other variables not just the ones preceding it in the formula.\n\n#Permanova on continuous variables\npermanova_S <- vegan::adonis2(physeq_clr_dist ~ S,\n                              data = metadata,\n                              perm = 1000)\npermanova_S\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ S, data = metadata, permutations = 1000)\n         Df SumOfSqs      R2      F   Pr(>F)    \nS         1   1294.1 0.23168 4.8247 0.000999 ***\nResidual 16   4291.5 0.76832                    \nTotal    17   5585.6 1.00000                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npermanova_NH4 <- vegan::adonis2(physeq_clr_dist ~ NH4,\n                                data = metadata,\n                                perm = 1000)\npermanova_NH4\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ NH4, data = metadata, permutations = 1000)\n         Df SumOfSqs      R2      F  Pr(>F)  \nNH4       1    769.8 0.13782 2.5575 0.01099 *\nResidual 16   4815.8 0.86218                 \nTotal    17   5585.6 1.00000                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\npermanova_PT <- vegan::adonis2(physeq_clr_dist ~ PT,\n                               data = metadata,\n                               perm = 1000)\npermanova_PT\n\nPermutation test for adonis under reduced model\nTerms added sequentially (first to last)\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ PT, data = metadata, permutations = 1000)\n         Df SumOfSqs      R2      F  Pr(>F)  \nPT        1    697.3 0.12483 2.2822 0.01499 *\nResidual 16   4888.3 0.87517                 \nTotal    17   5585.6 1.00000                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe result confirm that salinity and to a lesser extent NH4 and PT are important factors shaping microbial communities but what about the other variables? Lets construct a model with all the co-variables.\n\n#Inspecting co-variables\npermanova_all <- vegan::adonis2(physeq_clr_dist ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t,\n                                by=\"margin\",\n                                data=metadata,\n                                perm=1000)\n\npermanova_all\n\nPermutation test for adonis under reduced model\nMarginal effects of terms\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t, data = metadata, permutations = 1000, by = \"margin\")\n         Df SumOfSqs      R2      F Pr(>F)\nSiOH4     1    291.5 0.05219 1.0594 0.3247\nNO2       1    243.4 0.04357 0.8846 0.5255\nNO3       1    239.8 0.04293 0.8715 0.5614\nNH4       1    253.2 0.04533 0.9203 0.4575\nPO4       1    232.7 0.04165 0.8456 0.5564\nNT        1    234.6 0.04200 0.8527 0.5654\nPT        1    234.9 0.04206 0.8539 0.5794\nChla      1    200.8 0.03594 0.7296 0.7702\nT         1    285.9 0.05118 1.0390 0.3546\nS         1    286.2 0.05124 1.0402 0.3586\nSigma_t   1    285.3 0.05108 1.0370 0.3536\nResidual  6   1650.8 0.29555              \nTotal    17   5585.6 1.00000              \n\n\nWhat happened? Why none of the variables has no significant effect any more ?\nThe temptation to build an ecological model using all available information (i.e., all variables) is hard to resist. Lots of time and money are exhausted gathering data and supporting information. We also hope to identify every significant variable to more accurately characterize relationships with biological relevance. Collinearity, or excessive correlation among explanatory variables, can complicate or prevent the identification of an optimal set of explanatory variables for a statistical model. Let’s take a look at which explanatory variables are correlated.\n\n# inpecting autocorrélation\n# compute the correlation matrix\ncor_metadadata <- cor(metadata[, 11:21], method = \"spearman\")\n\ncor_mtest <- function(mat, ...) {\n  mat <- as.matrix(mat)\n  n <- ncol(mat)\n  p_mat <- matrix(NA, n, n)\n  diag(p_mat) <- 0\n  for (i in 1:(n - 1)) {\n    for (j in (i + 1):n) {\n      tmp <- cor.test(mat[, i], mat[, j], method = \"spearman\", ...)\n      p_mat[i, j] <- p_mat[j, i] <- tmp$p.value\n    }\n  }\n  colnames(p_mat) <- rownames(p_mat) <- colnames(mat)\n  p_mat\n}\n\n# matrix of the p-value of the correlation\np_mat <- cor_mtest(metadata[, 11:21])\n\n# Leave blank on no significant coefficient\ncorrplot::corrplot(cor_metadadata,\n                   type = \"upper\",\n                   order = \"hclust\",\n                   p.mat = p_mat,\n                   sig.level = 0.05,\n                   insig = \"blank\")\n\n\n\n\nWe can see that many explanatory variables are correlated. Lets remove some of them. We’ll keep S as a proxy of PO4, Sigma-t, NH4 and NO2. NO3 as a proxy of SiOH4. Chla as a proxy of PT.\n\npermanova_cor_pars <- vegan::adonis2(physeq_clr_dist ~ S + NO3 + NT + Chla + T,\n                                     by = \"margin\",\n                                     data = metadata,\n                                     perm = 1000)\npermanova_cor_pars\n\nPermutation test for adonis under reduced model\nMarginal effects of terms\nPermutation: free\nNumber of permutations: 1000\n\nvegan::adonis2(formula = physeq_clr_dist ~ S + NO3 + NT + Chla + T, data = metadata, permutations = 1000, by = \"margin\")\n         Df SumOfSqs      R2      F  Pr(>F)  \nS         1    568.2 0.10173 2.0376 0.03397 *\nNO3       1    215.5 0.03858 0.7727 0.71229  \nNT        1    263.4 0.04716 0.9446 0.43157  \nChla      1    170.9 0.03060 0.6129 0.93506  \nT         1    304.5 0.05452 1.0921 0.29471  \nResidual 12   3346.3 0.59910                 \nTotal    17   5585.6 1.00000                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe updated PERMANOVA model is improved over the original. We see that salinity is again significantly related to the response variable. However, the model with only salinity is even much better. The take home message is that true relationships among variables will be masked if explanatory variables are collinear. This creates problems in model creation which lead to complications in model inference. Taking the extra time to evaluate collinearity is a critical first step to creating more robust ecological models."
  },
  {
    "objectID": "practicals/beta_diversity.html#analysis-of-similarity-anosim",
    "href": "practicals/beta_diversity.html#analysis-of-similarity-anosim",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "7.2 ANalysis Of SIMilarity (ANOSIM)",
    "text": "7.2 ANalysis Of SIMilarity (ANOSIM)\nANOSIM tests for significant difference between two or more classes of objects based on any (dis)similarity measure (Clarke 1993). It compares the ranks of distances between objects of different classes with ranks of object distances within classes. The basis of this approach is similar to the NMDS ordination technique described above.\n\n#ANOSIM\nvegan::anosim(physeq_clr_dist, metadata$Geo, permutations = 1000)\n\n\nCall:\nvegan::anosim(x = physeq_clr_dist, grouping = metadata$Geo, permutations = 1000) \nDissimilarity: euclidean \n\nANOSIM statistic R: 0.5628 \n      Significance: 0.001998 \n\nPermutation: free\nNumber of permutations: 1000\n\n\nSimilarly to PERMANOVA, the result of ANOSIM indicates a significant effect of the Norther or Southern origin of the sample on bacterial communities.\nA more formal approach to hypotheses testing can be done using redundancy analysis or canonical correspondence analysis that directly uses information on metadata fields when generating the ordinations and conducting testing. These approaches directly test hypotheses about environmental variables."
  },
  {
    "objectID": "practicals/beta_diversity.html#redundant-analysis-rda",
    "href": "practicals/beta_diversity.html#redundant-analysis-rda",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "8.1 Redundant analysis (RDA)",
    "text": "8.1 Redundant analysis (RDA)\n\n8.1.1 Running the RDA\nRDA is a method combining regression and principal component analysis (PCA). RDA computes axes that are linear combinations of the explanatory variables. In RDA, one can truly say that the axes explain or model (in the statistical sense) the variation of the dependent matrix.\n\n# RDA of the Aitchinson distance\n# constrained by all the environmental variables\n# contained in metadata\n#\n# Observe the shortcut formula\nspe_rda <- vegan::rda(t(physeq_clr_asv) ~ .,\n                      metadata[, 11:21])\nhead(summary(spe_rda))  # Scaling 2 (default)\n\n\nCall:\nrda(formula = t(physeq_clr_asv) ~ SiOH4 + NO2 + NO3 + NH4 + PO4 +      NT + PT + Chla + T + S + Sigma_t, data = metadata[, 11:21]) \n\nPartitioning of variance:\n              Inertia Proportion\nTotal          328.56     1.0000\nConstrained    231.46     0.7044\nUnconstrained   97.11     0.2956\n\nEigenvalues, and their contribution to the variance \n\nImportance of components:\n                         RDA1     RDA2     RDA3     RDA4     RDA5     RDA6\nEigenvalue            85.2928 30.29173 20.29415 18.85659 15.83909 12.98651\nProportion Explained   0.2596  0.09219  0.06177  0.05739  0.04821  0.03952\nCumulative Proportion  0.2596  0.35179  0.41355  0.47094  0.51915  0.55868\n                          RDA7     RDA8     RDA9   RDA10   RDA11      PC1\nEigenvalue            11.78027 10.97738 10.18119 7.94385 7.01222 28.88564\nProportion Explained   0.03585  0.03341  0.03099 0.02418 0.02134  0.08791\nCumulative Proportion  0.59453  0.62794  0.65893 0.68310 0.70445  0.79236\n                           PC2     PC3      PC4      PC5     PC6\nEigenvalue            16.45693 16.3958 15.58129 11.19715 8.59184\nProportion Explained   0.05009  0.0499  0.04742  0.03408 0.02615\nCumulative Proportion  0.84245  0.8923  0.93977  0.97385 1.00000\n\nAccumulated constrained eigenvalues\nImportance of components:\n                         RDA1    RDA2     RDA3     RDA4     RDA5     RDA6\nEigenvalue            85.2928 30.2917 20.29415 18.85659 15.83909 12.98651\nProportion Explained   0.3685  0.1309  0.08768  0.08147  0.06843  0.05611\nCumulative Proportion  0.3685  0.4994  0.58706  0.66853  0.73696  0.79307\n                         RDA7     RDA8     RDA9   RDA10  RDA11\nEigenvalue            11.7803 10.97738 10.18119 7.94385 7.0122\nProportion Explained   0.0509  0.04743  0.04399 0.03432 0.0303\nCumulative Proportion  0.8440  0.89139  0.93538 0.96970 1.0000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n* General scaling constant of scores:  8.645047 \n\n\nSpecies scores\n\n                                                 RDA1      RDA2     RDA3\nASV1_Cyanobiaceae_Synechococcus CC9902        -0.1033  0.108773  0.04666\nASV2_Pseudoalteromonadaceae_Pseudoalteromonas -0.7807 -0.229145 -0.22860\nASV3_Clade I_Clade Ia                         -0.2568  0.002182 -0.22536\nASV4_NA_NA                                    -0.6996  0.193071  0.23547\nASV5_Clade I_Clade Ia                          0.5264 -0.195773  0.23032\nASV6_Clade II_NA                              -0.2542 -0.344583 -0.32380\n....                                                                    \n                                                  RDA4     RDA5     RDA6\nASV1_Cyanobiaceae_Synechococcus CC9902        -0.12535 -0.01552 -0.06487\nASV2_Pseudoalteromonadaceae_Pseudoalteromonas  0.33352  0.13369 -0.08880\nASV3_Clade I_Clade Ia                         -0.04191 -0.04528  0.11436\nASV4_NA_NA                                     0.20648 -0.23531 -0.06807\nASV5_Clade I_Clade Ia                         -0.05792  0.40196  0.22286\nASV6_Clade II_NA                              -0.31352 -0.10920  0.06137\n....                                                                    \n\n\nSite scores (weighted sums of species scores)\n\n       RDA1     RDA2    RDA3    RDA4     RDA5    RDA6\nS11B -1.703 -1.23820  2.9437 -0.2362  1.13728  0.4405\nS1B   2.565 -0.13340 -0.7868 -5.7453  3.30268  3.3657\nS2B   3.022 -2.96571  0.4021 -0.9802 -3.09213 -0.9282\nS2S  -1.731 -1.82618  2.0707 -0.3281 -0.66853  1.6638\nS3B   3.624 -1.55655 -1.2829 -2.0701 -2.02586 -1.7347\nS3S   3.165 -0.08923  2.8998  2.0441 -0.08464 -2.0314\n....                                                 \n\n\nSite constraints (linear combinations of constraining variables)\n\n        RDA1    RDA2    RDA3    RDA4    RDA5    RDA6\nS11B -1.2105 -0.7764  3.0649 -0.2199  1.2569 -0.7586\nS1B   1.7387  0.3983 -0.3817 -5.4943  3.2411  2.7484\nS2B   2.0536 -3.3237  0.6260 -1.4897 -2.8936 -0.1774\nS2S   0.5936 -2.0609  1.1588 -0.1736 -0.8183  1.8069\nS3B   4.1498 -1.1569 -1.6837 -1.1942 -2.4216 -2.5295\nS3S   2.0704 -0.1285  3.6947  1.1733  0.3885 -1.8438\n....                                                \n\n\nBiplot scores for constraining variables\n\n            RDA1     RDA2     RDA3     RDA4     RDA5      RDA6\nSiOH4   -0.57424 -0.21106 -0.25450  0.25678 -0.02349  0.213981\nNO2     -0.51463 -0.10086 -0.08171 -0.34294  0.35340 -0.013696\nNO3      0.59878  0.05632 -0.04267  0.02065 -0.30772 -0.095439\nNH4     -0.63097 -0.49073 -0.01146  0.07457  0.25646 -0.259440\nPO4     -0.49369 -0.05367 -0.31521 -0.04459  0.19877 -0.304690\nNT       0.02778 -0.05873 -0.28198 -0.59590  0.14825  0.392684\nPT      -0.61634 -0.27995 -0.01129 -0.12013  0.07328  0.533916\nChla    -0.47936 -0.07832 -0.06090  0.01293 -0.11376 -0.179421\nT       -0.57485  0.21879  0.26190 -0.53662 -0.42902 -0.007286\nS       -0.93622  0.00815 -0.06712 -0.05543  0.04078 -0.183950\nSigma_t -0.52380 -0.20293 -0.31121  0.40702  0.43162 -0.205711\n\n\nThe included environmental variables explain 70.44% of the variation in bacterial community composition across sites. 29.56 % of the variance is unexplained. However, we’ll see that the propotion of variance explained is much lower. The R2 from the summary measures the strength of the canonical relationship between the response variables (Y matrix, ASVs) and the explanatory variables (X matrix) by calculating the proportion of the variation of Y explained by the variables in X. However, this R2 is biased. We calculate an Adjusted R2, which also measures the strength of the relationship between Y and X, but applies a correction of the R2 to take into account the number of explanatory variables. This is the statistic that should be reported.\n\n# Unadjusted R^2 retrieved from the rda object\nR2 <- vegan::RsquareAdj(spe_rda)$r.squared\nR2\n\n[1] 0.7044457\n\n# Adjusted R^2 retrieved from the rda object\nR2adj <- vegan::RsquareAdj(spe_rda)$adj.r.squared\nR2adj\n\n[1] 0.1625961\n\n\nIn reality, the proportion of variance explained dropped to 16.25 %. The numerical output shows that the first two canonical axes explain together 35.1% of the total variance of the data, the first axis alone explaining 25.9%. These are unadjusted values, however. Since R2 adj = 16.2 %, the percentages of accumulated constrained adj eigenvalues show that the first axis alone explains 0.162 * 0.368 = 0.059 or 5.9% variance. Because ecological data are generally quite noisy, one should never expect to obtain a very high value of R2 . Furthermore, the first unconstrained eigenvalue (PC1), the first unconstrained axe for the residuals, is comparatively high, which means that it does display an important residual structure of the response data that is not explain by the environmental parameters measure here.\n\n\n8.1.2 Significance testing\nThe interpretation of the constrained ordination must be preceded by a test of statistical significance (see below). As in multiple regression, a non-significant result must not be interpreted and must be discarded.\n\n# Global test of the RDA result\nanova(spe_rda, step = 1000)\n\nPermutation test for rda under reduced model\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = t(physeq_clr_asv) ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t, data = metadata[, 11:21])\n         Df Variance      F Pr(>F)  \nModel    11  231.456 1.3001  0.095 .\nResidual  6   97.109                \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Tests of all canonical axes\nanova(spe_rda, by = \"axis\", step = 1000)\n\nPermutation test for rda under reduced model\nForward tests for axes\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = t(physeq_clr_asv) ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t, data = metadata[, 11:21])\n         Df Variance      F Pr(>F)\nRDA1      1   85.293 5.2699  0.134\nRDA2      1   30.292 1.8716  0.594\nRDA3      1   20.294 1.2539  0.998\nRDA4      1   18.857 1.1651  0.998\nRDA5      1   15.839 0.9786  1.000\nRDA6      1   12.987 0.8024  1.000\nRDA7      1   11.780 0.7279  1.000\nRDA8      1   10.977 0.6783  1.000\nRDA9      1   10.181 0.6291  1.000\nRDA10     1    7.944 0.4908  0.988\nRDA11     1    7.012 0.4333  0.897\nResidual  6   97.109              \n\n\nHere we can see that ur full model is statistically non significant (p = 0.08), and every canonical axis resulting from the RDA are not either statistically significant (p > 0.05). This RDA model is not interpretable.\nCan you tell why?\n\n\n8.1.3 Selecting variables\nIt happens sometimes that one wishes to reduce the number of explanatory variables. The reasons vary: search for parsimony, rich data set but poor a priori hypotheses and possible strong linear dependencies (correlations) among the explanatory variables in the RDA model, which could render the regression coefficients of the explanatory variables in the model unstable.\nA simple approach to identify collinearity among explanatory variables is the use of variance inflation factors (VIF). VIF calculations are straightforward and easily comprehensible; the higher the value, the higher the collinearity. VIF measure the proportion by which the variance of a regression coefficient is inflated in the presence of other explanatory variables. VIFs above 20 indicate strong collinearity. Ideally, VIFs above 10 should be at least examined, and avoided if possible.\n\n# Variance inflation factors (VIF)\nvegan::vif.cca(spe_rda)\n\n      SiOH4         NO2         NO3         NH4         PO4          NT \n   4.066588    3.489186    3.634643   16.867288    8.819736    4.908553 \n         PT        Chla           T           S     Sigma_t \n   6.835572    2.264012 5417.455601 8388.550079 6878.896122 \n\n\nSalinity, Temperature and Sigma.t have very hight VIFs wich confirm the collinearities observed earlier between explanatory variables (see the PERMANOVA section). A reduction of the number of explanatory variables is justified. In order to simplify this model, we can perform a forward selection (or backwards or stepwise). These types of selections help us select variables that are statistically important. However, it is important to note that selecting variables ecologically is much more important than performing selection in this way. If a variable of ecological interest is not selected, this does not mean it has to be removed from the RDA. Here, we will be performing forward selection on our 11 environmental variables. To do this, we can use the ordiR2step() function:\n\n# Forward selection of explanatory variables using vegan's ordiR2step()\nstep_forward <- vegan::ordiR2step(vegan::rda(t(physeq_clr_asv) ~ 1,\n                                             data = metadata[, 11:21]),\n                                  scope = formula(spe_rda),\n                                  direction = \"forward\",\n                                  pstep = 1000)\n\nStep: R2.adj= 0 \nCall: t(physeq_clr_asv) ~ 1 \n \n                R2.adjusted\n+ S              0.18366030\n<All variables>  0.16259613\n+ NH4            0.08392874\n+ PT             0.07013415\n+ T              0.06719602\n+ NO3            0.05904665\n+ SiOH4          0.05787026\n+ Sigma_t        0.05002017\n+ NO2            0.03846019\n+ PO4            0.03190148\n+ Chla           0.02451726\n<none>           0.00000000\n+ NT            -0.01448677\n\n\nHere, we are essentially adding one variable at a time, and retaining it if it significantly increases the model’s adjusted R2. The forward selection show us that a model with only salinity has higher R2 adjust than with all variable and explain 18.4 % of the variance. Lets calculate this most parsimonious RDA and check its significance.\n\n# Parsimonious RDA\nspe_rda_pars <- vegan::rda(t(physeq_clr_asv) ~ S, data = metadata[, 11:21])\nanova(spe_rda_pars, step = 1000)\n\nPermutation test for rda under reduced model\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = t(physeq_clr_asv) ~ S, data = metadata[, 11:21])\n         Df Variance      F Pr(>F)    \nModel     1   76.122 4.8247  0.001 ***\nResidual 16  252.443                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(spe_rda_pars, step = 1000, by = \"axis\")\n\nPermutation test for rda under reduced model\nForward tests for axes\nPermutation: free\nNumber of permutations: 999\n\nModel: rda(formula = t(physeq_clr_asv) ~ S, data = metadata[, 11:21])\n         Df Variance      F Pr(>F)   \nRDA1      1   76.122 4.8247  0.002 **\nResidual 16  252.443                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR2adj_pars <- vegan::RsquareAdj(spe_rda_pars)$adj.r.squared\n\n# Compare variance inflation factors\nvegan::vif.cca(spe_rda)\n\n      SiOH4         NO2         NO3         NH4         PO4          NT \n   4.066588    3.489186    3.634643   16.867288    8.819736    4.908553 \n         PT        Chla           T           S     Sigma_t \n   6.835572    2.264012 5417.455601 8388.550079 6878.896122 \n\nvegan::vif.cca(spe_rda_pars)\n\nS \n1 \n\n\nNow, both the model and the first canonical axis resulting from the RDA are statistically significant (p < 0.05). The VIF of salinity is only 1. This RDA model is interpretable. Lets plot it.\n\n\n8.1.4 RDA plot\n\n# Preparation of the data for the plot\n#\n# View analysis results\nii <- summary(spe_rda_pars)\n\n# Depending on the drawing result\n# the drawing data can be enlarged or\n# reduced to a certain extent, as follows\nsp <- as.data.frame(ii$species[, 1:2]) * 2\nsp_top <- sp[order(abs(sp$RDA1), decreasing = TRUE), ][1:6, ]\n\nst <- as.data.frame(ii$sites[, 1:2])\nst <- merge(st,\n      metadata[\"Geo\"],\n      by = \"row.names\")\n\nyz <- t(as.data.frame(ii$biplot[, 1:2]))\nrow.names(yz) <- \"Salinity\"\nyz <- as.data.frame(yz)\n\neigen_values <- format(100 *ii$cont[[1]][2,], digits=4)\n\n#plot\nggplot() +\n  geom_point(data = st, size = 4,\n             aes(x = RDA1, y = PC1,\n                 shape = Geo, fill = Geo)) +\n  scale_shape_manual(values = c(21:25)) +\n  geom_segment(data = sp_top,\n               arrow = arrow(angle = 22.5,\n                             length = unit(0.35, \"cm\"),\n                             type = \"closed\"),\n               linetype = 1, size = 0.6, colour = \"red\",\n               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +\n  ggrepel::geom_text_repel(data = sp_top,\n                           aes(x = RDA1, y = PC1, label = row.names(sp_top))) +\n  geom_segment(data = yz,\n               arrow = arrow(angle = 22.5,\n                             length = unit(0.35,\"cm\"),\n                             type = \"closed\"),\n               linetype = 1, size = 0.6, colour = \"blue\",\n               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +\n  ggrepel::geom_text_repel(data = yz, aes(RDA1, PC1, label=row.names(yz)))+\n  labs(x = paste(\"RDA 1 (\", eigen_values[1], \"%)\", sep = \"\"),\n       y = paste(\"PC 1 (\", eigen_values[2], \"%)\", sep = \"\"))+\n  geom_hline(yintercept = 0,linetype = 3,size = 1) + \n  geom_vline(xintercept = 0,linetype = 3,size = 1)+\n  guides(shape = guide_legend(title = NULL,\n         color = \"black\"),\n         fill = guide_legend(title = NULL))+\n  theme_bw() +\n  theme(panel.grid = element_blank())\n\n\n\n\nOne of the most powerful aspects of RDA is the simultaneous visualization of your response and explanatory variables (i.e. species and environmental variables). From this ordination, we can really say now that salinity is the main environmental driver measured shaping bacterial communities. Among all the ASVs, some are more related to this gradient of salinity. This is the case of ASV 12 and 11 for which abundance increase when salinity decreases and ASV 7 which presents the opposite pattern. These differential abundance patterns can be explored with many kind of analyses (see next chapter) but what is really powerful with RDA is that you highlight gradient relationships not a difference of abundance between two conditions. However, a large part of the variance in the bacterial community remains unexplained. Variance in species communities can be explained by deterministic processes such as species sorting (influence of the environment as we’ve seen here) but also by stochastic processes such as dispersal which depend, among other things, of the distance between communities. Since we have this information, lets take a look at a very common pattern in community ecology: the distance-decay pattern."
  },
  {
    "objectID": "practicals/beta_diversity.html#multiple-regression-on-dissimilarity-matrices-mrm",
    "href": "practicals/beta_diversity.html#multiple-regression-on-dissimilarity-matrices-mrm",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "8.2 Multiple Regression on dissimilarity Matrices (MRM)",
    "text": "8.2 Multiple Regression on dissimilarity Matrices (MRM)\nThe decay of assemblage similarity with spatial distance can be explained by alternative mechanisms: dispersal limitation and species sorting. To understand their relative contributions, we compare the decay in bacterial similarity with spatial distance and, independently, with environmental distance. You will find excellent articles on distance-decay relationship Here and here.\nA combination of Mantel correlation and multiple regression, multiple regression on distance matrices (MRM; Manly, 1986; Smouse et al., 1986; Legendre et al., 1994) allows a regression-type analysis of two or more (dis)similarity matrices, using permutations to determine the significance of the coefficients of determination. One matrix must contain (dis)similarities calculated from response data, such as OTU abundances, and the other matrices must contain (dis)similarities calculated from explanatory data (e.g. environmental parameters or space).\nFirst we calculate the spatial distance matrix. In order to calculate kilometric distance bewtween sampling points from geographic coordinates, we used the SpatialEpi package and the latlong2grid() function. Here, you will load the result of this function because there is a conflict with this package and the betapart package we use after.\n\n#library(SpatialEpi)\n#ANFcoord <- read.table(\"Location_coordinates.txt\", sep = \"\\t\", row.names = 1, header = T)\n#ANF_km <- latlong2grid(ANFcoord[,1:2])\n#rownames(ANF_km) <- rownames(ANFcoord)\n\nANF_km <- readRDS(here::here(\"data\",\"beta_diversity\",\"spatial_distance.rds\"))\nANF_km_dist <- dist(ANF_km)\n\nThen, The relationship between microbial pairwise similarity and spatial distance is assessed by fitting negative exponential function describing the decay in microbial similarity with spatial distance.\n\n#Calculate and add model to the plot\n\nANF_decay_exp <- betapart::decay.model(physeq_clr_dist/100,\n                                       ANF_km_dist,\n                                       y.type=\"dissim\",\n                                       model.type=\"exp\",\n                                       perm=100)\n\n#Plot Distance decay relationships\nplot(ANF_km_dist, physeq_clr_dist/100,\n     ylim=c(0, max(physeq_clr_dist/100)),\n     xlim=c(0, max(ANF_km_dist)),\n     xlab = \"Distance (km)\", ylab = \"Dissimilarity (CLR)\")\n\nbetapart::plot.decay(ANF_decay_exp, col = \"blue\",\n                     remove.dots = TRUE, add = TRUE)\n\nlegend(\"bottomright\",\n       paste(\"exp: (Beta =\", round(ANF_decay_exp$b.slope, 4),\n             \", Rsqr =\", round(ANF_decay_exp$pseudo.r.squared, 2),\n             \", p =\", round(ANF_decay_exp$p.value, 2)),\n       fill = \"blue\")\n\n\n\n\nThe negative exponential model significantly explained the decay in similarity with spatial distance (p < 0.01). But what is the contribution of dispersal and species sorting in this pattern? Lets find out by decomposing the variance between the spatial and the envirnomental matrices.\n\n#Variance partitioning\n#Microbiam matrix (response)\nphyseq_clr_dist_square <- phyloseq::distance(physeq_clr,\n                                             method = \"euclidean\",\n                                             diag = TRUE,\n                                             upper = TRUE)\n\n#Spatial matrix (explicative)\nANF_km_dist_square <- dist(ANF_km, diag = TRUE, upper = TRUE)\n\n#environmental matrix (explicative)\nenvdata <- dist(metadata[,11:21], diag = TRUE, upper = TRUE)\n\n\n#Multiple regressions on Matrices (MRM) - attention les colonnes et lignes des matrices doivent correspondrent (pas besoin d'avoir les mêmes noms)\n\necodist::MRM(physeq_clr_dist_square ~ envdata + ANF_km_dist_square, nperm=1000) # 0.366\n\n$coef\n                   physeq_clr_dist_square  pval\nInt                           19.45167946 0.917\nenvdata                        1.28567618 0.005\nANF_km_dist_square             0.01828172 0.002\n\n$r.squared\n      R2     pval \n0.366774 0.001000 \n\n$F.test\n       F   F.pval \n43.44112  0.00100 \n\necodist::MRM(physeq_clr_dist_square ~ envdata, nperm=1000) # 0.212\n\n$coef\n        physeq_clr_dist_square  pval\nInt                  21.042622 0.970\nenvdata               1.609333 0.003\n\n$r.squared\n       R2      pval \n0.2122659 0.0030000 \n\n$F.test\n       F   F.pval \n40.68905  0.00300 \n\necodist::MRM(physeq_clr_dist_square ~ ANF_km_dist_square, nperm=1000) # 0.238\n\n$coef\n                   physeq_clr_dist_square  pval\nInt                           22.34249373 0.371\nANF_km_dist_square             0.02210456 0.002\n\n$r.squared\n       R2      pval \n0.2384328 0.0020000 \n\n$F.test\n       F   F.pval \n47.27535  0.00200 \n\nmodEvA::varPart(A = 0.212, B = 0.238, AB = 0.366,\n                A.name = \"Environmental\",\n                B.name = \"Dispersal limitation\")\n\n\n\n\n                                                Proportion\nPure Environmental                                   0.128\nPure Dispersal limitation                            0.154\nPure Environmental_Dispersal limitation overlap      0.084\nUnexplained                                          0.634\n\n\nUsing multiple regression on distance matrices (MRM), spatial and environmental variables proved significant predictors of beta diversity and together explained 36.7 % of variation in dissimilarity of microbial communities. Variance partitioning was subsequently used to partition the variation into purely spatial, purely environmental and spatially-structured environmental components. With 15,4%, the amount of variation in dissimilarity explained by the purely spatial component was higher than the variation explained by the environmental component, indicating that dispersal is an important process shaping our communities.\nSimilarly to indirect gradient analyses, many different types of direct gradient analysis are available outthere. In the following graph, we offer suggestions of some of the appropriate choices based on data input structure and expected relationships among variables."
  },
  {
    "objectID": "practicals/beta_diversity.html#linear-discriminant-analysis-effect-size-lefse",
    "href": "practicals/beta_diversity.html#linear-discriminant-analysis-effect-size-lefse",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "9.1 Linear discriminant analysis Effect Size (LEFse)",
    "text": "9.1 Linear discriminant analysis Effect Size (LEFse)\nLEFSE has been developped by Segata et al. (2011). LEFse first use the non-parametric factorial Kruskal-Wallis (KW) sum-rank test to detect features with significant differential abundance with respect to the class of interest; biological consistency is subsequently investigated using a set of pairwise tests among subclasses using the (unpaired) Wilcoxon rank-sum test. As a last step, LEfSe uses LDA to estimate the effect size of each differentially abundant features.\n\n#LEFSE\nmm_lefse <- microbiomeMarker::run_lefse(physeq, norm = \"CPM\",\n                                        wilcoxon_cutoff = 0.01,\n                                        group = \"Geo\",\n                                        taxa_rank = \"none\",\n                                        kw_cutoff = 0.01,\n                                        multigrp_strat = TRUE,\n                                        lda_cutoff = 4)\n\nmm_lefse_table <- data.frame(mm_lefse@marker_table)\nmm_lefse_table\n\n         feature enrich_group   ef_lda       pvalue         padj\nmarker1    ASV11        North 4.722043 0.0015574784 0.0015574784\nmarker2    ASV12        North 4.698873 0.0045142882 0.0045142882\nmarker3    ASV10        North 4.656438 0.0022950748 0.0022950748\nmarker4    ASV18        North 4.436870 0.0045142882 0.0045142882\nmarker5    ASV35        North 4.188888 0.0045142882 0.0045142882\nmarker6    ASV49        North 4.005158 0.0045142882 0.0045142882\nmarker7     ASV2        South 4.919766 0.0039173223 0.0039173223\nmarker8     ASV7        South 4.696894 0.0010275895 0.0010275895\nmarker9     ASV8        South 4.665053 0.0020814438 0.0020814438\nmarker10    ASV3        South 4.446940 0.0091897421 0.0091897421\nmarker11   ASV13        South 4.373734 0.0073724319 0.0073724319\nmarker12   ASV27        South 4.371920 0.0008112059 0.0008112059\n\np_LDAsc <- microbiomeMarker::plot_ef_bar(mm_lefse)\np_abd <- microbiomeMarker::plot_abundance(mm_lefse, group = \"Geo\")\ngridExtra::grid.arrange(p_LDAsc, p_abd, nrow = 1)\n\n\n\n\nLEFse identifies 12 biomarkers and among them ASV 7, 11 and 12 that we already identifies ealier with other methods."
  },
  {
    "objectID": "practicals/beta_diversity.html#differential-analysis-of-compositions-of-microbiomes-with-bias-correction-ancom-bc",
    "href": "practicals/beta_diversity.html#differential-analysis-of-compositions-of-microbiomes-with-bias-correction-ancom-bc",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "9.2 Differential analysis of compositions of microbiomes with bias correction (ANCOM-BC)",
    "text": "9.2 Differential analysis of compositions of microbiomes with bias correction (ANCOM-BC)\nThe ANCOM-BC methodology assumes that the observed sample is an unknown fraction of a unit volume of the ecosystem, and the sampling fraction varies from sample to sample. ANCOM-BC accounts for sampling fraction by introducing a sample-specific offset term in a linear regression framework, that is estimated from the observed data. The offset term serves as the bias correction, and the linear regression framework in log scale is analogous to log-ratio transformation to deal with the compositionality of microbiome data. Furthermore, this method provides p-values and confidence intervals for each taxon. It also controls the FDR and it is computationally simple to implement.\n\n#ancomBC\nmm_ancombc <- microbiomeMarker::run_ancombc(physeq, group = \"Geo\",\n                                            taxa_rank = \"none\",\n                                            pvalue_cutoff = 0.001,\n                                            p_adjust = \"fdr\")\n\nmm_ancombc_table <- data.frame(mm_ancombc@marker_table)\nmm_ancombc_table\n\n         feature enrich_group      ef_W       pvalue         padj\nmarker1     ASV2        South  3.980197 6.885820e-05 7.230111e-04\nmarker2     ASV7        South  4.341347 1.416118e-05 1.652137e-04\nmarker3     ASV8        South  4.532481 5.829496e-06 1.020162e-04\nmarker4    ASV10        North -4.775089 1.796277e-06 6.286968e-05\nmarker5    ASV11        North -5.811580 6.188594e-09 3.249012e-07\nmarker6    ASV12        North -4.466839 7.938375e-06 1.041912e-04\nmarker7    ASV18        North -4.561024 5.090471e-06 1.020162e-04\nmarker8    ASV27        South  5.874154 4.250091e-09 3.249012e-07\nmarker9    ASV35        North -4.483869 7.330158e-06 1.041912e-04\nmarker10   ASV49        North -4.680720 2.858686e-06 7.504051e-05\n\nan_ef <- microbiomeMarker::plot_ef_bar(mm_ancombc)\nan_abd <- microbiomeMarker::plot_abundance(mm_ancombc, group = \"Geo\")\ngridExtra::grid.arrange(an_ef, an_abd, nrow = 1)\n\n\n\n\nANCOM-BC identifies 10 biomarkers and all in common with the results of the LEFse analysis."
  },
  {
    "objectID": "practicals/beta_diversity.html#anova-like-differential-expression-aldex2",
    "href": "practicals/beta_diversity.html#anova-like-differential-expression-aldex2",
    "title": "PARTIII_BETA_Diversity_ANF",
    "section": "9.3 ANOVA-like differential expression (ALDEx2)",
    "text": "9.3 ANOVA-like differential expression (ALDEx2)\nALDEx2 estimates technical variation within each sample per taxon by utilizing the Dirichlet distribution. It furthermore applies the centered-log-ratio transformation (or closely related log-ratio transforms). Depending on the experimental setup, it will perform a two sample Welch’s T-test and Wilcoxon-test or a one-way ANOVA and Kruskal-Wallis-test. The Benjamini-Hochberg procedure is applied in any case to correct for multiple testing.\n\nmm_aldex <- microbiomeMarker::run_aldex(physeq, group = \"Geo\",\n                                        norm = \"CPM\",\n                                        taxa_rank = \"none\",\n                                        p_adjust = \"fdr\")\n\nmm_aldex_table <- data.frame(mm_aldex@marker_table)\nmm_aldex_table\n\n        feature enrich_group ef_aldex       pvalue      padj\nmarker1   ASV27        North 1.773277 0.0003126156 0.0336317\n\n\nALDEx2 is much more stringent and identifies only 1 biomarker, ASV 27 which has been identified by the two other DAA methods. The others do not reach the FDR cut-off used here; although, they likely have “largish” effect sizes. Often, if I consider performing DA testing, I will run several models and focus on the intersection of OTUs given by at least two methods. Here it would be the 10 ASV identified with the ANCOM-BC."
  }
]